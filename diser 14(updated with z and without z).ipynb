{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f59c7e-4b0b-4089-bc6c-2640682d29f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[With z] [bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.7562931180000305] [G loss: 0.9874855279922485] [SNR: 0.3049098327755928] [RMSE: 0.6469405293464661]\n",
      "[With z] [bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 3.457866668701172] [G loss: 0.15869513154029846] [SNR: 0.3569745272397995] [RMSE: 0.6430739760398865]\n",
      "[With z] [bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 1.0793532133102417] [G loss: 0.35250476002693176] [SNR: 0.34128259867429733] [RMSE: 0.6442369222640991]\n",
      "[With z] [bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.784264862537384] [G loss: 1.0566315650939941] [SNR: 0.31120728701353073] [RMSE: 0.6464716196060181]\n",
      "[With z] [bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.7408990859985352] [G loss: 0.9521473050117493] [SNR: 0.2518025226891041] [RMSE: 0.6509079933166504]\n",
      "[With z] [bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.697436511516571] [G loss: 0.7205798625946045] [SNR: -0.5065901204943657] [RMSE: 0.7102957367897034]\n",
      "[With z] [em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.7076215147972107] [G loss: 0.5920265913009644] [SNR: -4.70700740814209] [RMSE: 1.1520203351974487]\n",
      "[With z] [em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6967812776565552] [G loss: 0.709529459476471] [SNR: -5.274631977081299] [RMSE: 1.2298191785812378]\n",
      "[With z] [em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6913281679153442] [G loss: 0.7522580623626709] [SNR: -5.381416082382202] [RMSE: 1.2450319528579712]\n",
      "[With z] [em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.685554563999176] [G loss: 0.7159497737884521] [SNR: -5.263822078704834] [RMSE: 1.2282902002334595]\n",
      "[With z] [em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6800280809402466] [G loss: 0.6976222395896912] [SNR: -5.242061018943787] [RMSE: 1.2252165079116821]\n",
      "[With z] [em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6742843389511108] [G loss: 0.7106910347938538] [SNR: -5.155706405639648] [RMSE: 1.2130955457687378]\n",
      "[With z] [ma SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6736370325088501] [G loss: 0.7425106763839722] [SNR: -5.08734405040741] [RMSE: 1.2035858631134033]\n",
      "[With z] [ma SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6649647355079651] [G loss: 0.7368332147598267] [SNR: -5.007747411727905] [RMSE: 1.1926065683364868]\n",
      "[With z] [ma SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6557365655899048] [G loss: 0.759881317615509] [SNR: -4.927340447902679] [RMSE: 1.1816169023513794]\n",
      "[With z] [ma SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.644715428352356] [G loss: 0.7613185048103333] [SNR: -4.927398264408112] [RMSE: 1.181625485420227]\n",
      "[With z] [ma SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.635208010673523] [G loss: 0.826301097869873] [SNR: -5.005720853805542] [RMSE: 1.1923283338546753]\n",
      "[With z] [ma SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6227859258651733] [G loss: 0.824004054069519] [SNR: -5.008226037025452] [RMSE: 1.1926723718643188]\n",
      "[With z] [em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.5929125547409058] [G loss: 0.8390706777572632] [SNR: -5.008265376091003] [RMSE: 1.1926778554916382]\n",
      "[With z] [em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6009107828140259] [G loss: 1.2300881147384644] [SNR: -5.008264183998108] [RMSE: 1.1926774978637695]\n",
      "[With z] [em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.5430302619934082] [G loss: 0.8635213971138] [SNR: -5.008208155632019] [RMSE: 1.19266939163208]\n",
      "[With z] [em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.4946925640106201] [G loss: 1.1515103578567505] [SNR: -4.9270325899124146] [RMSE: 1.1815756559371948]\n",
      "[With z] [em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.45658987760543823] [G loss: 1.146990180015564] [SNR: -4.8449912667274475] [RMSE: 1.1704676151275635]\n",
      "[With z] [em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.40442728996276855] [G loss: 1.6590405702590942] [SNR: -4.844959378242493] [RMSE: 1.17046320438385]\n",
      "[With z] [ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.4939093589782715] [G loss: 1.1163926124572754] [SNR: -4.711302220821381] [RMSE: 1.1525907516479492]\n",
      "[With z] [ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.8644524216651917] [G loss: 2.8662164211273193] [SNR: -4.496879875659943] [RMSE: 1.1244853734970093]\n",
      "[With z] [ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.5456706285476685] [G loss: 0.9488155245780945] [SNR: -4.544607698917389] [RMSE: 1.130681037902832]\n",
      "[With z] [ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6810340285301208] [G loss: 0.6010348200798035] [SNR: -3.645763099193573] [RMSE: 1.019525170326233]\n",
      "[With z] [ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.7060099840164185] [G loss: 0.5991777777671814] [SNR: -1.3874605298042297] [RMSE: 0.7861093282699585]\n",
      "[With z] [ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.703707754611969] [G loss: 0.6694655418395996] [SNR: -2.3266182839870453] [RMSE: 0.8758720755577087]\n",
      "[With z] [ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.712543249130249] [G loss: 0.7357087135314941] [SNR: -0.7158303260803223] [RMSE: 0.7276143431663513]\n",
      "[With z] [ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.7109687924385071] [G loss: 0.6523427367210388] [SNR: -2.3758015036582947] [RMSE: 0.8808459639549255]\n",
      "[With z] [ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.7075752019882202] [G loss: 0.6453763246536255] [SNR: -2.3954077064990997] [RMSE: 0.8828365206718445]\n",
      "[With z] [ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.7008549571037292] [G loss: 0.6737192869186401] [SNR: -2.153094559907913] [RMSE: 0.858548104763031]\n",
      "[With z] [ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6961790323257446] [G loss: 0.6901238560676575] [SNR: -0.9544394165277481] [RMSE: 0.7478797435760498]\n",
      "[With z] [ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6918260455131531] [G loss: 0.6916810274124146] [SNR: -0.5325673148036003] [RMSE: 0.7124233245849609]\n",
      "[With z] [ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6873894929885864] [G loss: 0.6980099678039551] [SNR: -0.8149440586566925] [RMSE: 0.7359644770622253]\n",
      "[With z] [ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6858572363853455] [G loss: 0.6810024380683899] [SNR: 0.37725117057561874] [RMSE: 0.6415748000144958]\n",
      "[With z] [ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6831791996955872] [G loss: 0.691504716873169] [SNR: -0.4243209958076477] [RMSE: 0.703600287437439]\n",
      "[With z] [ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6863845586776733] [G loss: 0.6930800080299377] [SNR: 0.262598879635334] [RMSE: 0.6500995755195618]\n",
      "[With z] [ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6861865520477295] [G loss: 0.6886349320411682] [SNR: 0.4072337970137596] [RMSE: 0.6393639445304871]\n",
      "[With z] [ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6867332458496094] [G loss: 0.6813357472419739] [SNR: 0.39518561214208603] [RMSE: 0.6402515769004822]\n",
      "[Without z] [bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6795821189880371] [G loss: 0.747097373008728] [SNR: -1.0485213249921799] [RMSE: 0.7560245394706726]\n",
      "[Without z] [bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 1.6022605895996094] [G loss: 0.2649249732494354] [SNR: -1.0289771854877472] [RMSE: 0.7543253302574158]\n",
      "[Without z] [bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.734764575958252] [G loss: 0.5724682211875916] [SNR: -1.0106386244297028] [RMSE: 0.7527341246604919]\n",
      "[Without z] [bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.7429518699645996] [G loss: 0.975691556930542] [SNR: -0.9973358362913132] [RMSE: 0.7515822649002075]\n",
      "[Without z] [bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.7124837636947632] [G loss: 0.706959068775177] [SNR: -1.3524247705936432] [RMSE: 0.7829446196556091]\n",
      "[Without z] [bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.7593493461608887] [G loss: 0.5504921078681946] [SNR: -3.1244319677352905] [RMSE: 0.9601329565048218]\n",
      "[Without z] [em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.7732192277908325] [G loss: 0.5682445764541626] [SNR: -5.125613808631897] [RMSE: 1.208900809288025]\n",
      "[Without z] [em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.739354133605957] [G loss: 0.700986385345459] [SNR: -5.162523984909058] [RMSE: 1.2140487432479858]\n",
      "[Without z] [em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.7147921919822693] [G loss: 0.6495879888534546] [SNR: -5.45212984085083] [RMSE: 1.2552099227905273]\n",
      "[Without z] [em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.700293242931366] [G loss: 0.68210369348526] [SNR: -5.371742248535156] [RMSE: 1.243646264076233]\n",
      "[Without z] [em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6894389390945435] [G loss: 0.694481372833252] [SNR: -5.316924452781677] [RMSE: 1.2358230352401733]\n",
      "[Without z] [em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.674353301525116] [G loss: 0.7152080535888672] [SNR: -5.317862629890442] [RMSE: 1.235955834388733]\n",
      "[Without z] [ma SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6655128002166748] [G loss: 0.7567228674888611] [SNR: -5.317349433898926] [RMSE: 1.2358825206756592]\n",
      "[Without z] [ma SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6809243559837341] [G loss: 0.6066300868988037] [SNR: -5.316832661628723] [RMSE: 1.2358088493347168]\n",
      "[Without z] [ma SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.9068989753723145] [G loss: 1.7240984439849854] [SNR: -5.315954089164734] [RMSE: 1.2356843948364258]\n",
      "[Without z] [ma SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6781061887741089] [G loss: 0.6614698171615601] [SNR: -5.314282178878784] [RMSE: 1.2354463338851929]\n",
      "[Without z] [ma SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6275388598442078] [G loss: 0.7008212804794312] [SNR: -5.309831500053406] [RMSE: 1.2348136901855469]\n",
      "[Without z] [ma SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.5935822129249573] [G loss: 0.8457740545272827] [SNR: -5.372211933135986] [RMSE: 1.2437132596969604]\n",
      "[Without z] [em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.5372563004493713] [G loss: 1.0585201978683472] [SNR: -5.464361906051636] [RMSE: 1.2569788694381714]\n",
      "[Without z] [em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.46566593647003174] [G loss: 1.1881122589111328] [SNR: -5.518054962158203] [RMSE: 1.2647730112075806]\n",
      "[Without z] [em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.3937728703022003] [G loss: 1.3859856128692627] [SNR: -5.554659962654114] [RMSE: 1.2701144218444824]\n",
      "[Without z] [em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.3478085696697235] [G loss: 1.6167551279067993] [SNR: -5.395498871803284] [RMSE: 1.2470523118972778]\n",
      "[Without z] [em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.4530344009399414] [G loss: 1.02413809299469] [SNR: -5.362942218780518] [RMSE: 1.242387294769287]\n",
      "[Without z] [em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.5266156792640686] [G loss: 2.3515374660491943] [SNR: -5.139367580413818] [RMSE: 1.2108159065246582]\n",
      "[Without z] [ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6298012137413025] [G loss: 1.0147782564163208] [SNR: -5.1536887884140015] [RMSE: 1.2128143310546875]\n",
      "[Without z] [ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6324983239173889] [G loss: 1.2632207870483398] [SNR: -3.156416416168213] [RMSE: 0.9636752009391785]\n",
      "[Without z] [ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.707323431968689] [G loss: 0.7372112274169922] [SNR: -0.9775775671005249] [RMSE: 0.7498748302459717]\n",
      "[Without z] [ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6879664659500122] [G loss: 0.6967894434928894] [SNR: -0.9843630343675613] [RMSE: 0.7504608631134033]\n",
      "[Without z] [ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6824265718460083] [G loss: 0.6897469758987427] [SNR: -0.9839162230491638] [RMSE: 0.7504222393035889]\n",
      "[Without z] [ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6768378019332886] [G loss: 0.6979130506515503] [SNR: -0.9792618453502655] [RMSE: 0.750019907951355]\n",
      "[Without z] [ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6843231916427612] [G loss: 0.7226216197013855] [SNR: -0.9738115966320038] [RMSE: 0.7495498657226562]\n",
      "[Without z] [ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6959844827651978] [G loss: 0.6386522650718689] [SNR: -1.0067854821681976] [RMSE: 0.7524002194404602]\n",
      "[Without z] [ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.7737041711807251] [G loss: 0.6134709715843201] [SNR: -1.6331960260868073] [RMSE: 0.8086668848991394]\n",
      "[Without z] [ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 1.0268502235412598] [G loss: 0.306692898273468] [SNR: -4.804057478904724] [RMSE: 1.1649646759033203]\n",
      "[Without z] [ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.8962557315826416] [G loss: 0.6589637398719788] [SNR: -5.545220971107483] [RMSE: 1.2687350511550903]\n",
      "[Without z] [ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.7803215384483337] [G loss: 0.5483060479164124] [SNR: -5.292102098464966] [RMSE: 1.2322955131530762]\n",
      "[Without z] [ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.7260661125183105] [G loss: 0.6200608015060425] [SNR: -5.134201645851135] [RMSE: 1.2100964784622192]\n",
      "[Without z] [ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6927685737609863] [G loss: 0.6515763401985168] [SNR: -5.074504613876343] [RMSE: 1.2018078565597534]\n",
      "[Without z] [ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.671052098274231] [G loss: 0.7664376497268677] [SNR: -4.981995224952698] [RMSE: 1.1890761852264404]\n",
      "[Without z] [ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.713083803653717] [G loss: 0.5800852179527283] [SNR: -4.912260174751282] [RMSE: 1.179567813873291]\n",
      "[Without z] [ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6821097135543823] [G loss: 0.9750888347625732] [SNR: -4.7528186440467834] [RMSE: 1.1581121683120728]\n",
      "[Without z] [ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6289078593254089] [G loss: 0.8672693371772766] [SNR: -4.653467237949371] [RMSE: 1.1449412107467651]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wfdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ECGDataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, raw_signals, noisy_signals):\n",
    "        self.raw_signals = raw_signals\n",
    "        self.noisy_signals = noisy_signals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_signal = self.raw_signals[idx]\n",
    "        noisy_signal = self.noisy_signals[idx]\n",
    "        return torch.tensor(raw_signal, dtype=torch.float32), torch.tensor(noisy_signal, dtype=torch.float32)\n",
    "\n",
    "# Define the add_noise function\n",
    "def add_noise(signal, noise, snr):\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    factor = (signal_power / noise_power) / (10 ** (snr / 10))\n",
    "    noisy_signal = signal + noise * 100 * np.sqrt(factor)\n",
    "    return noisy_signal\n",
    "\n",
    "# Define the load_mit_bih_data function\n",
    "def load_mit_bih_data(records, noise_type, snr_levels, target_length=650000):\n",
    "    raw_signals = []\n",
    "    noisy_signals_dict = {snr: [] for snr in snr_levels}\n",
    "    \n",
    "    for record in records:\n",
    "        raw_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-arrhythmia-database-1.0.0/{record}')\n",
    "        raw_signal = raw_record.p_signal[:, 0]  # Use the first channel for simplicity\n",
    "        \n",
    "        # Load noise and add it to the raw signal\n",
    "        noise_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-noise-stress-test-database-1.0.0/{noise_type}')\n",
    "        noise_signal = noise_record.p_signal[:, 0]\n",
    "        \n",
    "        # Ensure the signals are of the same length\n",
    "        min_length = min(len(raw_signal), len(noise_signal), target_length)\n",
    "        raw_signal = raw_signal[:min_length]\n",
    "        noise_signal = noise_signal[:min_length]\n",
    "        \n",
    "        # Pad signals to target length\n",
    "        if min_length < target_length:\n",
    "            raw_signal = np.pad(raw_signal, (0, target_length - min_length), 'constant')\n",
    "            noise_signal = np.pad(noise_signal, (0, target_length - min_length), 'constant')\n",
    "        \n",
    "        raw_signals.append(raw_signal)\n",
    "        \n",
    "        for snr in snr_levels:\n",
    "            noisy_signal = add_noise(raw_signal, noise_signal, snr)\n",
    "            noisy_signals_dict[snr].append(noisy_signal)\n",
    "    \n",
    "    return np.array(raw_signals), {snr: np.array(noisy_signals_dict[snr]) for snr in snr_levels}\n",
    "\n",
    "# Select records and noise types for the experiment\n",
    "records = ['103', '105', '111', '116', '122', '205', '213', '219', '223', '230']\n",
    "noise_types = ['bw', 'em', 'ma']\n",
    "combined_noise_types = ['em+bw', 'ma+bw', 'ma+em', 'ma+em+bw']\n",
    "snr_levels = [0, 1, 2, 3, 4, 5]\n",
    "target_length = 649984\n",
    "\n",
    "raw_signals, noisy_signals_dict = {}, {}\n",
    "for noise_type in noise_types:\n",
    "    raw_signals[noise_type], noisy_signals_dict[noise_type] = load_mit_bih_data(records, noise_type, snr_levels, target_length)\n",
    "\n",
    "# For combined noise types, combine the corresponding noises\n",
    "for combined_noise in combined_noise_types:\n",
    "    components = combined_noise.split('+')\n",
    "    combined_raw_signals, combined_noisy_signals = [], {snr: [] for snr in snr_levels}\n",
    "    for i in range(len(records)):\n",
    "        combined_signal = np.zeros(target_length)\n",
    "        for component in components:\n",
    "            raw_signal = raw_signals[component][i]\n",
    "            combined_signal += raw_signal / len(components)  # Average the signals\n",
    "        combined_raw_signals.append(combined_signal)\n",
    "        for snr in snr_levels:\n",
    "            combined_noise_signal = np.zeros(target_length)\n",
    "            for component in components:\n",
    "                noise_signal = noisy_signals_dict[component][snr][i]\n",
    "                combined_noise_signal += noise_signal / len(components)  # Average the noises\n",
    "            combined_noisy_signals[snr].append(combined_noise_signal)\n",
    "    raw_signals[combined_noise] = np.array(combined_raw_signals)\n",
    "    noisy_signals_dict[combined_noise] = {snr: np.array(combined_noisy_signals[snr]) for snr in snr_levels}\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "datasets = {}\n",
    "for noise_type in noise_types + combined_noise_types:\n",
    "    for snr in snr_levels:\n",
    "        datasets[(noise_type, snr)] = ECGDataset(raw_signals[noise_type], noisy_signals_dict[noise_type][snr])\n",
    "\n",
    "dataloaders = {key: DataLoader(dataset, batch_size=16, shuffle=True) for key, dataset in datasets.items()}\n",
    "\n",
    "# Define the Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, use_z=True):\n",
    "        super(Generator, self).__init__()\n",
    "        self.use_z = use_z\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(8, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.decoder_with_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(2048, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder_without_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        if self.use_z:\n",
    "            z = torch.randn_like(encoded)\n",
    "            encoded = torch.cat((encoded, z), 1)\n",
    "            decoded = self.decoder_with_z(encoded)\n",
    "        else:\n",
    "            decoded = self.decoder_without_z(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define the Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(x.size(0), -1)\n",
    "\n",
    "# Define the calculate_snr function\n",
    "def calculate_snr(original, denoised):\n",
    "    noise = original - denoised\n",
    "    snr = 10 * np.log10(np.sum(original ** 2) / np.sum(noise ** 2))\n",
    "    return snr\n",
    "\n",
    "def calculate_rmse(original, denoised):\n",
    "    mse = np.mean((original - denoised) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def train(generator, discriminator, dataloaders, num_epochs=1, lr=0.0005):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    results = {'Noise_Type': [], 'SNR_Level': [], 'Epoch': [], 'Batch': [], 'D_loss': [], 'G_loss': [], 'SNR': [], 'RMSE': []}\n",
    "    \n",
    "    for (noise_type, snr), dataloader in dataloaders.items():\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (raw_signals, noisy_signals) in enumerate(dataloader):\n",
    "                batch_size = raw_signals.size(0)\n",
    "                \n",
    "                # Ensure the signals have the same length\n",
    "                min_length = min(raw_signals.shape[-1], noisy_signals.shape[-1])\n",
    "                raw_signals = raw_signals[:, :min_length]\n",
    "                noisy_signals = noisy_signals[:, :min_length]\n",
    "\n",
    "                # Denoise the noisy signals\n",
    "                noisy_signals = noisy_signals.unsqueeze(1)  # Add channel dimension\n",
    "                raw_signals = raw_signals.unsqueeze(1)\n",
    "\n",
    "                # Train Generator\n",
    "                optimizer_G.zero_grad()\n",
    "                gen_signals = generator(noisy_signals)\n",
    "                \n",
    "                # Ensure the generated signals have the same length as the input signals\n",
    "                if gen_signals.shape[-1] != noisy_signals.shape[-1]:\n",
    "                    gen_signals = torch.nn.functional.interpolate(gen_signals, size=noisy_signals.shape[-1])\n",
    "\n",
    "                # Update valid and fake labels to match the discriminator output size\n",
    "                disc_output_size = discriminator(torch.cat((gen_signals, noisy_signals), 1)).size()\n",
    "                valid = torch.ones(disc_output_size).to(gen_signals.device)\n",
    "                fake = torch.zeros(disc_output_size).to(gen_signals.device)\n",
    "                \n",
    "                g_loss = criterion(discriminator(torch.cat((gen_signals, noisy_signals), 1)), valid)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # Train Discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(torch.cat((raw_signals, noisy_signals), 1)), valid)\n",
    "                fake_loss = criterion(discriminator(torch.cat((gen_signals.detach(), noisy_signals), 1)), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # Calculate SNR and RMSE\n",
    "                snr_value = calculate_snr(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "                rmse_value = calculate_rmse(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "\n",
    "                # Store results\n",
    "                results['Noise_Type'].append(noise_type)\n",
    "                results['SNR_Level'].append(snr)\n",
    "                results['Epoch'].append(epoch + 1)\n",
    "                results['Batch'].append(i + 1)\n",
    "                results['D_loss'].append(d_loss.item())\n",
    "                results['G_loss'].append(g_loss.item())\n",
    "                results['SNR'].append(snr_value)\n",
    "                results['RMSE'].append(rmse_value)\n",
    "                \n",
    "                print(f\"[{'With z' if generator.use_z else 'Without z'}] [{noise_type} SNR {snr}] [Epoch {epoch + 1}/{num_epochs}] [Batch {i + 1}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [SNR: {snr_value}] [RMSE: {rmse_value}]\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initialize models with and without z\n",
    "generator_with_z = Generator(use_z=True)\n",
    "generator_without_z = Generator(use_z=False)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Train the models and collect results for each SNR level\n",
    "results_with_z = train(generator_with_z, discriminator, dataloaders, num_epochs=1)  # Adjusted for quick testing\n",
    "results_without_z = train(generator_without_z, discriminator, dataloaders, num_epochs=1)  # Adjusted for quick testing\n",
    "\n",
    "# Create DataFrames to display results\n",
    "df_results_with_z = pd.DataFrame(results_with_z)\n",
    "df_results_without_z = pd.DataFrame(results_without_z)\n",
    "\n",
    "# Average SNR and RMSE for each SNR level\n",
    "avg_snr_with_z = df_results_with_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_with_z = df_results_with_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "avg_snr_without_z = df_results_without_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_without_z = df_results_without_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "# Plot SNR vs Average SNR\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_snr_with_z.index, avg_snr_with_z.values, label='With z')\n",
    "plt.plot(avg_snr_without_z.index, avg_snr_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Average SNR (dB)')\n",
    "plt.title('SNR vs Average SNR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('snr_vs_avg_snr.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot SNR vs RMSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_rmse_with_z.index, avg_rmse_with_z.values, label='With z')\n",
    "plt.plot(avg_rmse_without_z.index, avg_rmse_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('SNR vs RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('snr_vs_rmse.png')\n",
    "plt.show()\n",
    "\n",
    "# Display the DataFrames as a table\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Denoising Results with z\", dataframe=df_results_with_z)\n",
    "tools.display_dataframe_to_user(name=\"Denoising Results without z\", dataframe=df_results_without_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebc352-7ac1-4ce5-8887-f11265ae3f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536fd38-8c45-4947-8c95-6f55024504b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ef521-8d52-41e4-9e1f-66859aaf8622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
