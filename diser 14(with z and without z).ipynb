{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491b9e73-8fef-4a89-af56-2b4da2197cf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1024, 1024, 1], expected input[8, 2048, 2539] to have 1024 channels, but got 2048 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 312\u001b[0m\n\u001b[0;32m    309\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m Discriminator()\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# Train the models and collect results\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m results_with_z \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator_with_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m results_without_z \u001b[38;5;241m=\u001b[39m train(generator_without_z, discriminator, dataloaders, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, use_z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# Create DataFrames to display results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 267\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(generator, discriminator, dataloaders, num_epochs, lr, use_z)\u001b[0m\n\u001b[0;32m    265\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_z:\n\u001b[1;32m--> 267\u001b[0m     gen_signals \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     gen_signals \u001b[38;5;241m=\u001b[39m generator(noisy_signals)\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 158\u001b[0m, in \u001b[0;36mGeneratorWithZ.forward\u001b[1;34m(self, x, z)\u001b[0m\n\u001b[0;32m    156\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprelu(x)\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_connections):\n\u001b[1;32m--> 158\u001b[0m         x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_connections\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencodings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1024, 1024, 1], expected input[8, 2048, 2539] to have 1024 channels, but got 2048 channels instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the ECGDataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, raw_signals, noisy_signals):\n",
    "        self.raw_signals = raw_signals\n",
    "        self.noisy_signals = noisy_signals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_signal = self.raw_signals[idx]\n",
    "        noisy_signal = self.noisy_signals[idx]\n",
    "        return torch.tensor(raw_signal, dtype=torch.float32), torch.tensor(noisy_signal, dtype=torch.float32)\n",
    "\n",
    "# Define the add_noise function\n",
    "def add_noise(signal, noise, snr):\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    factor = (signal_power / noise_power) / (10 ** (snr / 10))\n",
    "    noisy_signal = signal + noise * np.sqrt(factor)\n",
    "    return noisy_signal\n",
    "\n",
    "# Define the load_mit_bih_data function\n",
    "def load_mit_bih_data(records, noise_types, snr_levels, target_length=650000):\n",
    "    raw_signals_dict = {noise_type: [] for noise_type in noise_types}\n",
    "    noisy_signals_dict = {noise_type: {snr: [] for snr in snr_levels} for noise_type in noise_types}\n",
    "    \n",
    "    for record in records:\n",
    "        raw_record = wfdb.rdrecord(f'M:/Dissertation/New folder/mit-bih-arrhythmia-database-1.0.0/{record}')\n",
    "        raw_signal = raw_record.p_signal[:, 0]  # Use the first channel for simplicity\n",
    "        \n",
    "        for noise_type in noise_types:\n",
    "            noise_record = wfdb.rdrecord(f'M:/Dissertation/New folder/mit-bih-noise-stress-test-database-1.0.0/{noise_type}')\n",
    "            noise_signal = noise_record.p_signal[:, 0]\n",
    "            \n",
    "            min_length = min(len(raw_signal), len(noise_signal), target_length)\n",
    "            raw_signal_cut = raw_signal[:min_length]\n",
    "            noise_signal_cut = noise_signal[:min_length]\n",
    "            \n",
    "            if min_length < target_length:\n",
    "                raw_signal_cut = np.pad(raw_signal_cut, (0, target_length - min_length), 'constant')\n",
    "                noise_signal_cut = np.pad(noise_signal_cut, (0, target_length - min_length), 'constant')\n",
    "            \n",
    "            raw_signals_dict[noise_type].append(raw_signal_cut)\n",
    "            \n",
    "            for snr in snr_levels:\n",
    "                noisy_signal = add_noise(raw_signal_cut, noise_signal_cut, snr)\n",
    "                noisy_signals_dict[noise_type][snr].append(noisy_signal)\n",
    "    \n",
    "    return raw_signals_dict, noisy_signals_dict\n",
    "\n",
    "# Select records and noise types for the experiment\n",
    "records = ['103', '105', '111', '116', '122', '205', '213', '219', '223', '230']\n",
    "noise_types = ['bw', 'em', 'ma']\n",
    "combined_noise_types = ['em+bw', 'ma+bw', 'ma+em', 'ma+em+bw']\n",
    "snr_levels = [0, 1, 2, 3, 4, 5]\n",
    "target_length = 649984\n",
    "\n",
    "raw_signals_dict, noisy_signals_dict = load_mit_bih_data(records, noise_types, snr_levels, target_length)\n",
    "\n",
    "# For combined noise types, combine the corresponding noises\n",
    "for combined_noise in combined_noise_types:\n",
    "    components = combined_noise.split('+')\n",
    "    combined_raw_signals = []\n",
    "    combined_noisy_signals = {snr: [] for snr in snr_levels}\n",
    "    \n",
    "    for i in range(len(records)):\n",
    "        combined_signal = np.zeros(target_length)\n",
    "        for component in components:\n",
    "            combined_signal += raw_signals_dict[component][i] / len(components)\n",
    "        combined_raw_signals.append(combined_signal)\n",
    "        \n",
    "        for snr in snr_levels:\n",
    "            combined_noise_signal = np.zeros(target_length)\n",
    "            for component in components:\n",
    "                combined_noise_signal += np.array(noisy_signals_dict[component][snr][i]) / len(components)\n",
    "            combined_noisy_signals[snr].append(combined_noise_signal)\n",
    "    \n",
    "    raw_signals_dict[combined_noise] = combined_raw_signals\n",
    "    noisy_signals_dict[combined_noise] = combined_noisy_signals\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "datasets = {}\n",
    "for noise_type in noise_types + combined_noise_types:\n",
    "    for snr in snr_levels:\n",
    "        raw_signals_train, raw_signals_test, noisy_signals_train, noisy_signals_test = train_test_split(\n",
    "            raw_signals_dict[noise_type], noisy_signals_dict[noise_type][snr], test_size=0.2, random_state=42)\n",
    "        \n",
    "        train_dataset = ECGDataset(raw_signals_train, noisy_signals_train)\n",
    "        test_dataset = ECGDataset(raw_signals_test, noisy_signals_test)\n",
    "        \n",
    "        datasets[(noise_type, snr, 'train')] = train_dataset\n",
    "        datasets[(noise_type, snr, 'test')] = test_dataset\n",
    "\n",
    "dataloaders = {key: DataLoader(dataset, batch_size=256, shuffle=True) for key, dataset in datasets.items()}\n",
    "\n",
    "# Define the Generator class with and without input variables z\n",
    "class GeneratorWithZ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorWithZ, self).__init__()\n",
    "        self.encoder = nn.ModuleList([\n",
    "            nn.Conv1d(1, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(1024, 2048, kernel_size=4, stride=2, padding=1),\n",
    "        ])\n",
    "        self.z_layer = nn.Linear(10, 2048)  # Assuming z is a vector of size 10\n",
    "        self.decoder = nn.ModuleList([\n",
    "            nn.ConvTranspose1d(4096, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(16, 1, kernel_size=4, stride=2, padding=1),\n",
    "        ])\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.skip_connections = nn.ModuleList([\n",
    "            nn.Conv1d(16, 16, kernel_size=1),\n",
    "            nn.Conv1d(32, 32, kernel_size=1),\n",
    "            nn.Conv1d(64, 64, kernel_size=1),\n",
    "            nn.Conv1d(128, 128, kernel_size=1),\n",
    "            nn.Conv1d(256, 256, kernel_size=1),\n",
    "            nn.Conv1d(512, 512, kernel_size=1),\n",
    "            nn.Conv1d(1024, 1024, kernel_size=1),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        encodings = []\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            x = self.prelu(x)\n",
    "            encodings.append(x)\n",
    "        \n",
    "        z = self.prelu(self.z_layer(z)).unsqueeze(2).repeat(1, 1, x.size(2))\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "        \n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            x = layer(x)\n",
    "            x = self.prelu(x)\n",
    "            if i < len(self.skip_connections):\n",
    "                x += self.skip_connections[-i-1](encodings[-i-1])\n",
    "        return x\n",
    "\n",
    "class GeneratorWithoutZ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorWithoutZ, self).__init__()\n",
    "        self.encoder = nn.ModuleList([\n",
    "            nn.Conv1d(1, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Conv1d(1024, 2048, kernel_size=4, stride=2, padding=1),\n",
    "        ])\n",
    "        self.decoder = nn.ModuleList([\n",
    "            nn.ConvTranspose1d(2048, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose1d(16, 1, kernel_size=4, stride=2, padding=1),\n",
    "        ])\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.skip_connections = nn.ModuleList([\n",
    "            nn.Conv1d(16, 16, kernel_size=1),\n",
    "            nn.Conv1d(32, 32, kernel_size=1),\n",
    "            nn.Conv1d(64, 64, kernel_size=1),\n",
    "            nn.Conv1d(128, 128, kernel_size=1),\n",
    "            nn.Conv1d(256, 256, kernel_size=1),\n",
    "            nn.Conv1d(512, 512, kernel_size=1),\n",
    "            nn.Conv1d(1024, 1024, kernel_size=1),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        encodings = []\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            x = self.prelu(x)\n",
    "            encodings.append(x)\n",
    "        \n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            x = layer(x)\n",
    "            x = self.prelu(x)\n",
    "            if i < len(self.skip_connections):\n",
    "                x += self.skip_connections[-i-1](encodings[-i-1])\n",
    "        return x\n",
    "\n",
    "# Define the Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(x.size(0), -1)\n",
    "\n",
    "# Define the calculate_snr function\n",
    "def calculate_snr(original, denoised):\n",
    "    noise = original - denoised\n",
    "    snr = 10 * np.log10(np.sum(original ** 2) / np.sum(noise ** 2))\n",
    "    return snr\n",
    "\n",
    "def calculate_rmse(original, denoised):\n",
    "    mse = np.mean((original - denoised) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def train(generator, discriminator, dataloaders, num_epochs=100, lr=0.0001, use_z=False):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_G = torch.optim.RMSprop(generator.parameters(), lr=lr)\n",
    "    optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=lr)\n",
    "    \n",
    "    results = {'Noise_Type': [], 'SNR_Level': [], 'Epoch': [], 'Batch': [], 'D_loss': [], 'G_loss': [], 'SNR': [], 'RMSE': []}\n",
    "    \n",
    "    for (noise_type, snr, phase), dataloader in dataloaders.items():\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (raw_signals, noisy_signals) in enumerate(dataloader):\n",
    "                batch_size = raw_signals.size(0)\n",
    "                \n",
    "                # Ensure the signals have the same length\n",
    "                min_length = min(raw_signals.shape[-1], noisy_signals.shape[-1])\n",
    "                raw_signals = raw_signals[:, :min_length]\n",
    "                noisy_signals = noisy_signals[:, :min_length]\n",
    "\n",
    "                # Denoise the noisy signals\n",
    "                noisy_signals = noisy_signals.unsqueeze(1)  # Add channel dimension\n",
    "                raw_signals = raw_signals.unsqueeze(1)\n",
    "                \n",
    "                # Create random z\n",
    "                z = torch.randn(batch_size, 10) if use_z else None\n",
    "\n",
    "                # Train Generator\n",
    "                optimizer_G.zero_grad()\n",
    "                if use_z:\n",
    "                    gen_signals = generator(noisy_signals, z)\n",
    "                else:\n",
    "                    gen_signals = generator(noisy_signals)\n",
    "                \n",
    "                # Update valid and fake labels to match the discriminator output size\n",
    "                disc_output_size = discriminator(torch.cat((gen_signals, noisy_signals), 1)).size()\n",
    "                valid = torch.ones(disc_output_size).to(gen_signals.device)\n",
    "                fake = torch.zeros(disc_output_size).to(gen_signals.device)\n",
    "                \n",
    "                g_loss = criterion(discriminator(torch.cat((gen_signals, noisy_signals), 1)), valid)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # Train Discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(torch.cat((raw_signals, noisy_signals), 1)), valid)\n",
    "                fake_loss = criterion(discriminator(torch.cat((gen_signals.detach(), noisy_signals), 1)), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # Calculate SNR and RMSE\n",
    "                snr_value = calculate_snr(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "                rmse_value = calculate_rmse(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "\n",
    "                # Store results\n",
    "                results['Noise_Type'].append(noise_type)\n",
    "                results['SNR_Level'].append(snr)\n",
    "                results['Epoch'].append(epoch + 1)\n",
    "                results['Batch'].append(i + 1)\n",
    "                results['D_loss'].append(d_loss.item())\n",
    "                results['G_loss'].append(g_loss.item())\n",
    "                results['SNR'].append(snr_value)\n",
    "                results['RMSE'].append(rmse_value)\n",
    "                \n",
    "                print(f\"[{noise_type} SNR {snr}] [Epoch {epoch + 1}/{num_epochs}] [Batch {i + 1}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [SNR: {snr_value}] [RMSE: {rmse_value}]\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initialize models\n",
    "generator_with_z = GeneratorWithZ()\n",
    "generator_without_z = GeneratorWithoutZ()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Train the models and collect results\n",
    "results_with_z = train(generator_with_z, discriminator, dataloaders, num_epochs=100, lr=0.0001, use_z=True)\n",
    "results_without_z = train(generator_without_z, discriminator, dataloaders, num_epochs=100, lr=0.0001, use_z=False)\n",
    "\n",
    "# Create DataFrames to display results\n",
    "df_results_with_z = pd.DataFrame(results_with_z)\n",
    "df_results_without_z = pd.DataFrame(results_without_z)\n",
    "\n",
    "# Plotting the results\n",
    "avg_snr_with_z = df_results_with_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_with_z = df_results_with_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "avg_snr_without_z = df_results_without_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_without_z = df_results_without_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(snr_levels, avg_snr_with_z, label='With z')\n",
    "plt.plot(snr_levels, avg_snr_without_z, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Average SNR (dB)')\n",
    "plt.title('SNR vs Average SNR')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(snr_levels, avg_rmse_with_z, label='With z')\n",
    "plt.plot(snr_levels, avg_rmse_without_z, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Average RMSE')\n",
    "plt.title('SNR vs Average RMSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed069d36-6b49-4555-b07c-811682d53f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
