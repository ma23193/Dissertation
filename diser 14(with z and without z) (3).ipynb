{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd39fdc-7e28-495d-ac22-b3ff0de2a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-arrhythmia-database-1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e528005-1878-4d0a-a5f4-16ba910dc961",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-noise-stress-test-database-1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "491b9e73-8fef-4a89-af56-2b4da2197cf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1024, 1024, 1], expected input[8, 2048, 253] to have 1024 channels, but got 2048 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 321\u001b[0m\n\u001b[0;32m    318\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m Discriminator()\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Train the models and collect results\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m results_with_z \u001b[38;5;241m=\u001b[39m train(generator_with_z, discriminator, dataloaders, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, use_z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    322\u001b[0m results_without_z \u001b[38;5;241m=\u001b[39m train(generator_without_z, discriminator, dataloaders, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, use_z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# Create DataFrames to display results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 276\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(generator, discriminator, dataloaders, num_epochs, lr, use_z)\u001b[0m\n\u001b[0;32m    274\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_z:\n\u001b[1;32m--> 276\u001b[0m     gen_signals \u001b[38;5;241m=\u001b[39m generator(noisy_signals, z)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m     gen_signals \u001b[38;5;241m=\u001b[39m generator(noisy_signals)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[22], line 159\u001b[0m, in \u001b[0;36mGeneratorWithZ.forward\u001b[1;34m(self, x, z)\u001b[0m\n\u001b[0;32m    157\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprelu(x)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_connections):\n\u001b[1;32m--> 159\u001b[0m     skip_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_connections[\u001b[38;5;241m-\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)](encodings[\u001b[38;5;241m-\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m!=\u001b[39m skip_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    161\u001b[0m         diff \u001b[38;5;241m=\u001b[39m skip_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1024, 1024, 1], expected input[8, 2048, 253] to have 1024 channels, but got 2048 channels instead"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import wfdb\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Define the ECGDataset class\n",
    "# class ECGDataset(Dataset):\n",
    "#     def __init__(self, raw_signals, noisy_signals):\n",
    "#         self.raw_signals = raw_signals\n",
    "#         self.noisy_signals = noisy_signals\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.raw_signals)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         raw_signal = self.raw_signals[idx]\n",
    "#         noisy_signal = self.noisy_signals[idx]\n",
    "#         return torch.tensor(raw_signal, dtype=torch.float32), torch.tensor(noisy_signal, dtype=torch.float32)\n",
    "\n",
    "# # Define the add_noise function\n",
    "# def add_noise(signal, noise, snr):\n",
    "#     signal_power = np.mean(signal ** 2)\n",
    "#     noise_power = np.mean(noise ** 2)\n",
    "#     factor = (signal_power / noise_power) / (10 ** (snr / 10))\n",
    "#     noisy_signal = signal + noise * np.sqrt(factor)\n",
    "#     return noisy_signal\n",
    "\n",
    "# # Define the load_mit_bih_data function\n",
    "# def load_mit_bih_data(records, noise_types, snr_levels, target_length=65000):\n",
    "#     raw_signals_dict = {noise_type: [] for noise_type in noise_types}\n",
    "#     noisy_signals_dict = {noise_type: {snr: [] for snr in snr_levels} for noise_type in noise_types}\n",
    "    \n",
    "#     for record in records:\n",
    "#         raw_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-arrhythmia-database-1.0.0/{record}')\n",
    "#         raw_signal = raw_record.p_signal[:, 0]  # Use the first channel for simplicity\n",
    "        \n",
    "#         for noise_type in noise_types:\n",
    "#             noise_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-noise-stress-test-database-1.0.0/{noise_type}')\n",
    "#             noise_signal = noise_record.p_signal[:, 0]\n",
    "            \n",
    "#             min_length = min(len(raw_signal), len(noise_signal), target_length)\n",
    "#             raw_signal_cut = raw_signal[:min_length]\n",
    "#             noise_signal_cut = noise_signal[:min_length]\n",
    "            \n",
    "#             if min_length < target_length:\n",
    "#                 raw_signal_cut = np.pad(raw_signal_cut, (0, target_length - min_length), 'constant')\n",
    "#                 noise_signal_cut = np.pad(noise_signal_cut, (0, target_length - min_length), 'constant')\n",
    "            \n",
    "#             raw_signals_dict[noise_type].append(raw_signal_cut)\n",
    "            \n",
    "#             for snr in snr_levels:\n",
    "#                 noisy_signal = add_noise(raw_signal_cut, noise_signal_cut, snr)\n",
    "#                 noisy_signals_dict[noise_type][snr].append(noisy_signal)\n",
    "    \n",
    "#     return raw_signals_dict, noisy_signals_dict\n",
    "\n",
    "# # Select records and noise types for the experiment\n",
    "# records = ['103', '105', '111', '116', '122', '205', '213', '219', '223', '230']\n",
    "# noise_types = ['bw', 'em', 'ma']\n",
    "# combined_noise_types = ['em+bw', 'ma+bw', 'ma+em', 'ma+em+bw']\n",
    "# snr_levels = [0, 1, 2, 3, 4, 5]\n",
    "# target_length = 65000\n",
    "\n",
    "# raw_signals_dict, noisy_signals_dict = load_mit_bih_data(records, noise_types, snr_levels, target_length)\n",
    "\n",
    "# # For combined noise types, combine the corresponding noises\n",
    "# for combined_noise in combined_noise_types:\n",
    "#     components = combined_noise.split('+')\n",
    "#     combined_raw_signals = []\n",
    "#     combined_noisy_signals = {snr: [] for snr in snr_levels}\n",
    "    \n",
    "#     for i in range(len(records)):\n",
    "#         combined_signal = np.zeros(target_length)\n",
    "#         for component in components:\n",
    "#             combined_signal += raw_signals_dict[component][i] / len(components)\n",
    "#         combined_raw_signals.append(combined_signal)\n",
    "        \n",
    "#         for snr in snr_levels:\n",
    "#             combined_noise_signal = np.zeros(target_length)\n",
    "#             for component in components:\n",
    "#                 combined_noise_signal += np.array(noisy_signals_dict[component][snr][i]) / len(components)\n",
    "#             combined_noisy_signals[snr].append(combined_noise_signal)\n",
    "    \n",
    "#     raw_signals_dict[combined_noise] = combined_raw_signals\n",
    "#     noisy_signals_dict[combined_noise] = combined_noisy_signals\n",
    "\n",
    "# # Create datasets and dataloaders\n",
    "# datasets = {}\n",
    "# for noise_type in noise_types + combined_noise_types:\n",
    "#     for snr in snr_levels:\n",
    "#         raw_signals_train, raw_signals_test, noisy_signals_train, noisy_signals_test = train_test_split(\n",
    "#             raw_signals_dict[noise_type], noisy_signals_dict[noise_type][snr], test_size=0.2, random_state=42)\n",
    "        \n",
    "#         train_dataset = ECGDataset(raw_signals_train, noisy_signals_train)\n",
    "#         test_dataset = ECGDataset(raw_signals_test, noisy_signals_test)\n",
    "        \n",
    "#         datasets[(noise_type, snr, 'train')] = train_dataset\n",
    "#         datasets[(noise_type, snr, 'test')] = test_dataset\n",
    "\n",
    "# dataloaders = {key: DataLoader(dataset, batch_size=16, shuffle=True) for key, dataset in datasets.items()}\n",
    "\n",
    "# # Define the Generator class with and without input variables z\n",
    "# class GeneratorWithZ(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GeneratorWithZ, self).__init__()\n",
    "#         self.encoder = nn.ModuleList([\n",
    "#             nn.Conv1d(1, 16, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(1024, 2048, kernel_size=4, stride=2, padding=1),\n",
    "#         ])\n",
    "#         self.z_layer = nn.Linear(10, 2048)  # Assuming z is a vector of size 10\n",
    "#         self.decoder = nn.ModuleList([\n",
    "#             nn.ConvTranspose1d(4096, 2048, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(2048, 1024, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(16, 1, kernel_size=4, stride=2, padding=1),\n",
    "#         ])\n",
    "#         self.prelu = nn.PReLU()\n",
    "#         self.skip_connections = nn.ModuleList([\n",
    "#             nn.Conv1d(16, 16, kernel_size=1),\n",
    "#             nn.Conv1d(32, 32, kernel_size=1),\n",
    "#             nn.Conv1d(64, 64, kernel_size=1),\n",
    "#             nn.Conv1d(128, 128, kernel_size=1),\n",
    "#             nn.Conv1d(256, 256, kernel_size=1),\n",
    "#             nn.Conv1d(512, 512, kernel_size=1),\n",
    "#             nn.Conv1d(1024, 1024, kernel_size=1),\n",
    "#         ])\n",
    "\n",
    "#     def forward(self, x, z):\n",
    "#         encodings = []\n",
    "#         for layer in self.encoder:\n",
    "#             x = layer(x)\n",
    "#             x = self.prelu(x)\n",
    "#             encodings.append(x)\n",
    "        \n",
    "#         z = self.prelu(self.z_layer(z)).unsqueeze(2).repeat(1, 1, x.size(2))\n",
    "#         x = torch.cat((x, z), dim=1)\n",
    "        \n",
    "#         for i, layer in enumerate(self.decoder):\n",
    "#             x = layer(x)\n",
    "#             x = self.prelu(x)\n",
    "#             if i < len(self.skip_connections):\n",
    "#                 skip_x = self.skip_connections[-(i+1)](encodings[-(i+1)])\n",
    "#                 if x.size(2) != skip_x.size(2):\n",
    "#                     diff = skip_x.size(2) - x.size(2)\n",
    "#                     x = F.pad(x, (diff // 2, diff - diff // 2))\n",
    "#                 x += skip_x\n",
    "#         return x\n",
    "\n",
    "# class GeneratorWithoutZ(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GeneratorWithoutZ, self).__init__()\n",
    "#         self.encoder = nn.ModuleList([\n",
    "#             nn.Conv1d(1, 16, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Conv1d(1024, 2048, kernel_size=4, stride=2, padding=1),\n",
    "#         ])\n",
    "#         self.decoder = nn.ModuleList([\n",
    "#             nn.ConvTranspose1d(2048, 1024, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ConvTranspose1d(16, 1, kernel_size=4, stride=2, padding=1),\n",
    "#         ])\n",
    "#         self.prelu = nn.PReLU()\n",
    "#         self.skip_connections = nn.ModuleList([\n",
    "#             nn.Conv1d(16, 16, kernel_size=1),\n",
    "#             nn.Conv1d(32, 32, kernel_size=1),\n",
    "#             nn.Conv1d(64, 64, kernel_size=1),\n",
    "#             nn.Conv1d(128, 128, kernel_size=1),\n",
    "#             nn.Conv1d(256, 256, kernel_size=1),\n",
    "#             nn.Conv1d(512, 512, kernel_size=1),\n",
    "#             nn.Conv1d(1024, 1024, kernel_size=1),\n",
    "#         ])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         encodings = []\n",
    "#         for layer in self.encoder:\n",
    "#             x = layer(x)\n",
    "#             x = self.prelu(x)\n",
    "#             encodings.append(x)\n",
    "        \n",
    "#         for i, layer in enumerate(self.decoder):\n",
    "#             x = layer(x)\n",
    "#             x = self.prelu(x)\n",
    "#             if i < len(self.skip_connections):\n",
    "#                 skip_x = self.skip_connections[-i-1](encodings[-i-1])\n",
    "#                 if x.size(2) != skip_x.size(2):\n",
    "#                     diff = skip_x.size(2) - x.size(2)\n",
    "#                     x = F.pad(x, (diff // 2, diff - diff // 2))\n",
    "#                 x += skip_x\n",
    "#         return x\n",
    "\n",
    "# # Define the Discriminator class\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.main = nn.Sequential(\n",
    "#             nn.Conv1d(2, 64, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv1d(512, 1, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.main(x).view(x.size(0), -1)\n",
    "\n",
    "# # Define the calculate_snr function\n",
    "# def calculate_snr(original, denoised):\n",
    "#     noise = original - denoised\n",
    "#     snr = 10 * np.log10(np.sum(original ** 2) / np.sum(noise ** 2))\n",
    "#     return snr\n",
    "\n",
    "# def calculate_rmse(original, denoised):\n",
    "#     mse = np.mean((original - denoised) ** 2)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     return rmse\n",
    "\n",
    "# def train(generator, discriminator, dataloaders, num_epochs=100, lr=0.0001, use_z=False):\n",
    "#     criterion = nn.BCELoss()\n",
    "#     optimizer_G = torch.optim.RMSprop(generator.parameters(), lr=lr)\n",
    "#     optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=lr)\n",
    "    \n",
    "#     results = {'Noise_Type': [], 'SNR_Level': [], 'Epoch': [], 'Batch': [], 'D_loss': [], 'G_loss': [], 'SNR': [], 'RMSE': []}\n",
    "    \n",
    "#     for (noise_type, snr, phase), dataloader in dataloaders.items():\n",
    "#         for epoch in range(num_epochs):\n",
    "#             for i, (raw_signals, noisy_signals) in enumerate(dataloader):\n",
    "#                 batch_size = raw_signals.size(0)\n",
    "                \n",
    "#                 # Ensure the signals have the same length\n",
    "#                 min_length = min(raw_signals.shape[-1], noisy_signals.shape[-1])\n",
    "#                 raw_signals = raw_signals[:, :min_length]\n",
    "#                 noisy_signals = noisy_signals[:, :min_length]\n",
    "\n",
    "#                 # Denoise the noisy signals\n",
    "#                 noisy_signals = noisy_signals.unsqueeze(1)  # Add channel dimension\n",
    "#                 raw_signals = raw_signals.unsqueeze(1)\n",
    "                \n",
    "#                 # Create random z\n",
    "#                 z = torch.randn(batch_size, 10) if use_z else None\n",
    "\n",
    "#                 # Train Generator\n",
    "#                 optimizer_G.zero_grad()\n",
    "#                 if use_z:\n",
    "#                     gen_signals = generator(noisy_signals, z)\n",
    "#                 else:\n",
    "#                     gen_signals = generator(noisy_signals)\n",
    "                \n",
    "#                 # Update valid and fake labels to match the discriminator output size\n",
    "#                 disc_output_size = discriminator(torch.cat((gen_signals, noisy_signals), 1)).size()\n",
    "#                 valid = torch.ones(disc_output_size).to(gen_signals.device)\n",
    "#                 fake = torch.zeros(disc_output_size).to(gen_signals.device)\n",
    "                \n",
    "#                 g_loss = criterion(discriminator(torch.cat((gen_signals, noisy_signals), 1)), valid)\n",
    "#                 g_loss.backward()\n",
    "#                 optimizer_G.step()\n",
    "\n",
    "#                 # Train Discriminator\n",
    "#                 optimizer_D.zero_grad()\n",
    "#                 real_loss = criterion(discriminator(torch.cat((raw_signals, noisy_signals), 1)), valid)\n",
    "#                 fake_loss = criterion(discriminator(torch.cat((gen_signals.detach(), noisy_signals), 1)), fake)\n",
    "#                 d_loss = (real_loss + fake_loss) / 2\n",
    "#                 d_loss.backward()\n",
    "#                 optimizer_D.step()\n",
    "                \n",
    "#                 # Calculate SNR and RMSE\n",
    "#                 snr_value = calculate_snr(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "#                 rmse_value = calculate_rmse(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "\n",
    "#                 # Store results\n",
    "#                 results['Noise_Type'].append(noise_type)\n",
    "#                 results['SNR_Level'].append(snr)\n",
    "#                 results['Epoch'].append(epoch + 1)\n",
    "#                 results['Batch'].append(i + 1)\n",
    "#                 results['D_loss'].append(d_loss.item())\n",
    "#                 results['G_loss'].append(g_loss.item())\n",
    "#                 results['SNR'].append(snr_value)\n",
    "#                 results['RMSE'].append(rmse_value)\n",
    "                \n",
    "#                 print(f\"[{noise_type} SNR {snr}] [Epoch {epoch + 1}/{num_epochs}] [Batch {i + 1}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [SNR: {snr_value}] [RMSE: {rmse_value}]\")\n",
    "\n",
    "#     return results\n",
    "\n",
    "# # Initialize models\n",
    "# generator_with_z = GeneratorWithZ()\n",
    "# generator_without_z = GeneratorWithoutZ()\n",
    "# discriminator = Discriminator()\n",
    "\n",
    "# # Train the models and collect results\n",
    "# results_with_z = train(generator_with_z, discriminator, dataloaders, num_epochs=20, lr=0.0001, use_z=True)\n",
    "# results_without_z = train(generator_without_z, discriminator, dataloaders, num_epochs=20, lr=0.0001, use_z=False)\n",
    "\n",
    "# # Create DataFrames to display results\n",
    "# df_results_with_z = pd.DataFrame(results_with_z)\n",
    "# df_results_without_z = pd.DataFrame(results_without_z)\n",
    "\n",
    "# # Plotting the results\n",
    "# avg_snr_with_z = df_results_with_z.groupby('SNR_Level')['SNR'].mean()\n",
    "# avg_rmse_with_z = df_results_with_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "# avg_snr_without_z = df_results_without_z.groupby('SNR_Level')['SNR'].mean()\n",
    "# avg_rmse_without_z = df_results_without_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(snr_levels, avg_snr_with_z, label='With z')\n",
    "# plt.plot(snr_levels, avg_snr_without_z, label='Without z')\n",
    "# plt.xlabel('SNR (dB)')\n",
    "# plt.ylabel('Average SNR (dB)')\n",
    "# plt.title('SNR vs Average SNR')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(snr_levels, avg_rmse_with_z, label='With z')\n",
    "# plt.plot(snr_levels, avg_rmse_without_z, label='Without z')\n",
    "# plt.xlabel('SNR (dB)')\n",
    "# plt.ylabel('Average RMSE')\n",
    "# plt.title('SNR vs Average RMSE')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0409b79-93c6-4176-ad28-f155bf7758c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6913185119628906] [G loss: 0.7053751349449158] [SNR: 0.9412021189928055] [RMSE: 0.6012424826622009]\n",
      "[bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6911393404006958] [G loss: 0.705209493637085] [SNR: 0.9413871914148331] [RMSE: 0.601229727268219]\n",
      "[bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6909600496292114] [G loss: 0.7050558924674988] [SNR: 0.941583514213562] [RMSE: 0.6012163758277893]\n",
      "[bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.690780758857727] [G loss: 0.7049150466918945] [SNR: 0.9417656809091568] [RMSE: 0.6012035012245178]\n",
      "[bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.690601110458374] [G loss: 0.7047874927520752] [SNR: 0.9419690817594528] [RMSE: 0.6011896133422852]\n",
      "[bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6904205083847046] [G loss: 0.7046741247177124] [SNR: 0.9421636909246445] [RMSE: 0.6011759638786316]\n",
      "[em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6903332471847534] [G loss: 0.7046830654144287] [SNR: 0.9423695504665375] [RMSE: 0.6011618971824646]\n",
      "[em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6901447772979736] [G loss: 0.7045344114303589] [SNR: 0.9425808489322662] [RMSE: 0.6011471748352051]\n",
      "[em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6899573802947998] [G loss: 0.7043871879577637] [SNR: 0.9427937865257263] [RMSE: 0.6011323928833008]\n",
      "[em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6897706985473633] [G loss: 0.7042522430419922] [SNR: 0.9430112689733505] [RMSE: 0.6011173129081726]\n",
      "[em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6895837783813477] [G loss: 0.7041344046592712] [SNR: 0.9432350099086761] [RMSE: 0.6011018753051758]\n",
      "[em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6893960237503052] [G loss: 0.7040354013442993] [SNR: 0.9434708207845688] [RMSE: 0.6010856032371521]\n",
      "[ma SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.689333438873291] [G loss: 0.7040660977363586] [SNR: 0.9436974674463272] [RMSE: 0.6010696291923523]\n",
      "[ma SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6891366243362427] [G loss: 0.7039464116096497] [SNR: 0.943944975733757] [RMSE: 0.6010528802871704]\n",
      "[ma SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6889399290084839] [G loss: 0.7038330435752869] [SNR: 0.9441807121038437] [RMSE: 0.6010364890098572]\n",
      "[ma SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.688742458820343] [G loss: 0.7037338614463806] [SNR: 0.9444194287061691] [RMSE: 0.6010197997093201]\n",
      "[ma SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6885434985160828] [G loss: 0.7036526799201965] [SNR: 0.9446709603071213] [RMSE: 0.6010023951530457]\n",
      "[ma SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6883424520492554] [G loss: 0.703589677810669] [SNR: 0.9449291974306107] [RMSE: 0.6009846329689026]\n",
      "[em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6882166862487793] [G loss: 0.7035794854164124] [SNR: 0.9451957792043686] [RMSE: 0.6009661555290222]\n",
      "[em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6880061030387878] [G loss: 0.7035205960273743] [SNR: 0.9454572945833206] [RMSE: 0.6009481549263]\n",
      "[em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6877950429916382] [G loss: 0.703467845916748] [SNR: 0.945727527141571] [RMSE: 0.600929319858551]\n",
      "[em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6875829696655273] [G loss: 0.7034260630607605] [SNR: 0.9460044652223587] [RMSE: 0.6009101867675781]\n",
      "[em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6873694062232971] [G loss: 0.7033972144126892] [SNR: 0.9462838619947433] [RMSE: 0.60089111328125]\n",
      "[em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6871541738510132] [G loss: 0.703380286693573] [SNR: 0.9465660899877548] [RMSE: 0.6008715033531189]\n",
      "[ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6871237754821777] [G loss: 0.7034308314323425] [SNR: 0.9468488395214081] [RMSE: 0.6008517742156982]\n",
      "[ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6868900060653687] [G loss: 0.7033873200416565] [SNR: 0.9471410512924194] [RMSE: 0.6008315086364746]\n",
      "[ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6866574287414551] [G loss: 0.7033411860466003] [SNR: 0.9474261850118637] [RMSE: 0.600811779499054]\n",
      "[ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.686424970626831] [G loss: 0.7033026218414307] [SNR: 0.9477271139621735] [RMSE: 0.6007912158966064]\n",
      "[ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.686191976070404] [G loss: 0.703276515007019] [SNR: 0.9480172395706177] [RMSE: 0.6007707715034485]\n",
      "[ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6859577894210815] [G loss: 0.7032645344734192] [SNR: 0.9483293443918228] [RMSE: 0.6007494926452637]\n",
      "[ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6859878301620483] [G loss: 0.7033074498176575] [SNR: 0.9486281126737595] [RMSE: 0.6007286310195923]\n",
      "[ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6857271194458008] [G loss: 0.7032700181007385] [SNR: 0.9489373117685318] [RMSE: 0.6007074117660522]\n",
      "[ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6854690313339233] [G loss: 0.7032305598258972] [SNR: 0.9492539614439011] [RMSE: 0.6006855964660645]\n",
      "[ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6852127313613892] [G loss: 0.703200101852417] [SNR: 0.9495676308870316] [RMSE: 0.6006636619567871]\n",
      "[ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6849571466445923] [G loss: 0.7031837701797485] [SNR: 0.9498867392539978] [RMSE: 0.6006414294242859]\n",
      "[ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6847014427185059] [G loss: 0.7031823992729187] [SNR: 0.9502162039279938] [RMSE: 0.6006188988685608]\n",
      "[ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6846339702606201] [G loss: 0.7032403945922852] [SNR: 0.9505531191825867] [RMSE: 0.6005957722663879]\n",
      "[ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6843574047088623] [G loss: 0.7032313346862793] [SNR: 0.9508825838565826] [RMSE: 0.6005727648735046]\n",
      "[ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6840834617614746] [G loss: 0.7032247185707092] [SNR: 0.9512156993150711] [RMSE: 0.6005497574806213]\n",
      "[ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6838107109069824] [G loss: 0.7032282948493958] [SNR: 0.9515579789876938] [RMSE: 0.6005262136459351]\n",
      "[ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6835387945175171] [G loss: 0.703244686126709] [SNR: 0.951903909444809] [RMSE: 0.6005021333694458]\n",
      "[ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6832669973373413] [G loss: 0.7032740712165833] [SNR: 0.9522515535354614] [RMSE: 0.6004783511161804]\n",
      "[bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6790487170219421] [G loss: 0.7127644419670105] [SNR: -2.4957163631916046] [RMSE: 0.8930909633636475]\n",
      "[bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6785167455673218] [G loss: 0.7129626274108887] [SNR: -2.4957485496997833] [RMSE: 0.8930940628051758]\n",
      "[bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6779956221580505] [G loss: 0.7131686210632324] [SNR: -2.495764195919037] [RMSE: 0.8930957317352295]\n",
      "[bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.677484393119812] [G loss: 0.7133817672729492] [SNR: -2.4957624077796936] [RMSE: 0.8930957317352295]\n",
      "[bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6769825220108032] [G loss: 0.7136022448539734] [SNR: -2.4957476556301117] [RMSE: 0.8930942416191101]\n",
      "[bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6764885783195496] [G loss: 0.7138301730155945] [SNR: -2.495724707841873] [RMSE: 0.89309161901474]\n",
      "[em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6768852472305298] [G loss: 0.713771402835846] [SNR: -2.4956902861595154] [RMSE: 0.8930882215499878]\n",
      "[em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6763123273849487] [G loss: 0.7139892578125] [SNR: -2.4956294894218445] [RMSE: 0.8930819034576416]\n",
      "[em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6757500171661377] [G loss: 0.7142103314399719] [SNR: -2.495560497045517] [RMSE: 0.8930746912956238]\n",
      "[em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6751976609230042] [G loss: 0.7144421935081482] [SNR: -2.495487481355667] [RMSE: 0.8930672407150269]\n",
      "[em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6746541261672974] [G loss: 0.7146883010864258] [SNR: -2.4953991174697876] [RMSE: 0.8930580615997314]\n",
      "[em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6741179823875427] [G loss: 0.7149491310119629] [SNR: -2.4953071773052216] [RMSE: 0.8930487632751465]\n",
      "[ma SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6742856502532959] [G loss: 0.715047299861908] [SNR: -2.495209276676178] [RMSE: 0.8930386900901794]\n",
      "[ma SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6737016439437866] [G loss: 0.7153085470199585] [SNR: -2.495095580816269] [RMSE: 0.893027126789093]\n",
      "[ma SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6731258034706116] [G loss: 0.7155752778053284] [SNR: -2.494956851005554] [RMSE: 0.8930130004882812]\n",
      "[ma SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6725570559501648] [G loss: 0.7158544063568115] [SNR: -2.4948184192180634] [RMSE: 0.8929985165596008]\n",
      "[ma SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6719945669174194] [G loss: 0.7161483764648438] [SNR: -2.4946731328964233] [RMSE: 0.8929834961891174]\n",
      "[ma SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6714376211166382] [G loss: 0.716457188129425] [SNR: -2.49451220035553] [RMSE: 0.8929668664932251]\n",
      "[em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6712785959243774] [G loss: 0.7165715098381042] [SNR: -2.494351714849472] [RMSE: 0.892950713634491]\n",
      "[em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6706851720809937] [G loss: 0.7169146537780762] [SNR: -2.4941834807395935] [RMSE: 0.8929333090782166]\n",
      "[em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6701004505157471] [G loss: 0.71726393699646] [SNR: -2.4940042197704315] [RMSE: 0.8929146528244019]\n",
      "[em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6695231795310974] [G loss: 0.7176218032836914] [SNR: -2.4938221275806427] [RMSE: 0.8928961753845215]\n",
      "[em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6689521670341492] [G loss: 0.7179886698722839] [SNR: -2.493630051612854] [RMSE: 0.8928760290145874]\n",
      "[em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6683864593505859] [G loss: 0.7183637022972107] [SNR: -2.4934254586696625] [RMSE: 0.8928552269935608]\n",
      "[ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6684858798980713] [G loss: 0.7184681296348572] [SNR: -2.4932140111923218] [RMSE: 0.8928337693214417]\n",
      "[ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6678481101989746] [G loss: 0.7188633680343628] [SNR: -2.4929939210414886] [RMSE: 0.8928109407424927]\n",
      "[ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6672213077545166] [G loss: 0.7192567586898804] [SNR: -2.4927502870559692] [RMSE: 0.8927861452102661]\n",
      "[ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6666041612625122] [G loss: 0.7196547985076904] [SNR: -2.492513209581375] [RMSE: 0.8927614688873291]\n",
      "[ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6659952402114868] [G loss: 0.7200603485107422] [SNR: -2.4922549724578857] [RMSE: 0.8927351832389832]\n",
      "[ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6653928160667419] [G loss: 0.7204751372337341] [SNR: -2.491993010044098] [RMSE: 0.892707884311676]\n",
      "[ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.66557776927948] [G loss: 0.7205011248588562] [SNR: -2.491721510887146] [RMSE: 0.8926804065704346]\n",
      "[ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.664885401725769] [G loss: 0.7209503650665283] [SNR: -2.4914444983005524] [RMSE: 0.8926517367362976]\n",
      "[ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6642059683799744] [G loss: 0.7213972806930542] [SNR: -2.4911536276340485] [RMSE: 0.8926218748092651]\n",
      "[ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6635379791259766] [G loss: 0.7218491435050964] [SNR: -2.4908624589443207] [RMSE: 0.8925914764404297]\n",
      "[ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6628793478012085] [G loss: 0.7223102450370789] [SNR: -2.4905459582805634] [RMSE: 0.8925591111183167]\n",
      "[ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6622285842895508] [G loss: 0.7227811813354492] [SNR: -2.490231841802597] [RMSE: 0.892527163028717]\n",
      "[ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6621042490005493] [G loss: 0.7230085730552673] [SNR: -2.4899157881736755] [RMSE: 0.8924944996833801]\n",
      "[ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6613950729370117] [G loss: 0.7235106825828552] [SNR: -2.489580512046814] [RMSE: 0.8924602270126343]\n",
      "[ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.660698652267456] [G loss: 0.7240118384361267] [SNR: -2.4892480671405792] [RMSE: 0.8924261331558228]\n",
      "[ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6600127220153809] [G loss: 0.724518358707428] [SNR: -2.4889005720615387] [RMSE: 0.8923907279968262]\n",
      "[ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6593348979949951] [G loss: 0.7250329852104187] [SNR: -2.488563507795334] [RMSE: 0.8923552632331848]\n",
      "[ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.658663272857666] [G loss: 0.7255569100379944] [SNR: -2.488206773996353] [RMSE: 0.8923189043998718]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wfdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ECGDataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, raw_signals, noisy_signals):\n",
    "        self.raw_signals = raw_signals\n",
    "        self.noisy_signals = noisy_signals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_signal = self.raw_signals[idx]\n",
    "        noisy_signal = self.noisy_signals[idx]\n",
    "        return torch.tensor(raw_signal, dtype=torch.float32), torch.tensor(noisy_signal, dtype=torch.float32)\n",
    "\n",
    "# Define the add_noise function\n",
    "def add_noise(signal, noise, snr):\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    factor = (signal_power / noise_power) / (10 ** (snr / 10))\n",
    "    noisy_signal = signal + noise * np.sqrt(factor)\n",
    "    return noisy_signal\n",
    "\n",
    "# Define the load_mit_bih_data function\n",
    "def load_mit_bih_data(records, noise_type, snr_levels, target_length=650000):\n",
    "    raw_signals = []\n",
    "    noisy_signals_dict = {snr: [] for snr in snr_levels}\n",
    "    \n",
    "    for record in records:\n",
    "        raw_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-arrhythmia-database-1.0.0/{record}')\n",
    "        raw_signal = raw_record.p_signal[:, 0]  # Use the first channel for simplicity\n",
    "        \n",
    "        # Load noise and add it to the raw signal\n",
    "        noise_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-noise-stress-test-database-1.0.0/{noise_type}')\n",
    "        noise_signal = noise_record.p_signal[:, 0]\n",
    "        \n",
    "        # Ensure the signals are of the same length\n",
    "        min_length = min(len(raw_signal), len(noise_signal), target_length)\n",
    "        raw_signal = raw_signal[:min_length]\n",
    "        noise_signal = noise_signal[:min_length]\n",
    "        \n",
    "        # Pad signals to target length\n",
    "        if min_length < target_length:\n",
    "            raw_signal = np.pad(raw_signal, (0, target_length - min_length), 'constant')\n",
    "            noise_signal = np.pad(noise_signal, (0, target_length - min_length), 'constant')\n",
    "        \n",
    "        raw_signals.append(raw_signal)\n",
    "        \n",
    "        for snr in snr_levels:\n",
    "            noisy_signal = add_noise(raw_signal, noise_signal, snr)\n",
    "            noisy_signals_dict[snr].append(noisy_signal)\n",
    "    \n",
    "    return np.array(raw_signals), {snr: np.array(noisy_signals_dict[snr]) for snr in snr_levels}\n",
    "\n",
    "# Select records and noise types for the experiment\n",
    "records = ['103', '105', '111', '116', '122', '205', '213', '219', '223', '230']\n",
    "noise_types = ['bw', 'em', 'ma']\n",
    "combined_noise_types = ['em+bw', 'ma+bw', 'ma+em', 'ma+em+bw']\n",
    "snr_levels = [0, 1, 2, 3, 4, 5]\n",
    "target_length = 649984\n",
    "\n",
    "raw_signals, noisy_signals_dict = {}, {}\n",
    "for noise_type in noise_types:\n",
    "    raw_signals[noise_type], noisy_signals_dict[noise_type] = load_mit_bih_data(records, noise_type, snr_levels, target_length)\n",
    "\n",
    "# For combined noise types, combine the corresponding noises\n",
    "for combined_noise in combined_noise_types:\n",
    "    components = combined_noise.split('+')\n",
    "    combined_raw_signals, combined_noisy_signals = [], {snr: [] for snr in snr_levels}\n",
    "    for i in range(len(records)):\n",
    "        combined_signal = np.zeros(target_length)\n",
    "        for component in components:\n",
    "            raw_signal = raw_signals[component][i]\n",
    "            combined_signal += raw_signal / len(components)  # Average the signals\n",
    "        combined_raw_signals.append(combined_signal)\n",
    "        for snr in snr_levels:\n",
    "            combined_noise_signal = np.zeros(target_length)\n",
    "            for component in components:\n",
    "                noise_signal = noisy_signals_dict[component][snr][i]\n",
    "                combined_noise_signal += noise_signal / len(components)  # Average the noises\n",
    "            combined_noisy_signals[snr].append(combined_noise_signal)\n",
    "    raw_signals[combined_noise] = np.array(combined_raw_signals)\n",
    "    noisy_signals_dict[combined_noise] = {snr: np.array(combined_noisy_signals[snr]) for snr in snr_levels}\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "datasets = {}\n",
    "for noise_type in noise_types + combined_noise_types:\n",
    "    for snr in snr_levels:\n",
    "        datasets[(noise_type, snr)] = ECGDataset(raw_signals[noise_type], noisy_signals_dict[noise_type][snr])\n",
    "\n",
    "dataloaders = {key: DataLoader(dataset, batch_size=16, shuffle=True) for key, dataset in datasets.items()}\n",
    "\n",
    "# Define the Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, use_z=True):\n",
    "        super(Generator, self).__init__()\n",
    "        self.use_z = use_z\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(8, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.decoder_with_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(2048, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder_without_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        if self.use_z:\n",
    "            z = torch.randn_like(encoded)\n",
    "            encoded = torch.cat((encoded, z), 1)\n",
    "            decoded = self.decoder_with_z(encoded)\n",
    "        else:\n",
    "            decoded = self.decoder_without_z(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define the Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(x.size(0), -1)\n",
    "\n",
    "# Define the calculate_snr function\n",
    "def calculate_snr(original, denoised):\n",
    "    noise = original - denoised\n",
    "    snr = 10 * np.log10(np.sum(original ** 2) / np.sum(noise ** 2))\n",
    "    return snr\n",
    "\n",
    "def calculate_rmse(original, denoised):\n",
    "    mse = np.mean((original - denoised) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def train(generator, discriminator, dataloaders, num_epochs=100, lr=0.000005):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    results = {'Noise_Type': [], 'SNR_Level': [], 'Epoch': [], 'Batch': [], 'D_loss': [], 'G_loss': [], 'SNR': [], 'RMSE': []}\n",
    "    \n",
    "    for (noise_type, snr), dataloader in dataloaders.items():\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (raw_signals, noisy_signals) in enumerate(dataloader):\n",
    "                batch_size = raw_signals.size(0)\n",
    "                \n",
    "                # Ensure the signals have the same length\n",
    "                min_length = min(raw_signals.shape[-1], noisy_signals.shape[-1])\n",
    "                raw_signals = raw_signals[:, :min_length]\n",
    "                noisy_signals = noisy_signals[:, :min_length]\n",
    "\n",
    "                # Denoise the noisy signals\n",
    "                noisy_signals = noisy_signals.unsqueeze(1)  # Add channel dimension\n",
    "                raw_signals = raw_signals.unsqueeze(1)\n",
    "\n",
    "                # Train Generator\n",
    "                optimizer_G.zero_grad()\n",
    "                gen_signals = generator(noisy_signals)\n",
    "                \n",
    "                # Ensure the generated signals have the same length as the input signals\n",
    "                if gen_signals.shape[-1] != noisy_signals.shape[-1]:\n",
    "                    gen_signals = torch.nn.functional.pad(gen_signals, (0, noisy_signals.shape[-1] - gen_signals.shape[-1]))\n",
    "\n",
    "                # Update valid and fake labels to match the discriminator output size\n",
    "                disc_output_size = discriminator(torch.cat((gen_signals, noisy_signals), 1)).size()\n",
    "                valid = torch.ones(disc_output_size).to(gen_signals.device)\n",
    "                fake = torch.zeros(disc_output_size).to(gen_signals.device)\n",
    "                \n",
    "                g_loss = criterion(discriminator(torch.cat((gen_signals, noisy_signals), 1)), valid)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # Train Discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(torch.cat((raw_signals, noisy_signals), 1)), valid)\n",
    "                fake_loss = criterion(discriminator(torch.cat((gen_signals.detach(), noisy_signals), 1)), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # Calculate SNR and RMSE\n",
    "                snr_value = calculate_snr(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "                rmse_value = calculate_rmse(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "\n",
    "                # Store results\n",
    "                results['Noise_Type'].append(noise_type)\n",
    "                results['SNR_Level'].append(snr)\n",
    "                results['Epoch'].append(epoch + 1)\n",
    "                results['Batch'].append(i + 1)\n",
    "                results['D_loss'].append(d_loss.item())\n",
    "                results['G_loss'].append(g_loss.item())\n",
    "                results['SNR'].append(snr_value)\n",
    "                results['RMSE'].append(rmse_value)\n",
    "                \n",
    "                print(f\"[{noise_type} SNR {snr}] [Epoch {epoch + 1}/{num_epochs}] [Batch {i + 1}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [SNR: {snr_value}] [RMSE: {rmse_value}]\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initialize models with and without z\n",
    "generator_with_z = Generator(use_z=True)\n",
    "generator_without_z = Generator(use_z=False)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Train the models and collect results for each SNR level\n",
    "results_with_z = train(generator_with_z, discriminator, dataloaders, num_epochs=1)  # Adjusted for quick testing\n",
    "results_without_z = train(generator_without_z, discriminator, dataloaders, num_epochs=1)  # Adjusted for quick testing\n",
    "\n",
    "# Create DataFrames to display results\n",
    "df_results_with_z = pd.DataFrame(results_with_z)\n",
    "df_results_without_z = pd.DataFrame(results_without_z)\n",
    "\n",
    "# Average SNR and RMSE for each SNR level\n",
    "avg_snr_with_z = df_results_with_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_with_z = df_results_with_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "avg_snr_without_z = df_results_without_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_without_z = df_results_without_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "# Plot SNR vs Average SNR\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_snr_with_z.index, avg_snr_with_z.values, label='With z')\n",
    "plt.plot(avg_snr_without_z.index, avg_snr_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Average SNR (dB)')\n",
    "plt.title('SNR vs Average SNR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot SNR vs RMSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_rmse_with_z.index, avg_rmse_with_z.values, label='With z')\n",
    "plt.plot(avg_rmse_without_z.index, avg_rmse_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('SNR vs RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display the DataFrames as a table\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Denoising Results with z\", dataframe=df_results_with_z)\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Denoising Results without z\", dataframe=df_results_without_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e24ab-a212-4960-9fe1-ba69c62b12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6926300525665283] [G loss: 0.686773955821991] [SNR: 1.2358668446540833] [RMSE: 0.5811878442764282]\n",
      "[bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6789685487747192] [G loss: 0.68644779920578] [SNR: 1.2510575354099274] [RMSE: 0.5801721215248108]\n",
      "[bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6581389307975769] [G loss: 0.6894474029541016] [SNR: 1.2809893488883972] [RMSE: 0.5781766176223755]\n",
      "[bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6229909658432007] [G loss: 0.7185783982276917] [SNR: 1.3263104856014252] [RMSE: 0.5751673579216003]\n",
      "[bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.5710328817367554] [G loss: 0.787251889705658] [SNR: 1.4014048874378204] [RMSE: 0.570216178894043]\n",
      "[bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.5183911323547363] [G loss: 0.8633074164390564] [SNR: 1.5446023643016815] [RMSE: 0.5608925223350525]\n",
      "[em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.604749858379364] [G loss: 1.0012465715408325] [SNR: 1.8322236835956573] [RMSE: 0.5426235198974609]\n",
      "[em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 1.4462296962738037] [G loss: 0.1251147985458374] [SNR: -0.2842377871274948] [RMSE: 0.6923436522483826]\n",
      "[em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.9106392860412598] [G loss: 0.8324608206748962] [SNR: -1.328614056110382] [RMSE: 0.7808014750480652]\n",
      "[em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.7390133738517761] [G loss: 1.5089517831802368] [SNR: -1.330605000257492] [RMSE: 0.780980110168457]\n",
      "[em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6212196946144104] [G loss: 1.2840828895568848] [SNR: -1.3306261599063873] [RMSE: 0.7809820771217346]\n",
      "[em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.5581730604171753] [G loss: 1.077001690864563] [SNR: -1.3306355476379395] [RMSE: 0.7809829115867615]\n",
      "[ma SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.5110910534858704] [G loss: 0.9969670176506042] [SNR: -1.3306355476379395] [RMSE: 0.7809829711914062]\n",
      "[ma SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.45281052589416504] [G loss: 1.062780737876892] [SNR: -1.3306321203708649] [RMSE: 0.7809828519821167]\n",
      "[ma SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.3872062861919403] [G loss: 1.2716480493545532] [SNR: -1.3306327164173126] [RMSE: 0.7809832096099854]\n",
      "[ma SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.3296318054199219] [G loss: 1.5202528238296509] [SNR: -1.3306362926959991] [RMSE: 0.780983030796051]\n",
      "[ma SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.2855147421360016] [G loss: 1.7463949918746948] [SNR: -1.3306370377540588] [RMSE: 0.7809831500053406]\n",
      "[ma SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.25490787625312805] [G loss: 1.9890302419662476] [SNR: -1.330639123916626] [RMSE: 0.7809831500053406]\n",
      "[em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.2506084144115448] [G loss: 2.144163131713867] [SNR: -1.3306359946727753] [RMSE: 0.7809832096099854]\n",
      "[em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.23874041438102722] [G loss: 2.496493339538574] [SNR: -1.3306380808353424] [RMSE: 0.7809830904006958]\n",
      "[em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.25417137145996094] [G loss: 1.583716869354248] [SNR: -1.3306373357772827] [RMSE: 0.7809830904006958]\n",
      "[em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.29357054829597473] [G loss: 3.296377658843994] [SNR: -1.3306359946727753] [RMSE: 0.7809831500053406]\n",
      "[em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.22203414142131805] [G loss: 2.5925240516662598] [SNR: -1.3306362926959991] [RMSE: 0.7809830904006958]\n",
      "[em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.22585195302963257] [G loss: 1.7072213888168335] [SNR: -1.3306458294391632] [RMSE: 0.7809835076332092]\n",
      "[ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.22050824761390686] [G loss: 2.3239967823028564] [SNR: -1.330636590719223] [RMSE: 0.7809832096099854]\n",
      "[ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.2198956310749054] [G loss: 2.623260259628296] [SNR: -1.3306380808353424] [RMSE: 0.7809830904006958]\n",
      "[ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.20164623856544495] [G loss: 2.377376079559326] [SNR: -1.3306345045566559] [RMSE: 0.780983030796051]\n",
      "[ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.19557307660579681] [G loss: 2.122230052947998] [SNR: -1.3306359946727753] [RMSE: 0.7809832096099854]\n",
      "[ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.18382245302200317] [G loss: 2.4222075939178467] [SNR: -1.3306394219398499] [RMSE: 0.7809832096099854]\n",
      "[ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.17458347976207733] [G loss: 2.4557385444641113] [SNR: -1.3306373357772827] [RMSE: 0.780983030796051]\n",
      "[ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.1933899223804474] [G loss: 2.521545648574829] [SNR: -1.3306298851966858] [RMSE: 0.7809828519821167]\n",
      "[ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.19268211722373962] [G loss: 2.8167474269866943] [SNR: -1.3306331634521484] [RMSE: 0.780983030796051]\n",
      "[ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.1788485199213028] [G loss: 2.333314895629883] [SNR: -1.3306362926959991] [RMSE: 0.780983030796051]\n",
      "[ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.1721165031194687] [G loss: 2.628840923309326] [SNR: -1.330634206533432] [RMSE: 0.780983030796051]\n",
      "[ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.16430258750915527] [G loss: 2.492621898651123] [SNR: -1.3306352496147156] [RMSE: 0.7809830904006958]\n",
      "[ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.16511736810207367] [G loss: 2.983365058898926] [SNR: -1.3306313753128052] [RMSE: 0.7809827923774719]\n",
      "[ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.17352107167243958] [G loss: 2.6703457832336426] [SNR: -1.3306321203708649] [RMSE: 0.7809827327728271]\n",
      "[ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.17084529995918274] [G loss: 2.9790639877319336] [SNR: -1.3306362926959991] [RMSE: 0.7809830904006958]\n",
      "[ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.15707671642303467] [G loss: 2.6261422634124756] [SNR: -1.3306359946727753] [RMSE: 0.7809829711914062]\n",
      "[ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.14986202120780945] [G loss: 2.7095909118652344] [SNR: -1.3306383788585663] [RMSE: 0.7809830904006958]\n",
      "[ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.14854805171489716] [G loss: 3.108083963394165] [SNR: -1.330636590719223] [RMSE: 0.780983030796051]\n",
      "[ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.15056556463241577] [G loss: 2.700054168701172] [SNR: -1.3306362926959991] [RMSE: 0.780983030796051]\n",
      "[bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 44.1235466003418] [G loss: 5.620379397441866e-07] [SNR: -2.0550021529197693] [RMSE: 0.8489062786102295]\n",
      "[bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 28.696163177490234] [G loss: 0.00014036535867489874] [SNR: -2.075152099132538] [RMSE: 0.8508781790733337]\n",
      "[bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 10.135220527648926] [G loss: 0.0018463263986632228] [SNR: -2.0990951359272003] [RMSE: 0.8532268404960632]\n",
      "[bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 5.456506252288818] [G loss: 0.008031086064875126] [SNR: -2.1265049278736115] [RMSE: 0.8559234738349915]\n",
      "[bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 3.6044869422912598] [G loss: 0.023774944245815277] [SNR: -2.1575115621089935] [RMSE: 0.8589847087860107]\n",
      "[bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 2.4925856590270996] [G loss: 0.056050803512334824] [SNR: -2.192254066467285] [RMSE: 0.8624274134635925]\n",
      "[em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 1.8307147026062012] [G loss: 0.14016969501972198] [SNR: -2.231397330760956] [RMSE: 0.8663225173950195]\n",
      "[em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 1.295806646347046] [G loss: 0.2294035255908966] [SNR: -2.286643832921982] [RMSE: 0.8718506693840027]\n",
      "[em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.9129621982574463] [G loss: 0.3698708117008209] [SNR: -2.4827711284160614] [RMSE: 0.8917611241340637]\n",
      "[em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6394780874252319] [G loss: 0.5949869751930237] [SNR: -3.556903600692749] [RMSE: 1.0091480016708374]\n",
      "[em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.3478405177593231] [G loss: 1.2276345491409302] [SNR: -6.056375503540039] [RMSE: 1.3456387519836426]\n",
      "[em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.21414251625537872] [G loss: 2.1517856121063232] [SNR: -5.147700905799866] [RMSE: 1.2119783163070679]\n",
      "[ma SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.2156638205051422] [G loss: 2.317405939102173] [SNR: -4.057338237762451] [RMSE: 1.0689977407455444]\n",
      "[ma SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.2781848609447479] [G loss: 1.3941748142242432] [SNR: -4.421708583831787] [RMSE: 1.1147949695587158]\n",
      "[ma SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 1.4553558826446533] [G loss: 0.09353720396757126] [SNR: -3.201013505458832] [RMSE: 0.9686356782913208]\n",
      "[ma SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 1.1435563564300537] [G loss: 0.20035666227340698] [SNR: -3.0873966217041016] [RMSE: 0.9560473561286926]\n",
      "[ma SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.7337061166763306] [G loss: 0.8823068737983704] [SNR: -2.9725760221481323] [RMSE: 0.9434928297996521]\n",
      "[ma SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6794354915618896] [G loss: 1.6977050304412842] [SNR: -2.880672514438629] [RMSE: 0.9335626363754272]\n",
      "[em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6105817556381226] [G loss: 1.6489198207855225] [SNR: -2.7338311076164246] [RMSE: 0.9179127216339111]\n",
      "[em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.5076531767845154] [G loss: 1.2784862518310547] [SNR: -2.614385187625885] [RMSE: 0.9053757190704346]\n",
      "[em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.43837839365005493] [G loss: 1.1816775798797607] [SNR: -2.6065033674240112] [RMSE: 0.9045549035072327]\n",
      "[em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.41586440801620483] [G loss: 1.100341558456421] [SNR: -2.4581775069236755] [RMSE: 0.8892395496368408]\n",
      "[em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.3356994390487671] [G loss: 1.477242112159729] [SNR: -2.4731627106666565] [RMSE: 0.8907748460769653]\n",
      "[em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.26248446106910706] [G loss: 2.064713954925537] [SNR: -2.525719404220581] [RMSE: 0.8961811661720276]\n",
      "[ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.32812249660491943] [G loss: 1.6625560522079468] [SNR: -2.253303825855255] [RMSE: 0.868510365486145]\n",
      "[ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.3369222581386566] [G loss: 1.5705053806304932] [SNR: -2.0188970863819122] [RMSE: 0.8453852534294128]\n",
      "[ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.3126261532306671] [G loss: 2.4936602115631104] [SNR: -1.8347860872745514] [RMSE: 0.8276546001434326]\n",
      "[ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.3586166203022003] [G loss: 1.5706530809402466] [SNR: -1.5135711431503296] [RMSE: 0.7976057529449463]\n",
      "[ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.374332070350647] [G loss: 3.4209611415863037] [SNR: -1.5135715901851654] [RMSE: 0.7976062893867493]\n",
      "[ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.2927733063697815] [G loss: 1.6559264659881592] [SNR: -1.5135733783245087] [RMSE: 0.7976060509681702]\n",
      "[ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.30967065691947937] [G loss: 2.969404697418213] [SNR: -1.5135681629180908] [RMSE: 0.7976057529449463]\n",
      "[ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.2634475529193878] [G loss: 2.3752083778381348] [SNR: -1.5135565400123596] [RMSE: 0.797604501247406]\n",
      "[ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.23891346156597137] [G loss: 2.296185255050659] [SNR: -1.5135186910629272] [RMSE: 0.7976009249687195]\n",
      "[ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.22097891569137573] [G loss: 2.6724438667297363] [SNR: -1.5128380060195923] [RMSE: 0.797538697719574]\n",
      "[ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.2586250305175781] [G loss: 1.9210189580917358] [SNR: -1.3306401669979095] [RMSE: 0.7809830904006958]\n",
      "[ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.2774776518344879] [G loss: 3.634243965148926] [SNR: -1.3306623697280884] [RMSE: 0.780985414981842]\n",
      "[ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.2772822976112366] [G loss: 2.160659074783325] [SNR: -1.330663412809372] [RMSE: 0.7809853553771973]\n",
      "[ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.24600961804389954] [G loss: 3.0740420818328857] [SNR: -1.3306580483913422] [RMSE: 0.7809853553771973]\n",
      "[ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.22584912180900574] [G loss: 2.6056814193725586] [SNR: -1.330663412809372] [RMSE: 0.7809855341911316]\n",
      "[ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.21398206055164337] [G loss: 2.5886034965515137] [SNR: -1.330660879611969] [RMSE: 0.7809853553771973]\n",
      "[ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.20415626466274261] [G loss: 2.8906285762786865] [SNR: -1.3306601345539093] [RMSE: 0.7809852361679077]\n",
      "[ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.19444221258163452] [G loss: 2.6517186164855957] [SNR: -1.3306580483913422] [RMSE: 0.7809853553771973]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wfdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ECGDataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, raw_signals, noisy_signals):\n",
    "        self.raw_signals = raw_signals\n",
    "        self.noisy_signals = noisy_signals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_signal = self.raw_signals[idx]\n",
    "        noisy_signal = self.noisy_signals[idx]\n",
    "        return torch.tensor(raw_signal, dtype=torch.float32), torch.tensor(noisy_signal, dtype=torch.float32)\n",
    "\n",
    "# Define the add_noise function\n",
    "def add_noise(signal, noise, snr):\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    factor = (signal_power / noise_power) / (10 ** (snr / 10))\n",
    "    noisy_signal = signal + noise * np.sqrt(factor)\n",
    "    return noisy_signal\n",
    "\n",
    "# Define the load_mit_bih_data function\n",
    "def load_mit_bih_data(records, noise_type, snr_levels, target_length=650000):\n",
    "    raw_signals = []\n",
    "    noisy_signals_dict = {snr: [] for snr in snr_levels}\n",
    "    \n",
    "    for record in records:\n",
    "        raw_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-arrhythmia-database-1.0.0/{record}')\n",
    "        raw_signal = raw_record.p_signal[:, 0]  # Use the first channel for simplicity\n",
    "        \n",
    "        # Load noise and add it to the raw signal\n",
    "        noise_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-noise-stress-test-database-1.0.0/{noise_type}')\n",
    "        noise_signal = noise_record.p_signal[:, 0]\n",
    "        \n",
    "        # Ensure the signals are of the same length\n",
    "        min_length = min(len(raw_signal), len(noise_signal), target_length)\n",
    "        raw_signal = raw_signal[:min_length]\n",
    "        noise_signal = noise_signal[:min_length]\n",
    "        \n",
    "        # Pad signals to target length\n",
    "        if min_length < target_length:\n",
    "            raw_signal = np.pad(raw_signal, (0, target_length - min_length), 'constant')\n",
    "            noise_signal = np.pad(noise_signal, (0, target_length - min_length), 'constant')\n",
    "        \n",
    "        raw_signals.append(raw_signal)\n",
    "        \n",
    "        for snr in snr_levels:\n",
    "            noisy_signal = add_noise(raw_signal, noise_signal, snr)\n",
    "            noisy_signals_dict[snr].append(noisy_signal)\n",
    "    \n",
    "    return np.array(raw_signals), {snr: np.array(noisy_signals_dict[snr]) for snr in snr_levels}\n",
    "\n",
    "# Select records and noise types for the experiment\n",
    "records = ['103', '105', '111', '116', '122', '205', '213', '219', '223', '230']\n",
    "noise_types = ['bw', 'em', 'ma']\n",
    "combined_noise_types = ['em+bw', 'ma+bw', 'ma+em', 'ma+em+bw']\n",
    "snr_levels = [0, 1, 2, 3, 4, 5]\n",
    "target_length = 649984\n",
    "\n",
    "raw_signals, noisy_signals_dict = {}, {}\n",
    "for noise_type in noise_types:\n",
    "    raw_signals[noise_type], noisy_signals_dict[noise_type] = load_mit_bih_data(records, noise_type, snr_levels, target_length)\n",
    "\n",
    "# For combined noise types, combine the corresponding noises\n",
    "for combined_noise in combined_noise_types:\n",
    "    components = combined_noise.split('+')\n",
    "    combined_raw_signals, combined_noisy_signals = [], {snr: [] for snr in snr_levels}\n",
    "    for i in range(len(records)):\n",
    "        combined_signal = np.zeros(target_length)\n",
    "        for component in components:\n",
    "            raw_signal = raw_signals[component][i]\n",
    "            combined_signal += raw_signal / len(components)  # Average the signals\n",
    "        combined_raw_signals.append(combined_signal)\n",
    "        for snr in snr_levels:\n",
    "            combined_noise_signal = np.zeros(target_length)\n",
    "            for component in components:\n",
    "                noise_signal = noisy_signals_dict[component][snr][i]\n",
    "                combined_noise_signal += noise_signal / len(components)  # Average the noises\n",
    "            combined_noisy_signals[snr].append(combined_noise_signal)\n",
    "    raw_signals[combined_noise] = np.array(combined_raw_signals)\n",
    "    noisy_signals_dict[combined_noise] = {snr: np.array(combined_noisy_signals[snr]) for snr in snr_levels}\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "datasets = {}\n",
    "for noise_type in noise_types + combined_noise_types:\n",
    "    for snr in snr_levels:\n",
    "        datasets[(noise_type, snr)] = ECGDataset(raw_signals[noise_type], noisy_signals_dict[noise_type][snr])\n",
    "\n",
    "dataloaders = {key: DataLoader(dataset, batch_size=16, shuffle=True) for key, dataset in datasets.items()}\n",
    "\n",
    "# Define the Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, use_z=True):\n",
    "        super(Generator, self).__init__()\n",
    "        self.use_z = use_z\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(8, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.decoder_with_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(2048, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder_without_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        if self.use_z:\n",
    "            z = torch.randn_like(encoded)\n",
    "            encoded = torch.cat((encoded, z), 1)\n",
    "            decoded = self.decoder_with_z(encoded)\n",
    "        else:\n",
    "            decoded = self.decoder_without_z(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define the Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(x.size(0), -1)\n",
    "\n",
    "# Define the calculate_snr function\n",
    "def calculate_snr(original, denoised):\n",
    "    noise = original - denoised\n",
    "    snr = 10 * np.log10(np.sum(original ** 2) / np.sum(noise ** 2))\n",
    "    return snr\n",
    "\n",
    "def calculate_rmse(original, denoised):\n",
    "    mse = np.mean((original - denoised) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def train(generator, discriminator, dataloaders, num_epochs=100, lr=0.0005):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    results = {'Noise_Type': [], 'SNR_Level': [], 'Epoch': [], 'Batch': [], 'D_loss': [], 'G_loss': [], 'SNR': [], 'RMSE': []}\n",
    "    \n",
    "    for (noise_type, snr), dataloader in dataloaders.items():\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (raw_signals, noisy_signals) in enumerate(dataloader):\n",
    "                batch_size = raw_signals.size(0)\n",
    "                \n",
    "                # Ensure the signals have the same length\n",
    "                min_length = min(raw_signals.shape[-1], noisy_signals.shape[-1])\n",
    "                raw_signals = raw_signals[:, :min_length]\n",
    "                noisy_signals = noisy_signals[:, :min_length]\n",
    "\n",
    "                # Denoise the noisy signals\n",
    "                noisy_signals = noisy_signals.unsqueeze(1)  # Add channel dimension\n",
    "                raw_signals = raw_signals.unsqueeze(1)\n",
    "\n",
    "                # Train Generator\n",
    "                optimizer_G.zero_grad()\n",
    "                gen_signals = generator(noisy_signals)\n",
    "                \n",
    "                # Ensure the generated signals have the same length as the input signals\n",
    "                if gen_signals.shape[-1] != noisy_signals.shape[-1]:\n",
    "                    gen_signals = torch.nn.functional.interpolate(gen_signals, size=noisy_signals.shape[-1])\n",
    "\n",
    "                # Update valid and fake labels to match the discriminator output size\n",
    "                disc_output_size = discriminator(torch.cat((gen_signals, noisy_signals), 1)).size()\n",
    "                valid = torch.ones(disc_output_size).to(gen_signals.device)\n",
    "                fake = torch.zeros(disc_output_size).to(gen_signals.device)\n",
    "                \n",
    "                g_loss = criterion(discriminator(torch.cat((gen_signals, noisy_signals), 1)), valid)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # Train Discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(torch.cat((raw_signals, noisy_signals), 1)), valid)\n",
    "                fake_loss = criterion(discriminator(torch.cat((gen_signals.detach(), noisy_signals), 1)), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # Calculate SNR and RMSE\n",
    "                snr_value = calculate_snr(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "                rmse_value = calculate_rmse(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "\n",
    "                # Store results\n",
    "                results['Noise_Type'].append(noise_type)\n",
    "                results['SNR_Level'].append(snr)\n",
    "                results['Epoch'].append(epoch + 1)\n",
    "                results['Batch'].append(i + 1)\n",
    "                results['D_loss'].append(d_loss.item())\n",
    "                results['G_loss'].append(g_loss.item())\n",
    "                results['SNR'].append(snr_value)\n",
    "                results['RMSE'].append(rmse_value)\n",
    "                \n",
    "                print(f\"[{noise_type} SNR {snr}] [Epoch {epoch + 1}/{num_epochs}] [Batch {i + 1}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [SNR: {snr_value}] [RMSE: {rmse_value}]\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initialize models with and without z\n",
    "generator_with_z = Generator(use_z=True)\n",
    "generator_without_z = Generator(use_z=False)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Train the models and collect results for each SNR level\n",
    "results_with_z = train(generator_with_z, discriminator, dataloaders, num_epochs=1)  # Adjusted for quick testing\n",
    "results_without_z = train(generator_without_z, discriminator, dataloaders, num_epochs=1)  # Adjusted for quick testing\n",
    "\n",
    "# Create DataFrames to display results\n",
    "df_results_with_z = pd.DataFrame(results_with_z)\n",
    "df_results_without_z = pd.DataFrame(results_without_z)\n",
    "\n",
    "# Average SNR and RMSE for each SNR level\n",
    "avg_snr_with_z = df_results_with_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_with_z = df_results_with_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "avg_snr_without_z = df_results_without_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_without_z = df_results_without_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "# Plot SNR vs Average SNR\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_snr_with_z.index, avg_snr_with_z.values, label='With z')\n",
    "plt.plot(avg_snr_without_z.index, avg_snr_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Average SNR (dB)')\n",
    "plt.title('SNR vs Average SNR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot SNR vs RMSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_rmse_with_z.index, avg_rmse_with_z.values, label='With z')\n",
    "plt.plot(avg_rmse_without_z.index, avg_rmse_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('SNR vs RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display the DataFrames as a table\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Denoising Results with z\", dataframe=df_results_with_z)\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Denoising Results without z\", dataframe=df_results_without_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cce1e9-5246-46de-8a5b-1544ba5c76fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[With z] [bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.7072569131851196] [G loss: 0.6577890515327454] [SNR: 2.1607254445552826] [RMSE: 0.5224846005439758]\n",
      "[With z] [bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 2.292759656906128] [G loss: 2.442997932434082] [SNR: 2.1606281399726868] [RMSE: 0.5224904417991638]\n",
      "[With z] [bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.8449093103408813] [G loss: 1.1702847480773926] [SNR: 2.1599072217941284] [RMSE: 0.5225340723991394]\n",
      "[With z] [bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.7401205897331238] [G loss: 0.6336720585823059] [SNR: 2.1560870110988617] [RMSE: 0.522763729095459]\n",
      "[With z] [bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.7254235148429871] [G loss: 0.5658223032951355] [SNR: 2.116299569606781] [RMSE: 0.5251639485359192]\n",
      "[With z] [bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.697318434715271] [G loss: 0.7003597021102905] [SNR: 0.529041700065136] [RMSE: 0.6304603815078735]\n",
      "[With z] [em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.7075744867324829] [G loss: 0.7886320352554321] [SNR: -4.091973006725311] [RMSE: 1.0732691287994385]\n",
      "[With z] [em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.7288933396339417] [G loss: 0.578389585018158] [SNR: -4.221408367156982] [RMSE: 1.0893818140029907]\n",
      "[With z] [em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.7072250843048096] [G loss: 0.8182833194732666] [SNR: -4.221673309803009] [RMSE: 1.089415431022644]\n",
      "[With z] [em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6915018558502197] [G loss: 0.7122951745986938] [SNR: -4.2216408252716064] [RMSE: 1.0894113779067993]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wfdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ECGDataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, raw_signals, noisy_signals):\n",
    "        self.raw_signals = raw_signals\n",
    "        self.noisy_signals = noisy_signals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_signal = self.raw_signals[idx]\n",
    "        noisy_signal = self.noisy_signals[idx]\n",
    "        return torch.tensor(raw_signal, dtype=torch.float32), torch.tensor(noisy_signal, dtype=torch.float32)\n",
    "\n",
    "# Define the add_noise function\n",
    "def add_noise(signal, noise, snr):\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    factor = (signal_power / noise_power) / (10 ** (snr / 10))\n",
    "    noisy_signal = signal + noise * 100 * np.sqrt(factor)\n",
    "    return noisy_signal\n",
    "\n",
    "# Define the load_mit_bih_data function\n",
    "def load_mit_bih_data(records, noise_type, snr_levels, target_length=650000):\n",
    "    raw_signals = []\n",
    "    noisy_signals_dict = {snr: [] for snr in snr_levels}\n",
    "    \n",
    "    for record in records:\n",
    "        raw_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-arrhythmia-database-1.0.0/{record}')\n",
    "        raw_signal = raw_record.p_signal[:, 0]  # Use the first channel for simplicity\n",
    "        \n",
    "        # Load noise and add it to the raw signal\n",
    "        noise_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-noise-stress-test-database-1.0.0/{noise_type}')\n",
    "        noise_signal = noise_record.p_signal[:, 0]\n",
    "        \n",
    "        # Ensure the signals are of the same length\n",
    "        min_length = min(len(raw_signal), len(noise_signal), target_length)\n",
    "        raw_signal = raw_signal[:min_length]\n",
    "        noise_signal = noise_signal[:min_length]\n",
    "        \n",
    "        # Pad signals to target length\n",
    "        if min_length < target_length:\n",
    "            raw_signal = np.pad(raw_signal, (0, target_length - min_length), 'constant')\n",
    "            noise_signal = np.pad(noise_signal, (0, target_length - min_length), 'constant')\n",
    "        \n",
    "        raw_signals.append(raw_signal)\n",
    "        \n",
    "        for snr in snr_levels:\n",
    "            noisy_signal = add_noise(raw_signal, noise_signal, snr)\n",
    "            noisy_signals_dict[snr].append(noisy_signal)\n",
    "    \n",
    "    return np.array(raw_signals), {snr: np.array(noisy_signals_dict[snr]) for snr in snr_levels}\n",
    "\n",
    "# Select records and noise types for the experiment\n",
    "records = ['103', '105', '111', '116', '122', '205', '213', '219', '223', '230']\n",
    "noise_types = ['bw', 'em', 'ma']\n",
    "combined_noise_types = ['em+bw', 'ma+bw', 'ma+em', 'ma+em+bw']\n",
    "snr_levels = [0, 1, 2, 3, 4, 5]\n",
    "target_length = 649984\n",
    "\n",
    "raw_signals, noisy_signals_dict = {}, {}\n",
    "for noise_type in noise_types:\n",
    "    raw_signals[noise_type], noisy_signals_dict[noise_type] = load_mit_bih_data(records, noise_type, snr_levels, target_length)\n",
    "\n",
    "# For combined noise types, combine the corresponding noises\n",
    "for combined_noise in combined_noise_types:\n",
    "    components = combined_noise.split('+')\n",
    "    combined_raw_signals, combined_noisy_signals = [], {snr: [] for snr in snr_levels}\n",
    "    for i in range(len(records)):\n",
    "        combined_signal = np.zeros(target_length)\n",
    "        for component in components:\n",
    "            raw_signal = raw_signals[component][i]\n",
    "            combined_signal += raw_signal / len(components)  # Average the signals\n",
    "        combined_raw_signals.append(combined_signal)\n",
    "        for snr in snr_levels:\n",
    "            combined_noise_signal = np.zeros(target_length)\n",
    "            for component in components:\n",
    "                noise_signal = noisy_signals_dict[component][snr][i]\n",
    "                combined_noise_signal += noise_signal / len(components)  # Average the noises\n",
    "            combined_noisy_signals[snr].append(combined_noise_signal)\n",
    "    raw_signals[combined_noise] = np.array(combined_raw_signals)\n",
    "    noisy_signals_dict[combined_noise] = {snr: np.array(combined_noisy_signals[snr]) for snr in snr_levels}\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "datasets = {}\n",
    "for noise_type in noise_types + combined_noise_types:\n",
    "    for snr in snr_levels:\n",
    "        datasets[(noise_type, snr)] = ECGDataset(raw_signals[noise_type], noisy_signals_dict[noise_type][snr])\n",
    "\n",
    "dataloaders = {key: DataLoader(dataset, batch_size=16, shuffle=True) for key, dataset in datasets.items()}\n",
    "\n",
    "# Define the Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, use_z=True):\n",
    "        super(Generator, self).__init__()\n",
    "        self.use_z = use_z\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(8, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.decoder_with_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(2048, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder_without_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        if self.use_z:\n",
    "            z = torch.randn_like(encoded)\n",
    "            encoded = torch.cat((encoded, z), 1)\n",
    "            decoded = self.decoder_with_z(encoded)\n",
    "        else:\n",
    "            decoded = self.decoder_without_z(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define the Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(x.size(0), -1)\n",
    "\n",
    "# Define the calculate_snr function\n",
    "def calculate_snr(original, denoised):\n",
    "    noise = original - denoised\n",
    "    snr = 10 * np.log10(np.sum(original ** 2) / np.sum(noise ** 2))\n",
    "    return snr\n",
    "\n",
    "def calculate_rmse(original, denoised):\n",
    "    mse = np.mean((original - denoised) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def train(generator, discriminator, dataloaders, num_epochs=1, lr=0.0005):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    results = {'Noise_Type': [], 'SNR_Level': [], 'Epoch': [], 'Batch': [], 'D_loss': [], 'G_loss': [], 'SNR': [], 'RMSE': []}\n",
    "    \n",
    "    for (noise_type, snr), dataloader in dataloaders.items():\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (raw_signals, noisy_signals) in enumerate(dataloader):\n",
    "                batch_size = raw_signals.size(0)\n",
    "                \n",
    "                # Ensure the signals have the same length\n",
    "                min_length = min(raw_signals.shape[-1], noisy_signals.shape[-1])\n",
    "                raw_signals = raw_signals[:, :min_length]\n",
    "                noisy_signals = noisy_signals[:, :min_length]\n",
    "\n",
    "                # Denoise the noisy signals\n",
    "                noisy_signals = noisy_signals.unsqueeze(1)  # Add channel dimension\n",
    "                raw_signals = raw_signals.unsqueeze(1)\n",
    "\n",
    "                # Train Generator\n",
    "                optimizer_G.zero_grad()\n",
    "                gen_signals = generator(noisy_signals)\n",
    "                \n",
    "                # Ensure the generated signals have the same length as the input signals\n",
    "                if gen_signals.shape[-1] != noisy_signals.shape[-1]:\n",
    "                    gen_signals = torch.nn.functional.interpolate(gen_signals, size=noisy_signals.shape[-1])\n",
    "\n",
    "                # Update valid and fake labels to match the discriminator output size\n",
    "                disc_output_size = discriminator(torch.cat((gen_signals, noisy_signals), 1)).size()\n",
    "                valid = torch.ones(disc_output_size).to(gen_signals.device)\n",
    "                fake = torch.zeros(disc_output_size).to(gen_signals.device)\n",
    "                \n",
    "                g_loss = criterion(discriminator(torch.cat((gen_signals, noisy_signals), 1)), valid)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # Train Discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(torch.cat((raw_signals, noisy_signals), 1)), valid)\n",
    "                fake_loss = criterion(discriminator(torch.cat((gen_signals.detach(), noisy_signals), 1)), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                \n",
    "                # Calculate SNR and RMSE\n",
    "                snr_value = calculate_snr(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "                rmse_value = calculate_rmse(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "\n",
    "                # Store results\n",
    "                results['Noise_Type'].append(noise_type)\n",
    "                results['SNR_Level'].append(snr)\n",
    "                results['Epoch'].append(epoch + 1)\n",
    "                results['Batch'].append(i + 1)\n",
    "                results['D_loss'].append(d_loss.item())\n",
    "                results['G_loss'].append(g_loss.item())\n",
    "                results['SNR'].append(snr_value)\n",
    "                results['RMSE'].append(rmse_value)\n",
    "                \n",
    "                print(f\"[{'With z' if generator.use_z else 'Without z'}] [{noise_type} SNR {snr}] [Epoch {epoch + 1}/{num_epochs}] [Batch {i + 1}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [SNR: {snr_value}] [RMSE: {rmse_value}]\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initialize models with and without z\n",
    "generator_with_z = Generator(use_z=True)\n",
    "generator_without_z = Generator(use_z=False)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Train the models and collect results for each SNR level\n",
    "results_with_z = train(generator_with_z, discriminator, dataloaders, num_epochs=1)  # Adjusted for quick testing\n",
    "results_without_z = train(generator_without_z, discriminator, dataloaders, num_epochs=1)  # Adjusted for quick testing\n",
    "\n",
    "# Create DataFrames to display results\n",
    "df_results_with_z = pd.DataFrame(results_with_z)\n",
    "df_results_without_z = pd.DataFrame(results_without_z)\n",
    "\n",
    "# Average SNR and RMSE for each SNR level\n",
    "avg_snr_with_z = df_results_with_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_with_z = df_results_with_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "avg_snr_without_z = df_results_without_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_without_z = df_results_without_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "# Plot SNR vs Average SNR\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_snr_with_z.index, avg_snr_with_z.values, label='With z')\n",
    "plt.plot(avg_snr_without_z.index, avg_snr_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Average SNR (dB)')\n",
    "plt.title('SNR vs Average SNR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot SNR vs RMSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_rmse_with_z.index, avg_rmse_with_z.values, label='With z')\n",
    "plt.plot(avg_rmse_without_z.index, avg_rmse_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('SNR vs RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display the DataFrames as a table\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Denoising Results with z\", dataframe=df_results_with_z)\n",
    "tools.display_dataframe_to_user(name=\"Denoising Results without z\", dataframe=df_results_without_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb0bb97-452b-4b5e-95e9-be7d5ada3442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6938540935516357] [G loss: 0.70538330078125] [SNR: 1.9466766715049744] [RMSE: 0.49582982063293457]\n",
      "[bw SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: 1.7225344479084015] [RMSE: 0.6887550950050354]\n",
      "[bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6827574968338013] [G loss: 0.6731495261192322] [SNR: 1.922444999217987] [RMSE: 0.574996292591095]\n",
      "[bw SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: 1.3121423125267029] [RMSE: 0.37077462673187256]\n",
      "[bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6667925119400024] [G loss: 0.6643915772438049] [SNR: 1.8695633113384247] [RMSE: 0.5844566226005554]\n",
      "[bw SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: 2.02610120177269] [RMSE: 0.29989880323410034]\n",
      "[bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6478341817855835] [G loss: 0.6929236650466919] [SNR: 1.9218753278255463] [RMSE: 0.5441152453422546]\n",
      "[bw SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: 1.7928458750247955] [RMSE: 0.5154151916503906]\n",
      "[bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.6219359636306763] [G loss: 0.7352486848831177] [SNR: 1.626967340707779] [RMSE: 0.5493919253349304]\n",
      "[bw SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: 3.2659056782722473] [RMSE: 0.4800695776939392]\n",
      "[bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.5442359447479248] [G loss: 0.8554836511611938] [SNR: 1.8990865349769592] [RMSE: 0.5822984576225281]\n",
      "[bw SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: 2.4551528692245483] [RMSE: 0.2866981029510498]\n",
      "[em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.5362846255302429] [G loss: 1.0487934350967407] [SNR: 1.9417202472686768] [RMSE: 0.5633006691932678]\n",
      "[em SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: 1.1611447483301163] [RMSE: 0.44616612792015076]\n",
      "[em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.6290953159332275] [G loss: 0.5306485891342163] [SNR: 1.704995334148407] [RMSE: 0.5938643217086792]\n",
      "[em SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -5.709754824638367] [RMSE: 0.7618797421455383]\n",
      "[em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.6143589019775391] [G loss: 1.8207817077636719] [SNR: -1.1857014894485474] [RMSE: 0.7874714732170105]\n",
      "[em SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -0.44115442782640457] [RMSE: 0.6286666989326477]\n",
      "[em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.5089714527130127] [G loss: 1.2467018365859985] [SNR: 2.267978936433792] [RMSE: 0.5608566999435425]\n",
      "[em SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -5.5097973346710205] [RMSE: 0.6634054780006409]\n",
      "[em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 1.0481853485107422] [G loss: 0.25209739804267883] [SNR: 1.1119360476732254] [RMSE: 0.6377254724502563]\n",
      "[em SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -6.288090348243713] [RMSE: 0.7810599207878113]\n",
      "[em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.7553535103797913] [G loss: 0.8388110399246216] [SNR: -0.17849784344434738] [RMSE: 0.7068184018135071]\n",
      "[em SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -4.496005475521088] [RMSE: 0.9595107436180115]\n",
      "[ma SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6735686659812927] [G loss: 1.9286062717437744] [SNR: -2.2665415704250336] [RMSE: 0.7503365278244019]\n",
      "[ma SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -0.32573506236076355] [RMSE: 0.9895864129066467]\n",
      "[ma SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.5750038027763367] [G loss: 1.2673033475875854] [SNR: -2.619401514530182] [RMSE: 0.895778477191925]\n",
      "[ma SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -2.6877814531326294] [RMSE: 0.9527710676193237]\n",
      "[ma SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.7499356865882874] [G loss: 0.5903429985046387] [SNR: -3.032861351966858] [RMSE: 1.0172559022903442]\n",
      "[ma SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -7.563157081604004] [RMSE: 1.0300897359848022]\n",
      "[ma SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.8723142743110657] [G loss: 0.4048815071582794] [SNR: -4.458010494709015] [RMSE: 1.1338000297546387]\n",
      "[ma SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -5.39194643497467] [RMSE: 1.1805338859558105]\n",
      "[ma SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.7075339555740356] [G loss: 0.6487728953361511] [SNR: -4.9851298332214355] [RMSE: 1.2051504850387573]\n",
      "[ma SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -5.697044134140015] [RMSE: 1.2208203077316284]\n",
      "[ma SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.6447411775588989] [G loss: 0.7906374335289001] [SNR: -4.956305027008057] [RMSE: 1.2786518335342407]\n",
      "[ma SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -8.885021805763245] [RMSE: 1.098120093345642]\n",
      "[em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.5758610963821411] [G loss: 0.928075909614563] [SNR: -5.101367235183716] [RMSE: 1.267344355583191]\n",
      "[em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -7.133989930152893] [RMSE: 1.1594535112380981]\n",
      "[em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.5157179236412048] [G loss: 1.067543625831604] [SNR: -5.101376175880432] [RMSE: 1.267345666885376]\n",
      "[em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -7.133991718292236] [RMSE: 1.1594537496566772]\n",
      "[em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.44394412636756897] [G loss: 1.253116250038147] [SNR: -5.915536284446716] [RMSE: 1.2130106687545776]\n",
      "[em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -4.072205424308777] [RMSE: 1.3723759651184082]\n",
      "[em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.36238202452659607] [G loss: 1.614676833152771] [SNR: -5.148078203201294] [RMSE: 1.2642335891723633]\n",
      "[em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -6.747652888298035] [RMSE: 1.1729661226272583]\n",
      "[em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.2695823609828949] [G loss: 2.1482748985290527] [SNR: -4.928877949714661] [RMSE: 1.2840014696121216]\n",
      "[em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -9.728146195411682] [RMSE: 1.0836765766143799]\n",
      "[em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.17481887340545654] [G loss: 2.7792086601257324] [SNR: -5.148078799247742] [RMSE: 1.2642335891723633]\n",
      "[em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -6.747653484344482] [RMSE: 1.1729662418365479]\n",
      "[ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.10914473235607147] [G loss: 3.4509096145629883] [SNR: -5.26820182800293] [RMSE: 1.2554514408111572]\n",
      "[ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -5.967922806739807] [RMSE: 1.210110068321228]\n",
      "[ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.050033725798130035] [G loss: 4.055269718170166] [SNR: -5.225592255592346] [RMSE: 1.2633380889892578]\n",
      "[ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -6.2524789571762085] [RMSE: 1.1768200397491455]\n",
      "[ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.02221241220831871] [G loss: 4.51318359375] [SNR: -5.144651532173157] [RMSE: 1.2633272409439087]\n",
      "[ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -6.757685542106628] [RMSE: 1.176866054534912]\n",
      "[ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.011224567890167236] [G loss: 5.045111179351807] [SNR: -4.969832599163055] [RMSE: 1.281270146369934]\n",
      "[ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -8.929643630981445] [RMSE: 1.0965323448181152]\n",
      "[ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.0077506788074970245] [G loss: 5.3679914474487305] [SNR: -5.911562442779541] [RMSE: 1.2086471319198608]\n",
      "[ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -4.113265872001648] [RMSE: 1.3876899480819702]\n",
      "[ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.004494853317737579] [G loss: 5.833284854888916] [SNR: -4.905524849891663] [RMSE: 1.2843174934387207]\n",
      "[ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -10.17282485961914] [RMSE: 1.0821796655654907]\n",
      "[ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.004388491623103619] [G loss: 6.078895092010498] [SNR: -5.364168882369995] [RMSE: 1.248591423034668]\n",
      "[ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -5.505784749984741] [RMSE: 1.2381739616394043]\n",
      "[ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.0033839994575828314] [G loss: 6.3077545166015625] [SNR: -5.119187831878662] [RMSE: 1.2636477947235107]\n",
      "[ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -6.937057375907898] [RMSE: 1.175487756729126]\n",
      "[ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.002657814184203744] [G loss: 6.547904968261719] [SNR: -5.013515949249268] [RMSE: 1.2781920433044434]\n",
      "[ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -8.248029947280884] [RMSE: 1.1108105182647705]\n",
      "[ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.0023350724950432777] [G loss: 6.665159225463867] [SNR: -5.101375579833984] [RMSE: 1.267345666885376]\n",
      "[ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -7.133989930152893] [RMSE: 1.1594539880752563]\n",
      "[ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.0019096601754426956] [G loss: 6.812212944030762] [SNR: -4.944586455821991] [RMSE: 1.2803517580032349]\n",
      "[ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -9.230636954307556] [RMSE: 1.100814938545227]\n",
      "[ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.002073379699140787] [G loss: 6.762729644775391] [SNR: -6.719262599945068] [RMSE: 1.168860673904419]\n",
      "[ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -3.2840606570243835] [RMSE: 1.5179102420806885]\n",
      "[ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.0019084750674664974] [G loss: 6.9567341804504395] [SNR: -5.515226125717163] [RMSE: 1.2354447841644287]\n",
      "[ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -4.966537058353424] [RMSE: 1.2898449897766113]\n",
      "[ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.0016865123761817813] [G loss: 7.049417495727539] [SNR: -5.515223741531372] [RMSE: 1.2354447841644287]\n",
      "[ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -4.966541528701782] [RMSE: 1.2898452281951904]\n",
      "[ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.0013238447718322277] [G loss: 7.22667932510376] [SNR: -4.971765577793121] [RMSE: 1.2809300422668457]\n",
      "[ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -8.885035514831543] [RMSE: 1.0981217622756958]\n",
      "[ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.0012998126912862062] [G loss: 7.20935583114624] [SNR: -5.853877067565918] [RMSE: 1.217195749282837]\n",
      "[ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -4.170798659324646] [RMSE: 1.3574738502502441]\n",
      "[ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.0010992124443873763] [G loss: 7.374945163726807] [SNR: -5.010079741477966] [RMSE: 1.2772949934005737]\n",
      "[ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -8.25059175491333] [RMSE: 1.1149277687072754]\n",
      "[ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.001142640016041696] [G loss: 7.366588115692139] [SNR: -5.466063022613525] [RMSE: 1.2392021417617798]\n",
      "[ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -5.12205183506012] [RMSE: 1.2753463983535767]\n",
      "[bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 2.0004801750183105] [G loss: 0.02122803032398224] [SNR: 0.9292184561491013] [RMSE: 0.5574496388435364]\n",
      "[bw SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: 0.8147383481264114] [RMSE: 0.7646358013153076]\n",
      "[bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.8932006359100342] [G loss: 0.4563845992088318] [SNR: 0.9155438840389252] [RMSE: 0.6456691026687622]\n",
      "[bw SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: 0.8559311181306839] [RMSE: 0.39076942205429077]\n",
      "[bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.37553155422210693] [G loss: 1.534708023071289] [SNR: 0.9048781543970108] [RMSE: 0.6531105041503906]\n",
      "[bw SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: 1.3329973816871643] [RMSE: 0.3248104155063629]\n",
      "[bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.25631722807884216] [G loss: 2.5222339630126953] [SNR: 0.9596507996320724] [RMSE: 0.6078580021858215]\n",
      "[bw SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: 0.981987938284874] [RMSE: 0.5658484101295471]\n",
      "[bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.2839603126049042] [G loss: 2.7857584953308105] [SNR: 0.896659791469574] [RMSE: 0.5975820422172546]\n",
      "[bw SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: 1.337072104215622] [RMSE: 0.5994402170181274]\n",
      "[bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.4063814878463745] [G loss: 1.7514152526855469] [SNR: 0.9031173586845398] [RMSE: 0.6530464887619019]\n",
      "[bw SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -2.9157713055610657] [RMSE: 0.5320727229118347]\n",
      "[em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 1.8679170608520508] [G loss: 0.2854837477207184] [SNR: -1.1900031566619873] [RMSE: 0.8078424334526062]\n",
      "[em SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -5.778073072433472] [RMSE: 0.9918762445449829]\n",
      "[em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 3.0557363033294678] [G loss: 0.021129122003912926] [SNR: -3.8525819778442383] [RMSE: 1.1260720491409302]\n",
      "[em SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -8.424112796783447] [RMSE: 1.0413682460784912]\n",
      "[em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 1.9071286916732788] [G loss: 0.11331147700548172] [SNR: -4.768135845661163] [RMSE: 1.1894782781600952]\n",
      "[em SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -5.7572245597839355] [RMSE: 1.1593750715255737]\n",
      "[em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6880302429199219] [G loss: 0.9167141318321228] [SNR: -4.571963846683502] [RMSE: 1.232676386833191]\n",
      "[em SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -9.553264379501343] [RMSE: 1.05670166015625]\n",
      "[em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.42712152004241943] [G loss: 2.6604132652282715] [SNR: -4.6137624979019165] [RMSE: 1.232873558998108]\n",
      "[em SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -8.899568915367126] [RMSE: 1.0550141334533691]\n",
      "[em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.28561708331108093] [G loss: 3.1151323318481445] [SNR: -4.806841313838959] [RMSE: 1.204272747039795]\n",
      "[em SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -5.767890214920044] [RMSE: 1.110821008682251]\n",
      "[ma SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.36833131313323975] [G loss: 2.1752138137817383] [SNR: -5.518402457237244] [RMSE: 1.0910613536834717]\n",
      "[ma SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -2.644263803958893] [RMSE: 1.2923500537872314]\n",
      "[ma SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.35355088114738464] [G loss: 1.722747802734375] [SNR: -4.610901176929474] [RMSE: 1.1266149282455444]\n",
      "[ma SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -3.6918920278549194] [RMSE: 1.0695327520370483]\n",
      "[ma SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.3175056576728821] [G loss: 1.3434038162231445] [SNR: -3.760867118835449] [RMSE: 1.1061917543411255]\n",
      "[ma SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -7.438248991966248] [RMSE: 1.0153825283050537]\n",
      "[ma SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.283932089805603] [G loss: 1.586909294128418] [SNR: -4.109773933887482] [RMSE: 1.089242935180664]\n",
      "[ma SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -4.300728738307953] [RMSE: 1.041160225868225]\n",
      "[ma SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.22479155659675598] [G loss: 2.105067253112793] [SNR: -3.8834235072135925] [RMSE: 1.0615878105163574]\n",
      "[ma SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -4.407700896263123] [RMSE: 1.052409052848816]\n",
      "[ma SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.16457103192806244] [G loss: 3.1795778274536133] [SNR: -3.4521707892417908] [RMSE: 1.075339436531067]\n",
      "[ma SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -7.952967882156372] [RMSE: 0.9863865375518799]\n",
      "[em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.16814839839935303] [G loss: 3.182264566421509] [SNR: -3.482540249824524] [RMSE: 1.0518487691879272]\n",
      "[em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -5.689806938171387] [RMSE: 0.9818478226661682]\n",
      "[em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.12143871188163757] [G loss: 3.308954954147339] [SNR: -3.499574363231659] [RMSE: 1.0539137125015259]\n",
      "[em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -5.674190521240234] [RMSE: 0.9800841212272644]\n",
      "[em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.09971550852060318] [G loss: 3.3448915481567383] [SNR: -4.416810572147369] [RMSE: 1.02077054977417]\n",
      "[em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -2.1933704614639282] [RMSE: 1.1054303646087646]\n",
      "[em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.06694521009922028] [G loss: 3.579232692718506] [SNR: -3.521462380886078] [RMSE: 1.048326849937439]\n",
      "[em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -5.193608403205872] [RMSE: 0.9808063507080078]\n",
      "[em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.04517601802945137] [G loss: 3.6013147830963135] [SNR: -3.083885610103607] [RMSE: 1.0382832288742065]\n",
      "[em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -8.671682476997375] [RMSE: 0.9595696926116943]\n",
      "[em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.04623336344957352] [G loss: 3.5108048915863037] [SNR: -3.3027520775794983] [RMSE: 1.022258996963501]\n",
      "[em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -5.081522464752197] [RMSE: 0.9682310223579407]\n",
      "[ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.03939872235059738] [G loss: 4.266857147216797] [SNR: -3.4107249975204468] [RMSE: 1.013738989830017]\n",
      "[ma+bw SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -4.194968640804291] [RMSE: 0.9866819381713867]\n",
      "[ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.040780216455459595] [G loss: 3.664559841156006] [SNR: -3.2003766298294067] [RMSE: 1.0005961656570435]\n",
      "[ma+bw SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -5.190791487693787] [RMSE: 1.0414193868637085]\n",
      "[ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.08970256894826889] [G loss: 2.271834373474121] [SNR: -3.5038381814956665] [RMSE: 1.0458641052246094]\n",
      "[ma+bw SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -4.488120377063751] [RMSE: 0.9062515497207642]\n",
      "[ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 1.0197042226791382] [G loss: 0.2744983732700348] [SNR: -2.7593207359313965] [RMSE: 0.9933789968490601]\n",
      "[ma+bw SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: -6.684079170227051] [RMSE: 0.846726655960083]\n",
      "[ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.5001406073570251] [G loss: 3.9129531383514404] [SNR: -3.557005524635315] [RMSE: 0.9216620326042175]\n",
      "[ma+bw SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: 0.4008603096008301] [RMSE: 0.8252512216567993]\n",
      "[ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.5113400220870972] [G loss: 1.9328043460845947] [SNR: -0.6078862771391869] [RMSE: 0.7830517292022705]\n",
      "[ma+bw SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: -2.4681314826011658] [RMSE: 0.44572263956069946]\n",
      "[ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.6410361528396606] [G loss: 1.8175854682922363] [SNR: 0.055971844121813774] [RMSE: 0.6689801216125488]\n",
      "[ma+em SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: -0.36132656037807465] [RMSE: 0.6847921013832092]\n",
      "[ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.43977344036102295] [G loss: 1.759415626525879] [SNR: -0.24436073377728462] [RMSE: 0.7209154367446899]\n",
      "[ma+em SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: -0.18090009689331055] [RMSE: 0.5400204658508301]\n",
      "[ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.2955264449119568] [G loss: 2.126777410507202] [SNR: 0.20737247541546822] [RMSE: 0.7007314562797546]\n",
      "[ma+em SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -0.44949375092983246] [RMSE: 0.45259857177734375]\n",
      "[ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.30418580770492554] [G loss: 2.1460843086242676] [SNR: 1.0451000928878784] [RMSE: 0.6245558857917786]\n",
      "[ma+em SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: 1.4354895055294037] [RMSE: 0.4322943389415741]\n",
      "[ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.26370134949684143] [G loss: 2.4402005672454834] [SNR: 1.2934775650501251] [RMSE: 0.6243469715118408]\n",
      "[ma+em SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: 0.48895902931690216] [RMSE: 0.3595294654369354]\n",
      "[ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.3461293876171112] [G loss: 1.6269196271896362] [SNR: 0.5823221802711487] [RMSE: 0.5042935609817505]\n",
      "[ma+em SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: 2.231103628873825] [RMSE: 0.804429292678833]\n",
      "[ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [D loss: 0.4177521765232086] [G loss: 2.073017120361328] [SNR: 0.8713149279356003] [RMSE: 0.5922381281852722]\n",
      "[ma+em+bw SNR 0] [Epoch 1/1] [Batch 1/1] [SNR: 0.8688933402299881] [RMSE: 0.6588188409805298]\n",
      "[ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [D loss: 0.5326719284057617] [G loss: 1.3341128826141357] [SNR: -0.38830898702144623] [RMSE: 0.684664249420166]\n",
      "[ma+em+bw SNR 1] [Epoch 1/1] [Batch 1/1] [SNR: 0.36157194525003433] [RMSE: 0.6984444856643677]\n",
      "[ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [D loss: 0.497967928647995] [G loss: 4.100700855255127] [SNR: -0.25555090978741646] [RMSE: 0.7442428469657898]\n",
      "[ma+em+bw SNR 2] [Epoch 1/1] [Batch 1/1] [SNR: -2.281760424375534] [RMSE: 0.5134365558624268]\n",
      "[ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [D loss: 0.6274127960205078] [G loss: 0.7248884439468384] [SNR: 1.117490828037262] [RMSE: 0.5454964637756348]\n",
      "[ma+em+bw SNR 3] [Epoch 1/1] [Batch 1/1] [SNR: 2.3233239352703094] [RMSE: 0.6427252292633057]\n",
      "[ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [D loss: 0.3650232255458832] [G loss: 2.3042588233947754] [SNR: 1.9371800124645233] [RMSE: 0.5740217566490173]\n",
      "[ma+em+bw SNR 4] [Epoch 1/1] [Batch 1/1] [SNR: -3.4426766633987427] [RMSE: 0.6409895420074463]\n",
      "[ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [D loss: 0.4274038076400757] [G loss: 1.7155972719192505] [SNR: 0.1868107169866562] [RMSE: 0.6463955044746399]\n",
      "[ma+em+bw SNR 5] [Epoch 1/1] [Batch 1/1] [SNR: 1.0531685501337051] [RMSE: 0.6264221668243408]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wfdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ECGDataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, raw_signals, noisy_signals):\n",
    "        self.raw_signals = raw_signals\n",
    "        self.noisy_signals = noisy_signals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_signal = self.raw_signals[idx]\n",
    "        noisy_signal = self.noisy_signals[idx]\n",
    "        return torch.tensor(raw_signal, dtype=torch.float32), torch.tensor(noisy_signal, dtype=torch.float32)\n",
    "\n",
    "# Define the add_noise function\n",
    "def add_noise(signal, noise, snr):\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    factor = (signal_power / noise_power) / (10 ** (snr / 10))\n",
    "    noisy_signal = signal + noise * np.sqrt(factor)\n",
    "    return noisy_signal\n",
    "\n",
    "# Define the load_mit_bih_data function\n",
    "def load_mit_bih_data(records, noise_type, snr_levels, target_length=650000):\n",
    "    raw_signals = []\n",
    "    noisy_signals_dict = {snr: [] for snr in snr_levels}\n",
    "    \n",
    "    for record in records:\n",
    "        raw_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-arrhythmia-database-1.0.0/{record}')\n",
    "        raw_signal = raw_record.p_signal[:, 0]  # Use the first channel for simplicity\n",
    "        \n",
    "        # Load noise and add it to the raw signal\n",
    "        noise_record = wfdb.rdrecord(f'C:\\\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\New folder\\\\mit-bih-noise-stress-test-database-1.0.0/{noise_type}')\n",
    "        noise_signal = noise_record.p_signal[:, 0]\n",
    "        \n",
    "        # Ensure the signals are of the same length\n",
    "        min_length = min(len(raw_signal), len(noise_signal), target_length)\n",
    "        raw_signal = raw_signal[:min_length]\n",
    "        noise_signal = noise_signal[:min_length]\n",
    "        \n",
    "        # Pad signals to target length\n",
    "        if min_length < target_length:\n",
    "            raw_signal = np.pad(raw_signal, (0, target_length - min_length), 'constant')\n",
    "            noise_signal = np.pad(noise_signal, (0, target_length - min_length), 'constant')\n",
    "        \n",
    "        raw_signals.append(raw_signal)\n",
    "        \n",
    "        for snr in snr_levels:\n",
    "            noisy_signal = add_noise(raw_signal, noise_signal, snr)\n",
    "            noisy_signals_dict[snr].append(noisy_signal)\n",
    "    \n",
    "    return np.array(raw_signals), {snr: np.array(noisy_signals_dict[snr]) for snr in snr_levels}\n",
    "\n",
    "# Select records and noise types for the experiment\n",
    "records = ['103', '105', '111', '116', '122', '205', '213', '219', '223', '230']\n",
    "noise_types = ['bw', 'em', 'ma']\n",
    "combined_noise_types = ['em+bw', 'ma+bw', 'ma+em', 'ma+em+bw']\n",
    "snr_levels = [0, 1, 2, 3, 4, 5]\n",
    "target_length = 649984\n",
    "\n",
    "raw_signals, noisy_signals_dict = {}, {}\n",
    "for noise_type in noise_types:\n",
    "    raw_signals[noise_type], noisy_signals_dict[noise_type] = load_mit_bih_data(records, noise_type, snr_levels, target_length)\n",
    "\n",
    "# For combined noise types, combine the corresponding noises\n",
    "for combined_noise in combined_noise_types:\n",
    "    components = combined_noise.split('+')\n",
    "    combined_raw_signals, combined_noisy_signals = [], {snr: [] for snr in snr_levels}\n",
    "    for i in range(len(records)):\n",
    "        combined_signal = np.zeros(target_length)\n",
    "        for component in components:\n",
    "            raw_signal = raw_signals[component][i]\n",
    "            combined_signal += raw_signal / len(components)  # Average the signals\n",
    "        combined_raw_signals.append(combined_signal)\n",
    "        for snr in snr_levels:\n",
    "            combined_noise_signal = np.zeros(target_length)\n",
    "            for component in components:\n",
    "                noise_signal = noisy_signals_dict[component][snr][i]\n",
    "                combined_noise_signal += noise_signal / len(components)  # Average the noises\n",
    "            combined_noisy_signals[snr].append(combined_noise_signal)\n",
    "    raw_signals[combined_noise] = np.array(combined_raw_signals)\n",
    "    noisy_signals_dict[combined_noise] = {snr: np.array(combined_noisy_signals[snr]) for snr in snr_levels}\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "datasets = {}\n",
    "for noise_type in noise_types + combined_noise_types:\n",
    "    for snr in snr_levels:\n",
    "        datasets[(noise_type, snr)] = ECGDataset(raw_signals[noise_type], noisy_signals_dict[noise_type][snr])\n",
    "\n",
    "dataloaders = {}\n",
    "for key, dataset in datasets.items():\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    dataloaders[key] = {'train': DataLoader(train_dataset, batch_size=16, shuffle=True), 'test': DataLoader(test_dataset, batch_size=16, shuffle=False)}\n",
    "\n",
    "# Define the Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, use_z=True):\n",
    "        super(Generator, self).__init__()\n",
    "        self.use_z = use_z\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(8, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.decoder_with_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(2048, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder_without_z = nn.Sequential(\n",
    "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        if self.use_z:\n",
    "            z = torch.randn_like(encoded)\n",
    "            encoded = torch.cat((encoded, z), 1)\n",
    "            decoded = self.decoder_with_z(encoded)\n",
    "        else:\n",
    "            decoded = self.decoder_without_z(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define the Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv1d(512, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(x.size(0), -1)\n",
    "\n",
    "# Define the calculate_snr function\n",
    "def calculate_snr(original, denoised):\n",
    "    noise = original - denoised\n",
    "    snr = 10 * np.log10(np.sum(original ** 2) / np.sum(noise ** 2))\n",
    "    return snr\n",
    "\n",
    "def calculate_rmse(original, denoised):\n",
    "    mse = np.mean((original - denoised) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def train(generator, discriminator, dataloaders, num_epochs=100, lr=0.0005, use_z=True):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    results = {'Noise_Type': [], 'SNR_Level': [], 'Epoch': [], 'Batch': [], 'D_loss': [], 'G_loss': [], 'SNR': [], 'RMSE': [], 'Type': []}\n",
    "    \n",
    "    for (noise_type, snr), split_dataloaders in dataloaders.items():\n",
    "        train_loader = split_dataloaders['train']\n",
    "        test_loader = split_dataloaders['test']\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            generator.train()\n",
    "            discriminator.train()\n",
    "            for i, (raw_signals, noisy_signals) in enumerate(train_loader):\n",
    "                batch_size = raw_signals.size(0)\n",
    "                \n",
    "                # Ensure the signals have the same length\n",
    "                min_length = min(raw_signals.shape[-1], noisy_signals.shape[-1])\n",
    "                raw_signals = raw_signals[:, :min_length]\n",
    "                noisy_signals = noisy_signals[:, :min_length]\n",
    "\n",
    "                # Denoise the noisy signals\n",
    "                noisy_signals = noisy_signals.unsqueeze(1)  # Add channel dimension\n",
    "                raw_signals = raw_signals.unsqueeze(1)\n",
    "\n",
    "                # Train Generator\n",
    "                optimizer_G.zero_grad()\n",
    "                gen_signals = generator(noisy_signals)\n",
    "                \n",
    "                # Ensure the generated signals have the same length as the input signals\n",
    "                if gen_signals.shape[-1] != noisy_signals.shape[-1]:\n",
    "                    gen_signals = torch.nn.functional.interpolate(gen_signals, size=noisy_signals.shape[-1])\n",
    "\n",
    "                # Update valid and fake labels to match the discriminator output size\n",
    "                disc_output_size = discriminator(torch.cat((gen_signals, noisy_signals), 1)).size()\n",
    "                valid = torch.ones(disc_output_size).to(gen_signals.device)\n",
    "                fake = torch.zeros(disc_output_size).to(gen_signals.device)\n",
    "                \n",
    "                g_loss = criterion(discriminator(torch.cat((gen_signals, noisy_signals), 1)), valid)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # Train Discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(torch.cat((raw_signals, noisy_signals), 1)), valid)\n",
    "                fake_loss = criterion(discriminator(torch.cat((gen_signals.detach(), noisy_signals), 1)), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "                # Calculate SNR and RMSE\n",
    "                snr_value = calculate_snr(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "                rmse_value = calculate_rmse(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "\n",
    "                # Store results\n",
    "                results['Noise_Type'].append(noise_type)\n",
    "                results['SNR_Level'].append(snr)\n",
    "                results['Epoch'].append(epoch + 1)\n",
    "                results['Batch'].append(i + 1)\n",
    "                results['D_loss'].append(d_loss.item())\n",
    "                results['G_loss'].append(g_loss.item())\n",
    "                results['SNR'].append(snr_value)\n",
    "                results['RMSE'].append(rmse_value)\n",
    "                results['Type'].append('Train' if use_z else 'Test')\n",
    "\n",
    "                print(f\"[{noise_type} SNR {snr}] [Epoch {epoch + 1}/{num_epochs}] [Batch {i + 1}/{len(train_loader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [SNR: {snr_value}] [RMSE: {rmse_value}]\")\n",
    "        \n",
    "        # Testing phase\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (raw_signals, noisy_signals) in enumerate(test_loader):\n",
    "                batch_size = raw_signals.size(0)\n",
    "                \n",
    "                # Ensure the signals have the same length\n",
    "                min_length = min(raw_signals.shape[-1], noisy_signals.shape[-1])\n",
    "                raw_signals = raw_signals[:, :min_length]\n",
    "                noisy_signals = noisy_signals[:, :min_length]\n",
    "\n",
    "                # Denoise the noisy signals\n",
    "                noisy_signals = noisy_signals.unsqueeze(1)  # Add channel dimension\n",
    "                raw_signals = raw_signals.unsqueeze(1)\n",
    "\n",
    "                # Generate signals\n",
    "                gen_signals = generator(noisy_signals)\n",
    "                \n",
    "                # Ensure the generated signals have the same length as the input signals\n",
    "                if gen_signals.shape[-1] != noisy_signals.shape[-1]:\n",
    "                    gen_signals = torch.nn.functional.interpolate(gen_signals, size=noisy_signals.shape[-1])\n",
    "\n",
    "                # Calculate SNR and RMSE\n",
    "                snr_value = calculate_snr(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "                rmse_value = calculate_rmse(raw_signals.squeeze().cpu().numpy(), gen_signals.squeeze().cpu().detach().numpy())\n",
    "\n",
    "                # Store results\n",
    "                results['Noise_Type'].append(noise_type)\n",
    "                results['SNR_Level'].append(snr)\n",
    "                results['Epoch'].append(epoch + 1)\n",
    "                results['Batch'].append(i + 1)\n",
    "                results['D_loss'].append(0)\n",
    "                results['G_loss'].append(0)\n",
    "                results['SNR'].append(snr_value)\n",
    "                results['RMSE'].append(rmse_value)\n",
    "                results['Type'].append('Test')\n",
    "\n",
    "                print(f\"[{noise_type} SNR {snr}] [Epoch {epoch + 1}/{num_epochs}] [Batch {i + 1}/{len(test_loader)}] [SNR: {snr_value}] [RMSE: {rmse_value}]\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initialize models with and without z\n",
    "generator_with_z = Generator(use_z=True)\n",
    "generator_without_z = Generator(use_z=False)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Train the models and collect results for each SNR level\n",
    "results_with_z = train(generator_with_z, discriminator, dataloaders, num_epochs=1, use_z=True)  # Adjusted for quick testing\n",
    "results_without_z = train(generator_without_z, discriminator, dataloaders, num_epochs=1, use_z=False)  # Adjusted for quick testing\n",
    "\n",
    "# Create DataFrames to display results\n",
    "df_results_with_z = pd.DataFrame(results_with_z)\n",
    "df_results_without_z = pd.DataFrame(results_without_z)\n",
    "\n",
    "# Average SNR and RMSE for each SNR level\n",
    "avg_snr_with_z = df_results_with_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_with_z = df_results_with_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "avg_snr_without_z = df_results_without_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_without_z = df_results_without_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "# Plot SNR vs Average SNR\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_snr_with_z.index, avg_snr_with_z.values, label='With z')\n",
    "plt.plot(avg_snr_without_z.index, avg_snr_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Average SNR (dB)')\n",
    "plt.title('SNR vs Average SNR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot SNR vs RMSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_rmse_with_z.index, avg_rmse_with_z.values, label='With z')\n",
    "plt.plot(avg_rmse_without_z.index, avg_rmse_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('SNR vs RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display the DataFrames as a table\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Denoising Results with z\", dataframe=df_results_with_z)\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Denoising Results without z\", dataframe=df_results_without_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e10152-593c-4af4-8099-cb7f6250711d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/0AAAIhCAYAAAActNqAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACteUlEQVR4nOzdeVxVdf7H8dcFLvsOsskqLrgvUCmaSmmZWVmp7U3LVL8ap6nJ0la1PdvHZmpqSpvJsjTbV8s1l1TcNZdUVARUZN8v3PP748JVQhQUvIDv5+NxH3G/53vO/Rz8BnzOdzMZhmEgIiIiIiIiIm2Ok6MDEBEREREREZHmoaRfREREREREpI1S0i8iIiIiIiLSRinpFxEREREREWmjlPSLiIiIiIiItFFK+kVERERERETaKCX9IiIiIiIiIm2Ukn4RERERERGRNkpJv4iIiIiIiEgbpaRfRESkkX799VeuvPJKoqOjcXNzIzQ0lAEDBvDAAw/Uqjd06FBMJhMjRoyoc420tDRMJhMvvfSSvWzRokWYTCb7y9nZmXbt2nHZZZexZs2aZr+vxvr73/+OyWRi1KhRjg6lxSkuLuaFF16gd+/e+Pr64uPjQ3x8POPGjWPx4sX2esf+m69YsaLOdW655Ra8vb1rldW0q5qXu7s73bp14+mnn6aioqLZ701ERFoXJf0iIiKN8M0335CcnExBQQHTpk3jxx9/5PXXX2fgwIF8/PHHxz3nhx9+YMGCBQ3+jGeffZYVK1awaNEiHn/8cZYvX86QIUPYuXNnU93GabNYLHzwwQcAfP/99xw4cMDBEbUcVVVVXHTRRTzzzDOMGTOGOXPmMHfuXO6//37y8/NZunTpcc976KGHGvwZHTp0YMWKFaxYsYI5c+bQqVMnHn/8ccaPH99UtyEiIm2Ei6MDEBERaU2mTZtGXFwcP/zwAy4uR3+NXnvttUybNq1O/c6dO1NZWclDDz3E6tWrMZlMJ/2MTp060b9/fwDOP/98/P39+dOf/sQHH3zA1KlTm+5mTsMXX3zB4cOHufTSS/nmm294//33eeSRR85oDFVVVVRWVuLm5nZGP/dklixZwvLly3nvvfe49dZb7eUXX3wx48ePx2q11jlnxIgRfP/993z11VdcdtllJ/0MDw8PexsBuOSSS+jWrRvvv/8+//jHP3B3d2+amxERkVZPPf0iIiKNcOTIEYKDg2sl/DWcnOr+WjWbzTzzzDOkpqbWOxLgZJKSkgA4ePDgCet9/vnnmEwmfv755zrH3nzzTUwmExs3bgRg9+7dXHvttURERNinKFx44YWsX7++QTG9++67uLq6MmPGDKKiopgxYwaGYQBw+PBhXF1defzxx+uct23bNkwmE//4xz/sZVlZWdx1111ERkbi6upKXFwcU6dOpbKy0l6nZjrEtGnTePrpp4mLi8PNzY2FCxdSVlbGAw88QJ8+ffDz8yMwMJABAwbwxRdf1Pn8vLw8br/9dgIDA/H29ubSSy9l9+7dmEwmpkyZUqvuzp07uf766wkJCcHNzY2uXbvyz3/+86TfmyNHjgAQHh5+3OPHaye33HIL3bp14+GHH6aqquqkn/FHLi4u9OnTh4qKCvLy8hp9voiItF1K+kVERBphwIAB/Prrr9x77738+uuvWCyWk55zzTXXkJiYyGOPPdag+n+0Z88ewDZq4ERGjRpFSEgIM2bMqHNs5syZ9OvXj169egEwcuRIUlNTmTZtGvPnz+fNN9+kb9++DUoY09PT+fHHH7niiito164df/rTn/j9999ZsmQJAO3atWPUqFG8//77dXq1Z8yYgaurKzfccANgS/jPPfdcfvjhB5544gm+++47br/9dp577jnuuOOOOp/9j3/8gwULFvDSSy/x3XffkZCQQHl5OTk5OUyYMIHPP/+cjz76iEGDBnHVVVfx3//+136u1Wrlsssu48MPP2TixIl89tlnnHfeecddc2Hr1q2cc845bN68mZdffpmvv/6aSy+9lHvvvfekoy2SkpIwm8387W9/Y9asWWRmZp70e+rs7Mxzzz3Hli1beP/9909a/3j27NmDv78/7dq1O6XzRUSkjTJERESkwbKzs41BgwYZgAEYZrPZSE5ONp577jmjsLCwVt0hQ4YY3bt3NwzDMH766ScDMKZPn24YhmHs2bPHAIwXX3zRXn/hwoUGYHz88ceGxWIxSkpKjGXLlhldunQxunXrZuTm5p40vr///e+Gh4eHkZeXZy/bunVrrc/Ozs42AOO11147pe/Bk08+aQDG999/bxiGYezevdswmUzGTTfdZK/z5ZdfGoDx448/2ssqKyuNiIgI4+qrr7aX3XXXXYa3t7exd+/eWp/x0ksvGYCxZcsWwzCOfr/i4+ONioqKE8ZXWVlpWCwW4/bbbzf69u1rL//mm28MwHjzzTdr1X/uuecMwJg8ebK97OKLLzYiIyON/Pz8WnXHjx9vuLu7Gzk5OSeM4d133zW8vb3t7SQ8PNy4+eabjSVLltSqV/NvPmfOHMMwDGPQoEFGZGSkUVpaahiGYfzpT38yvLy8ap1T064sFothsViMzMxM44knnjAA46233jphXCIicvZRT7+IiEgjBAUFsXTpUlavXs3zzz/PFVdcwY4dO3j44Yfp2bMn2dnZxz3vwgsv5KKLLuLJJ5+ksLDwhJ9xzTXXYDab8fT0ZODAgRQUFPDNN9/g7+9/0vhuu+02SktLa00lmDFjBm5ublx//fUABAYGEh8fz4svvsgrr7zCunXrjjvP/HgMw7AP6R8+fDgAcXFxDB06lE8//ZSCggLANsc8LCys1qiDH374gYyMDG677TZ72ddff01KSgoRERFUVlbaX5dccglArZXuAS6//HLMZnOduObMmcPAgQPx9vbGxcUFs9nMu+++y2+//WavU3OtcePG1Tr3uuuuq/W+rKyMn3/+mSuvvBJPT89acY0cOZKysjJWrlx5wu/TbbfdRnp6Oh9++CH33nsvUVFRfPDBBwwZMoQXX3yx3vNeeOEF0tPTef311094/S1btmA2mzGbzYSHh/Pkk0/y8MMPc9ddd53wPBEROfso6RcRETkFSUlJTJw4kTlz5pCRkcH9999PWlracRfzq/HCCy+QnZ1da5u++uqtXr2axYsX8+ijj3Lw4EFGjx5NeXn5SePq3r0755xzjj3Zrqqq4oMPPuCKK64gMDAQwD7v/+KLL2batGn069ePdu3ace+99570gcSCBQvYs2cPY8eOpaCggLy8PPLy8hg3bhwlJSV89NFHgG2O+U033cRnn31mnzIwc+ZMwsPDufjii+3XO3jwIF999ZU9ga15de/eHaDOQ5TjzZOfN28e48aNo3379nzwwQesWLGC1atXc9ttt1FWVmavd+TIEVxcXOzfhxqhoaG13h85coTKykqmT59eJ66RI0ceN67j8fPz47rrruP111/n119/ZePGjYSGhvLoo4/WO40iOTmZ0aNH8/zzz5Obm1vvtePj41m9ejWrVq1izpw59O7dm+eee47Zs2efNC4RETm7aPV+ERGR02Q2m5k8eTKvvvoqmzdvrrdenz59uO6663jllVfsyePxdOjQwb543+DBg/Hw8OCxxx5j+vTpTJgw4aTx3Hrrrdxzzz389ttv7N69m8zMzFqryAPExMTw7rvvArBjxw4++eQTpkyZQkVFBW+99Va9164555VXXuGVV1457vGa3uZbb72VF198kdmzZ3PNNdfw5Zdfct999+Hs7GyvHxwcTK9evXjmmWeO+3kRERG13h9v94MPPviAuLg4Pv7441rH//iQJCgoiMrKSnJycmol/llZWbXqBQQE4OzszE033cRf/vKX48YVFxd33PIT6d69O9deey2vvfYaO3bs4Nxzzz1uveeee44ePXrw7LPP1nstd3d3exs555xzSElJoXv37tx3332MGjUKb2/vRscnIiJtk3r6RUREGqG+RdlqhpH/MUn9o6effpqKiopGbb330EMP0bFjR55//vmT9sSDbbi6u7s7M2fOZObMmbRv356LLrqo3vqdO3fmscceo2fPnqxdu7beerm5uXz22WcMHDiQhQsX1nndcMMNrF692v7go2vXrpx33nnMmDGDDz/8kPLy8joPH0aNGsXmzZuJj48nKSmpzutk30+wPQhwdXWtlfBnZWXVWb1/yJAhAHV2Ufhj77inpycpKSmsW7eOXr16HTeuoKCgeuM5cuQIFRUVxz22bds24MTtJCEhgdtuu43p06ezb9++eusdKygoiOeff56DBw8yffr0Bp0jIiJnB/X0i4iINMLFF19MZGQkl112GQkJCVitVtavX8/LL7+Mt7c3f/vb3054flxcHHffffdJ52wfy2w28+yzzzJu3Dhef/11HnvssRPW9/f358orr2TmzJnk5eUxYcKEWtvEbdy4kfHjxzN27Fg6deqEq6srCxYsYOPGjUyaNKne686aNYuysjLuvfdehg4dWud4UFAQs2bN4t133+XVV18FbHPb77rrLjIyMkhOTqZLly61znnyySeZP38+ycnJ3HvvvXTp0oWysjLS0tL49ttveeutt4iMjDzh/Y4aNYp58+Zxzz33MGbMGPbv389TTz1FeHg4O3futNcbMWIEAwcO5IEHHqCgoIDExERWrFhhX+H/2O/R66+/zqBBgzj//PO5++67iY2NpbCwkN9//52vvvqKBQsW1BvPwoUL+dvf/sYNN9xAcnIyQUFBHDp0iI8++ojvv/+em2+++aT3NGXKFGbNmsXChQvx8vI6Yd0aN998M6+88govvfQSf/nLX/D19W3QeSIi0sY5eiVBERGR1uTjjz82rr/+eqNTp06Gt7e3YTabjejoaOOmm24ytm7dWqvusav3H+vw4cOGr69vvav316zk/kfnnXeeERAQUGtl/vr8+OOP9pXjd+zYUevYwYMHjVtuucVISEgwvLy8DG9vb6NXr17Gq6++alRWVtZ7zT59+hghISFGeXl5vXX69+9vBAcH2+vk5+cbHh4eBmC88847xz3n8OHDxr333mvExcUZZrPZCAwMNBITE41HH33UKCoqMgzj+LsdHOv55583YmNjDTc3N6Nr167GO++8Y0yePNn44586OTk5xq233mr4+/sbnp6exvDhw42VK1cagPH666/Xqrtnzx7jtttuM9q3b2+YzWajXbt2RnJysvH000/Xe/+GYRj79+83HnvsMWPgwIFGWFiY4eLiYvj4+BjnnXeeMX369Frf4xP9mz/yyCMGUO/q/cdTs0PB1KlTTxijiIicPUyGYRgOet4gIiIi4nAffvghN9xwA8uWLSM5OdnR4YiIiDQpJf0iIiJy1vjoo484cOAAPXv2xMnJiZUrV/Liiy/St2/fOtsDioiItAWa0y8iIiJnDR8fH2bPns3TTz9NcXEx4eHh3HLLLTz99NOODk1ERKRZqKdfREREREREpI3Sln0iIiIiIiIibZSSfhEREREREZE2Skm/iIiIiIiISBulhfyagNVqJSMjAx8fH0wmk6PDERERERERkTbOMAwKCwuJiIjAyan+/nwl/U0gIyODqKgoR4chIiIiIiIiZ5n9+/cTGRlZ73El/U3Ax8cHsH2zfX19HRxN/SwWCz/++CMXXXQRZrPZ0eGI1KE2Ki2d2qi0dGqj0hqonUpL11raaEFBAVFRUfZ8tD5K+ptAzZB+X1/fFp/0e3p64uvr26Ibr5y91EalpVMblZZObVRaA7VTaelaWxs92RRzLeQnIiIiIiIi0kYp6RcRERERERFpo5T0i4iIiIiIiLRRmtN/hhiGQWVlJVVVVQ6LwWKx4OLiQllZmUPjaK2cnZ1xcXHRtowiIiIiItJqKOk/AyoqKsjMzKSkpMShcRiGQVhYGPv371fieoo8PT0JDw/H1dXV0aGIiIiIiIiclJL+Zma1WtmzZw/Ozs5ERETg6urqsITbarVSVFSEt7c3Tk6a2dEYhmFQUVHB4cOH2bNnD506ddL3UEREREREWjwl/c2soqICq9VKVFQUnp6eDo3FarVSUVGBu7u7EtZT4OHhgdlsZu/evfbvo4iIiIiISEumzO8MUZLdNujfUUREREREWhNlMCIiIiIiIiJtlJJ+ERERERERkTZKSb80mUWLFmEymcjLyzthvdjYWF577bUzEpOIiIiIiMjZTEm/1PHWW2/h4+NDZWWlvayoqAiz2cz5559fq+7SpUsxmUzs2LGD5ORkMjMz8fPzA2DmzJn4+/ufydBFRERERETkGEr6pY6UlBSKiopYs2aNvWzp0qWEhYWxevVqSkpK7OWLFi0iIiKCzp074+rqSlhYmMO2JBQREREREZHalPSfYYZhUFJR6ZCXYRgNirFLly5ERESwaNEie9miRYu44ooriI+PZ/ny5bXKU1JS7F/XDO9ftGgRt956K/n5+ZhMJkwmE1OmTLGfV1JSwm233YaPjw/R0dG8/fbb9caTlpZmv8axr6FDhzbqey8iIiIiInK2cXF0AGebUksV3Z74wSGfvXnK8AbXHTp0KAsXLmTSpEkALFy4kIceegir1crChQsZNmwYFRUVrFixgunTp9c5Pzk5mddee40nnniC7du3A+Dt7W0//vLLL/PUU0/xyCOPMHfuXO6++24GDx5MQkJCnWtFRUWRmZlpf5+VlcWwYcMYPHhwg+9HRERERETkbKSefjmuoUOHsmzZMiorKyksLGTdunUMHjyYIUOG2EcArFy5ktLSUntP/7FcXV3x8/PDZDIRFhZGWFhYraR/5MiR3HPPPXTs2JGJEycSHBxca2TBsZydne3X8Pf35//+7/8YMGBArZEDIiIiIiIiUpd6+s8wD7MzW5+82CGf7eZsorCsYXVTUlIoLi5m9erV5Obm0rlzZ0JCQhgyZAg33XQTxcXFLFq0iOjoaDp06NDoWHr16mX/uubBwKFDh0563u23305hYSHz58/HyUnPrERERERak4pKK6l7czlSRoOnnorI6VHSf4aZTCY8XR3zbbdarQ2u27FjRyIjI1m4cCG5ubkMGTIEgLCwMOLi4li2bBkLFy7kggsuOKVYzGZzrfcmk+mk8T399NN8//33rFq1Ch8fn1P6XBERERFxjK0ZBTwwZwO/ZRYALrz1+xISYwLsr+4Rfri6qFNHpKkp6Zd6paSksGjRInJzc3nwwQft5UOGDOGHH35g5cqV3HrrrfWe7+rqSlVVVZPE8umnn/Lkk0/y3XffER8f3yTXFBEREZHmV1ll5c1Fu/jHgp1Yqgy8XJ0ps1RyqLCc7zZn8d3mLADcXJzoHelPv2MeBAR6uTo4epHWT0m/1CslJYW//OUvWCwWe08/2JL+u+++m7KysuPO568RGxtLUVERP//8M71798bT0xNPT89Gx7F582ZuvvlmJk6cSPfu3cnKsv1icHV1JTAwsPE3JiIiIiJnxM6DhTwwZwMb0/MBuKhbKFMvS+CXhT/TvucANhwoJHVvDql7c8ktsbAqLYdVaTn28zsEe9kfACTFBtAh2BsnJ20PLdIYSvqlXikpKZSWlpKQkEBoaKi9fMiQIRQWFhIfH09UVFS95ycnJ/N///d/XHPNNRw5coTJkyef0uJ7a9asoaSkhKeffpqnn366Vhz1Lf4nIiIiIo5TZTV495fdvPTjDioqrfi6uzD1iu6M7tOeyspKXJ3hnNgAkjuFAPEYhsHu7GJS9+aSmpZL6r5cfj9UxO7sYnZnFzMnNR0APw+z/SFAv+gA+kT54+Hq7NibFWnhlPRLvWJjY4+7wEpkZORxy4cOHVqn/M033+TNN9+sVZaWllbn3PXr19cbxy233MItt9zSoJhFRERExLH2ZBczYc4GUvfmAjC0Szuev6oXYX7u9Z5jMpmIb+dNfDtvxiXZOpXySipYuy+X1L25rEnLZUN6HvmlFhZsO8SCbbYFoF2cTHSL8K21NkC4n0fz36RIK6KkX0RERERETpvVavDfFWk8//02yixWvN1ceHxUV8YlRWEyNX5Ivr+nKxckhHJBgm3EqaXKym+ZBaypHgmQmpZLVkEZG9Pz2Ziez4xlaQC09/egX0wASdUPARLCfHBx1gKBcvZS0i8iIiIiIqdlf04JD83dyIrdRwBIjg9i2pheRAY0fj2n+pidnegV6U+vSH9uIw7DMMjIL2NNWg5r9+ayZm8uv2UWcCCvlAN5pXy1IQMAT1dn+kT520cC9I0OwM/DfJJPE2k7lPSLiIiIiMgpMQyDj1bt55lvtlJcUYWH2ZmHRyZw43kxzb7gnslkor2/B+37tOeKPu0BKC6vZMP+PNbstU0LWLsvl8KySpbvOsLyXUeqz4NOId4kxgTaFgiMCSAmyPOURiOItAZK+kVEREREpNEy80uZ+Okmluw4DNgW5ntxTG9ig70cFpOXmwvJHYNJ7hgM2KYc7DxUZFsXYK9tREDakRJ2HCxix8EiPlq1D4Bgb1f6RR/dJaB7hB/uZi0QKG2Dkn4REREREWkwwzCYt/YAU77aQmFZJa4uTjx0cRduHRiHcwvbTs/JyUSXMB+6hPlw/XnRABwuLLcvEJi6N5dN6flkF1Xw49aD/Lj1IACuzk70aO9LUmyg/WFAOx83R96KyClT0i8iIiIiIg1yqLCMR+Zt5qffbMlx70g/Xh7Xm44hPg6OrOHa+bhxcfcwLu4eBkB5ZRWbD+TbdwlYuy+X7KIK1u7LY+2+PPt5MUGeJEYHkBhrewjQOcSn2acwiDQFJf0iIiIiInJSX23I4PEvNpNXYsHsbOK+YZ25a3CHVr8yvpuLc/X8/kDuHGwbybD3SIltJED1LgE7DhWy90gJe4+UMG/dAQB83F3oGx1AYrRtSkDvKH+83ZReScujVikiIiIiIvXKKa7g8c83882mTAC6hfvy8rjedA33dXBkzcNkMhEb7EVssBdXJ0YCkF9qYd2+XNZWPwhYty+PwrJKluw4bF/TwMkEXcN97bsEJMYE0N7fQwsEisMp6RcRERERkeP6YUsWj362ieyiCpydTPwlpSPjUzri6tK6e/cby8/DzNAuIQztEgJAZZWVbVmF9nUBUvfmciCvlC0ZBWzJKOC/K/YCEObrTmJMAP2qdwnoFuGLuZWPjJDWR0m/NJlFixaRkpJCbm4u/v7+9daLjY3lvvvu47777jtjsYmIiIhIw+WXWJj61Rb7UPbOod68PLYPPSP9HBxZy+Di7ESP9n70aO/Hn5JjAdtuBmv35tl3CdiSUUBWQRnfbMq0j5JwNzvRO9K/1mgAf09XB96JnA2U9Esdb731Fg8++CC5ubm4uNiaSFFREQEBAfTv35+lS5fa6y5dupTBgwezfft2kpOTyczMxM/P9stg5syZ3HfffeTl5TniNvRwQUREROQULNp+iImfbuRgQTlOJrhzcDz3DeukLexOItzPg0t7eXBpr3AASiuq2JCeV2s0QH6phV/35PDrnhz7efHtvEiKCbQ9BIgNoEOwl6YESJNS0i91pKSkUFRUxJo1a+jfvz9gS+7DwsJYvXo1JSUleHp6Arbe/YiICDp37gxAWFiYw+IWERERkVNXWGbhmW9+Y/bq/QDEBXvx0tjeJMYEODiy1snD1Zn+HYLo3yEIAKvVYHd2kX2XgNR9uew+XMyu6tfHa2zf9wBPs22bwFjbIoG9o/z1wEVOiyaUnGmGARXFjnkZRoNC7NKlCxERESxatMhetmjRIq644gri4+NZvnx5rfKUlBT71yaTiby8PBYtWsStt95Kfn4+JpMJk8nElClT7OeVlJRw22234ePjQ3R0NG+//XatGDZt2sQFF1yAh4cHQUFB3HnnnRQVFdmPDx06tE4P/ujRo7nlllvsx/fu3cv9999v//zjmTlzpv34sa9jYxURERFp65b/ns2I15baE/5bB8by7b3nK+FvQk5OJjqG+HDNOdG8OLY3Cx4YytrHh/Ofm5O4e2g858YG4ubiRG6JhZ+3HWLa99u55u2V9Jj8A1f8cxlPfb2VbzdlcrCgzNG3Iq2MevrPNEsJPBvhmM+elN7gqkOHDmXhwoVMmjQJgIULF/LQQw9htVpZuHAhw4YNo6KighUrVjB9+vQ65ycnJ/Paa6/xxBNPsH37dgC8vb3tx19++WWeeuopHnnkEebOncvdd9/N4MGDSUhIoKSkhBEjRtC/f39Wr17NoUOH+POf/8z48eOZOXNmg+KfN28evXv35s477+SOO+6ot94111zDiBEj7O8XLVrETTfdxMCBAxv0OSIiIiKtWUlFJc9/t82+8FxUoAcvjult752W5hXo5cqwbqEM6xYKQEWllS0Z+aTuzWXtPtuIgEOF5WzYn8eG/Xm8+8seACIDPEisXhywX0wACWG+ODtpSoAcn5J+Oa6hQ4dy//33U1lZSWlpKevWrWPw4MFUVVXxj3/8A4CVK1dSWlpq7+k/lqurK35+fphMpuMO+R85ciT33HMPABMnTuTVV19l0aJFJCQkMGvWLEpLS/nvf/+Ll5cXAG+88QaXXXYZL7zwAqGhoSeNPzAwEGdnZ3x8fE445cDDwwMPDw8Adu3axfjx43n22WcZPnz4yb9JIiIiIq3YmrQcHpizgb1HSgC44bxoHhnZFS/tNe8wri5O9I0OoG+0bYSFYRik55ba1wRYszeX7VkFpOeWkp5byhfrMwDwcnWmb/TRXQL6RPvj62525K1IC9Iq/o9OS0vjqaeeYsGCBWRlZREREcGNN97Io48+iqtr/atd3nLLLbz//vu1ys477zxWrlxpf19eXs6ECRP46KOPKC0t5cILL+Rf//oXkZGRzXMzZk94JKN5rn0yzu5QVtigqikpKRQXF7N69Wpyc3Pp3LkzISEhDBkyhJtuuoni4mIWLVpEdHQ0HTp0aHQovXr1sn9d82Dg0KFDAPz222/07t3bnvADDBw4EKvVyvbt2xuU9DdWfn4+o0aN4pJLLuHBBx9s8uuLiIiItBRllipe/nE7//llD4YB4X7uvHB1LwZ3bufo0OQPTCYTUYGeRAV6Mrpve8C29sKG/fms2ZtD6t5c1u3Lo6i8kl9+z+aX37Orz4MuoT72HQKSYgKJCvTQAoFnqVaR9G/btg2r1cq///1vOnbsyObNm7njjjsoLi7mpZdeOuG5I0aMYMaMGfb3f3xIcN999/HVV18xe/ZsgoKCeOCBBxg1ahSpqak4OzfDghkmE7h6nbxec7BaG1y1Y8eOREZGsnDhQnJzcxkyZAhgW6gvLi6OZcuWsXDhQi644IJTCsVsrv3k0WQyYa2OzzCMen8g1ZQ7OTlh/GGNAovFckqxVFVVcc011+Dr68s777xzStcQERERaQ3W78/jgU/Ws+twMQBjEiN5fFQ3/DzUK9xa+LibGdQpmEGdggGoshrsOFhYa5eAfTklbMsqZFtWIbN+3QdAsLcbSTVbBcYG0D3CFzcXLRB4NmgVSf+IESNqzbvu0KED27dv58033zxp0u/m5lbv8O78/Hzeffdd/ve//zFs2DAAPvjgA6Kiovjpp5+4+OKLm+4mWqGUlBQWLVpEbm5urd7vIUOG8MMPP7By5UpuvfXWes93dXWlqqqq0Z/brVs33n//fYqLi+29/cuWLcPJycm+S0C7du3IzMy0n1NVVcXmzZtrTTVo6Offf//9bNq0idWrV+Pu7t7oeEVERERauvLKKv7x807eWrybKqtBOx83nr+qJxd2bfoRlHJmOTuZ6BruS9dwX27sHwPAoYIy1u47OiVg84F8sovK+X5LFt9vyQJsUwl6tfez7xKQGBNAkLebI29FmkmrSPqPJz8/n8DAwJPWW7RoESEhIfj7+zNkyBCeeeYZQkJCAEhNTcVisXDRRRfZ60dERNCjRw+WL19eb9JfXl5OeXm5/X1BQQFg62n+Y2+zxWLBMAysVqu9J9tRanrGa+I5mSFDhvDXv/4Vi8XC+eefbz/n/PPP5y9/+QtlZWUMGTLEXn7sf61WK9HR0RQVFTF//nx69+6Np6enfau/48VQU3bdddcxefJkbr75ZiZPnszhw4f561//yo033ki7du2wWq0MHTqUCRMm8NVXXxEfH89rr71GXl5erevGxMSwePFixo0bh5ubG8HBwXXuccaMGfzrX//i008/BSAjwzb1wtvbu9bCgzWsViuGYWCxWJpnJMhZrub/n1MdtSHS3NRGpaVTG5Xj2ZpZwMRPN7PtoG0npFE9w3hiVAIBnq4OaStqp80vwMOZC7sEc2EX29+/5ZYqNmUUsHZfnv2VW2JhTfVDgRqxQZ70jfYnMdqfflH+xLfzwuksXCCwtbTRhsbXKpP+Xbt2MX36dF5++eUT1rvkkksYO3YsMTEx7Nmzh8cff5wLLriA1NRU3NzcyMrKwtXVlYCA2luRhIaGkpWVVe91n3vuOaZOnVqn/Mcff7QntTVcXFwICwujqKiIioqKRtxl8yksbNi8/nPOOYfS0lI6d+6Mh4eH/eFGv379KCwsJC4uDj8/P3t5SUmJ/fpOTk706NGDW2+9lWuvvZacnBwmTpzIpEmTsFqtlJWV2c8DW099eXm5vWzOnDk8/PDDnHfeeXh4eHD55Zfz9NNP24+PGTOGNWvW8Kc//QkXFxfuvvtuBg0ahMVisdd56KGHuP/+++nUqRPl5eXk5h79gVbj559/pqqqitGjR9cqr4n1jyoqKigtLWXJkiVUVlY26PsojTd//nxHhyByQmqj0tKpjQpAlRV+yjDxfboTVsOEl4vBuA5W+nins2JRw3d1ai5qp2deJBAZAJf5w+Ey2FNosr+ySk2kHSkh7UgJn62zdYR5OBvE+hh08DGI84FobwO3s6jfq6W30Zr862RMxh8nRp9BU6ZMOW7yfKzVq1eTlJRkf5+RkcGQIUMYMmQI//nPfxr1eZmZmcTExDB79myuuuoqPvzwQ2699dZavfYAw4cPJz4+nrfeeuu41zleT39UVBTZ2dn4+vrWqltWVsb+/fuJjY11+NBxwzAoLCzEx8dHi3icorKyMtLS0oiKinL4v2dbZLFYmD9/PsOHD6+z7oNIS6A2Ki2d2qjU2HmwiIfmbWZzhq0z5KJuITx5WdcWMXxb7bRlyi+1sG6/bRTAun15bEjPp9RSe2Sus5OJrmE+R0cDRPsT7tf2/iZuLW20oKCA4OBg8vPz6+Shx3JoT//48eO59tprT1gnNjbW/nVGRgYpKSkMGDCAt99+u9GfFx4eTkxMDDt37gRsi9JVVFSQm5tbq7f/0KFDJCcn13sdNzc33Nzq/sA0m811GkVVVRUmkwknJyecnJwaHXNTqhn2XhOPNJ6TkxMmk+m4/9bSdPT9lZZObVRaOrXRs1eV1eCdpbt55ccdVFRZ8fMw8+QV3bm8d0SL6/RRO21Zgs1mhnf3ZHj3CAAsVVa2ZRbadwlI3ZtLZn4ZmzMK2JxRwP9W2hYIDPdzr7VLQNdwH1yc20au0dLbaENjc2jSHxwcfNx51sdz4MABUlJSSExMZMaMGaeUtB45coT9+/cTHh4OQGJiImazmfnz5zNu3DjANhpg8+bNTJs2rdHXFxERERFxlN2Hi5gwZwNr9+UBkNKlHc9f3YtQ37bXEyvNz+zsRM9IP3pG+nHrwDgAMvJKa+0SsDWzgMz8Mr7emMnXG22LbHuYnekT5W/fJaBfVAB+ni03cT4btIo5/RkZGQwdOpTo6GheeuklDh8+bD927Mr8CQkJPPfcc1x55ZUUFRUxZcoUrr76asLDw0lLS+ORRx4hODiYK6+8EgA/Pz9uv/12HnjgAYKCgggMDGTChAn07NnTvpq/iIiIiEhLZrUazFyexrQftlFmseLt5sITo7oxNimyxfXuS+sW4e9BhL8Hl/W2jQYoLq9kQ3oeqWm5pO7LZe3eXArKKlmx+wgrdh+xn9cpxJuk2AD6RQeQFBtIbJCn2uYZ1CqS/h9//JHff/+d33//ncjIyFrHjl2SYPv27eTn5wPg7OzMpk2b+O9//0teXh7h4eGkpKTw8ccf4+PjYz/n1VdfxcXFhXHjxlFaWsqFF17IzJkztTK7iIiIiLR4+3NKmDBnA7/uyQFgUMdgXhjTi/b+Hg6OTM4GXm4uJMcHkxxvG71ttRr8frjItlVgWi5r9+WyJ7uYnYeK2HmoiI9W7Qcg0Mu1+gGAbVpAz/Z+uJuVfzWXVpH033LLLdxyyy0nrXfsAwAPDw9++OGHk57j7u7O9OnTmT59+umEeFIOXC9RmpD+HUVERKQlMAyDD1ft45lvfqOkogpPV2ceHtmVG8+LVg+qOIyTk4nOoT50DvXhunOjAThSVG6bDrAvl9S0XDYeyCenuIKffjvIT78dBMDsbKJHez+SqtcG6BcTQIiPpqU0lVaR9LdmNYsrlJSU4OGhJ66tXc22GC15QQ8RERFp2zLySpn46UaW7swG4NzYQF4c24uYIC8HRyZSV5C3Gxd1D+Oi7rZp2eWVVWw+UMDa6nUB1uzNJbuonHXVuwa8s3QPANGBnvYFAhNjAugc6oOzkx5onQol/c3M2dkZf39/Dh06BICnp+Pmr1itVioqKigrK9Pq/Y1kGAYlJSUcOnQIf39/Tf8QERGRM84wDOampvPkV1spLK/EzcWJBy/uwm0D43BSMiSthJuLsz2RvwNbu96fU1prl4DtBwvZl1PCvpwSPlt3AAAfNxf6RPvbdwnoE+2Pt5vS2YbQd+kMqFlssCbxdxTDMCgtLcXDw0PDvk6Rv79/rcUjRURERM6EQwVlPPLZJn76zfb3ZJ8of14e15v4dt4Ojkzk9JhMJqKDPIkO8uSqfrb12wrKLKzfl8eavbbFAdfty6WwvJKlO7PtI1ycTJAQ5ltrNEBkgPKc41HSfwaYTCbCw8MJCQnBYrE4LA6LxcKSJUsYPHiwhqefArPZrB5+EREROaMMw+CrjZk88cVm8kosuDo7cd/wTtx5foc2sxe6yB/5upsZ3Lkdgzu3A6Cyysr2g4WsrZ4OkLo3l/TcUrZmFrA1s4D/rdwLQIiPm32XgMSYALpH+OHqov9PlPSfQc7Ozg5NGp2dnamsrMTd3V1Jv4iIiEgLd6SonMe/2My3m7IA6B7hyyvj+tAlzOckZ4q0LS7OTnSP8KN7hB83DYgF4GBBmX2XgNR9uWw5kM+hwnK+3ZRl/3/GzcWJ3pH+JMYGkFj9ICDAy9WBd+IYSvpFRERERFqY7zdn8ehnmzhSXIGLk4m/pHRk/AUdMat3XwSAUF93RvYMZ2TPcADKLFVs2J9n3yUgdV8ueSUWVqXlsCotx35eh3Ze9l0CEmMC6BDs3ebXxFDSLyIiIiLSQuSXWJj85WY+X58BQJdQH14e15se7f0cHJlIy+Zudua8DkGc1yEIsE2N2Z1dbHsAsDeXNXtz2HW4mN3Vr0/WpAPg72m2TwdIjAmgd6Q/Lm3sGYCSfhERERGRFmDhtkNM/HQjhwrLcTLBXUPiuW9YJ9xctKaQSGOZTCbi23kT386bcedEAZBbXMHafUe3CtywP4+8EgsLth1iwTbbIpkuTia6hfsQ5WRipCNvoAkp6RcRERERcaDCMgtPf/0bH6/ZD9iGH780tjf9ogMcHJlI2xLg5cqFXUO5sGsoABWVVn7LLLDvErBmbw4HC8rZeKAA56C2092vpF9ERERExEGW/Z7NQ3M3ciCvFJMJbhsYx4MXd8HdrN59kebm6uJE7yh/ekf5c/ugOAzD4EBeKat2Z7NnyzpHh9dklPSLiIiIiJxhxeWVPP/dNvtWY9GBnrw4ppd9PrKInHkmk4nIAE9Ce4XzbbqSfhEREREROQWr9uQwYc4G9uWUAHBT/xgmXZKAl5v+NBeRpqefLCIiIiIiZ0CZpYoXf9jOe8v2YBgQ4efOtDG9GdQp2NGhiUgbpqRfRERERKSZrduXywNzNrD7cDEA45IieWxUN3zdzQ6OTETaOiX9IiIiIiLNpLyyitd/2slbi3dhNSDEx43nr+7JBQmhjg5NRM4SSvpFRERERJrB5gP5TJizgW1ZhQCM7hPBlMu74+/p6uDIRORsoqRfRERERKQJWaqs/HPh77yx4HcqrQZBXq48c2UPRvQId3RoInIWUtIvIiIiItJEtmcV8sCc9Ww+UADAJT3CeHp0D4K83RwcmYicrZT0i4iIiIicpiqrwdtLdvPq/B1UVFnx8zDz5BXdubx3BCaTydHhichZTEm/iIiIiMhp2HW4iAlzNrBuXx4AFyaE8NxVPQnxdXdsYCIiKOkXERERETklVqvBjOVpTPt+G+WVVnzcXHjism6MSYxU776ItBhK+kVEREREGmnfkRImzN3Aqj05AJzfKZgXru5FhL+HgyMTEalNSb+IiIiISAMZhsGsX/fx7Le/UVJRhaerM49e2pXrz41W776ItEhK+kVEREREGiAjr5SJn25k6c5sAM6LC+TFMb2JDvJ0cGQiIvVT0i8iIiIicgKGYTAnNZ2nvtpKYXklbi5OTByRwC3JsTg5qXdfRFo2Jf0iIiIiIvU4VFDGw/M28fO2QwD0jfbn5bG96dDO28GRiYg0jJJ+EREREZE/MAyDLzdk8MQXW8gvteDq7MTfL+rMHed3wFm9+yLSiijpFxERERE5RnZROY99tpnvt2QB0KO9Ly+P7UOXMB8HRyYi0nhK+kVEREREqn23KZPHPt/MkeIKXJxM/PWCTtyTEo/Z2cnRoYmInBIl/SIiIiJy1ssrqWDyl1v4Yn0GAAlhPrw0tjc92vs5ODIRkdOjpF9EREREzmoLth1k0qebOFRYjpMJ7h4az70XdsLNxdnRoYmInDYl/SIiIiJyVioos/DUV1uZk5oOQHw7L14e14c+Uf6ODUxEpAkp6RcRERGRs87SnYeZOHcjGfllmEzw50FxPHBRF9zN6t0XkbZFSb+IiIiInDWKyyt57rvf+GDlPgBigjx5aWxvzokNdHBkIiLNQ0m/iIiIiJwVft19hAfnbmRfTgkANw+IYdIlCXi66k9iEWm79BNORERERNq0MksV077fzozlezAMaO/vwbQxvRjYMdjRoYmINDsl/SIiIiLSZq3dl8uETzawO7sYgGvPieLRS7vi4252cGQiImeGkn4RERERaXPKK6t4df5O3l6yC6sBob5uPH91L1K6hDg6NBGRM0pJv4iIiIi0KZvS83lgznp2HCwC4Mq+7ZlyWXf8PNW7LyJnHyX9IiIiItImWKqsvLHgd95Y+DtVVoNgb1eeubInF3cPc3RoIiIOo6RfRERERFq9bVkFPPDJBrZkFABwac9wnryiO0Hebg6OTETEsZT0i4iIiEirVVll5d9LdvPaTzuwVBn4e5p56ooeXNY7wtGhiYi0CEr6RURERKRV+v1QEQ/M2cCG/XkADOsawrNX9STEx92xgYmItCBK+kVERESkVamyGsxYtocXf9hOeaUVH3cXJl/Wnav7tcdkMjk6PBGRFkVJv4iIiIi0GnuPFDNhzgZWp+UCcH6nYKaN6UW4n4eDIxMRaZmcHB1AQ6SlpXH77bcTFxeHh4cH8fHxTJ48mYqKihOeZzKZjvt68cUX7XWGDh1a5/i1117b3LckIiIiIo1gtRr8b0UaI15byuq0XLxcnXn2yp7897ZzlfCLiJxAq+jp37ZtG1arlX//+9907NiRzZs3c8cdd1BcXMxLL71U73mZmZm13n/33XfcfvvtXH311bXK77jjDp588kn7ew8P/eIQERERaSkO5JXy0NwNLPv9CAD9OwTy4pjeRAV6OjgyEZGWr1Uk/SNGjGDEiBH29x06dGD79u28+eabJ0z6w8Jq78n6xRdfkJKSQocOHWqVe3p61qkrIiIiIo5lGAafrNnPU1//RlF5Je5mJyaNSODmAbE4OWnuvohIQ7SKpP948vPzCQwMbHD9gwcP8s033/D+++/XOTZr1iw++OADQkNDueSSS5g8eTI+Pj71Xqu8vJzy8nL7+4IC236wFosFi8XSiLs4s2pia8kxytlNbVRaOrVRaenaUhs9WFDGo19sZfGObAD6Rvkx7eoexAZ5UVVVSVWVgwOUU9aW2qm0Ta2ljTY0PpNhGEYzx9Lkdu3aRb9+/Xj55Zf585//3KBzpk2bxvPPP09GRgbu7ke3cXnnnXeIi4sjLCyMzZs38/DDD9OxY0fmz59f77WmTJnC1KlT65R/+OGHeHpqmJmIiIjIqTIMSM028ekeJ0qqTLiYDEZGWUmJMFDnvojIUSUlJVx//fXk5+fj6+tbbz2HJv31Jc/HWr16NUlJSfb3GRkZDBkyhCFDhvCf//ynwZ+VkJDA8OHDmT59+gnrpaamkpSURGpqKv369TtuneP19EdFRZGdnX3Cb7ajWSwW5s+fz/DhwzGbzY4OR6QOtVFp6dRGpaVr7W30SFE5j3/5G/N/OwRAz/a+vHBVDzqFeDs4MmlKrb2dStvXWtpoQUEBwcHBJ036HTq8f/z48SddKT82Ntb+dUZGBikpKQwYMIC33367wZ+zdOlStm/fzscff3zSuv369cNsNrNz5856k343Nzfc3NzqlJvN5hbdKGq0ljjl7KU2Ki2d2qi0dK2xjX67KZPHPt9MTnEFZmcT917Qif8bGo/ZuVVsNiWnoDW2Uzm7tPQ22tDYHJr0BwcHExwc3KC6Bw4cICUlhcTERGbMmIGTU8N/Abz77rskJibSu3fvk9bdsmULFouF8PDwBl9fRERERE5NbnEFT3y5ha82ZACQEObDy+N60z3Cz8GRiYi0Da3i0WlGRgZDhw4lKiqKl156icOHD5OVlUVWVlategkJCXz22We1ygoKCpgzZ85x5/7v2rWLJ598kjVr1pCWlsa3337L2LFj6du3LwMHDmzWexIRERE52/209SAXvbaErzZk4OxkYnxKR74cP0gJv4hIE2oVq/f/+OOP/P777/z+++9ERkbWOnbskgTbt28nPz+/1vHZs2djGAbXXXddneu6urry888/8/rrr1NUVERUVBSXXnopkydPxtnZuXluRkREROQsV1Bm4cmvtjI3NR2AjiHevDy2N72j/B0bmIhIG9Qqkv5bbrmFW2655aT1jrcm4Z133smdd9553PpRUVEsXrz4dMMTERERkQZasuMwEz/dSGZ+GSYT3HF+B/4+vDPuZnW4iIg0h1aR9IuIiIhI61ZUXsmz3/7Gh7/uAyA2yJOXxvYmKTbQwZGJiLRtSvpFREREpFmt2HWEB+duID23FIBbkmN5aEQXPF31p6iISHPTT1oRERERaRalFVW88P02Zi5PA6C9vwcvju1FcnzDdm8SEZHTp6RfRERERJpc6t4cJszZyJ7sYgCuOzeKRy/threb/vwUETmT9FNXRERERJpMmaWKV3/awTtLdmM1IMzXneev7snQLiGODk1E5KykpF9EREREmsSm9Hz+/sl6dh4qAuCqfu2ZfFl3/DzMDo5MROTspaRfRERERE5LRaWVNxbs5J+LdlFlNQj2duPZK3twUfcwR4cmInLWU9IvIiIiIqfst8wCHvhkA1szCwAY1SucJ6/oQaCXq4MjExERUNIvIiIiIqegssrKW4t38frPO7FUGQR4mnlqdA9G9YpwdGgiInIMJf0iIiIi0ii/HyrkgU82sCE9H4Dh3UJ59sqetPNxc3BkIiLyR0r6RURERKRBqqwG7/2yhxd/3E5FpRUfdxemXt6dK/u2x2QyOTo8ERE5DiX9IiIiInJSadnFTJizgTV7cwEY0rkdL1zdizA/dwdHJiIiJ6KkX0RERETqZbUa/G/lXp7/bhulliq8XJ15fFQ3rjknSr37IiKtgJJ+ERERETmu9NwSHpq7keW7jgAwoEMQ08b0IirQ08GRiYhIQynpFxEREZFaDMPg49X7efqb3ygqr8TD7MzDIxO48bwYnJzUuy8i0poo6RcRERERu6z8MibN28ii7YcBSIoJ4KWxvYkN9nJwZCIiciqU9IuIiIgIhmHw2boDTPlyCwVllbi6OPHgRV24bVAczurdFxFptZT0i4iIiJzlDheW88hnm5i/9SAAvSP9eHlcbzqG+Dg4MhEROV1K+kVERETOYt9szOSxzzeRW2LB7GzivmGduWtwB1ycnRwdmoiINAEl/SIiIiJnoZziCp74YjNfb8wEoGu4Ly+P7U23CF8HRyYiIk1JSb+IiIjIWWb+1oM8PG8T2UXlODuZ+MvQeMZf0AlXF/Xui4i0NUr6RURERM4S+aUWpn61hXlrDwDQKcSbl8f1plekv2MDExGRZqOkX0REROQssHjHYSbO3UhWQRkmE9w5uAP3D+uMu9nZ0aGJiEgzUtIvIiIi0oYVlVfyzDdb+WjVfgDigr14aWwvEmMCHRyZiIicCUr6RURERNqo5buyeWjuRtJzSwG4JTmWiSMS8HBV776IyNlCSb+IiIhIG1NSUcmr3+1g5vI0ACIDPHhxTG8GxAc5NjARETnjlPSLiIiItCF7CuGVf65kb04JANefF80jI7vi7aY/+0REzkb66S8iIiLSylVWWVm0/TAfr97HT785Y1BCuJ87L1zdi8Gd2zk6PBERcSAl/SIiIiKt1M6DhcxJTWfe2gNkF5VXl5q4sm8EUy7vgZ+H2aHxiYiI4ynpFxEREWlF8kstfLkhg7lr9rMhPd9eHuTlyhW9w2lXtIs/X9UDs1kJv4iIKOkXERERafGqrAbLfs9mTmo6P2zJoqLSCoCLk4mUhBDGJkaSkhAC1iq+/XaXg6MVEZGWREm/iIiISAuVll3M3NR0Pl2bTmZ+mb28S6gPY5MiGd23PcHebvZyi7XKEWGKiEgLpqRfREREpAUpKq/k242ZzE1NZ1Vajr3cz8PMFX0iGJsYRY/2vphMJgdGKSIirYWSfhEREREHMwyDX/fkMGdNOt9tzqSkwtZj72SC8zu1Y2xSJMO6huJudnZwpCIi0too6RcRERFxkAN5pXyams7c1HT25ZTYy+OCvRiTGMnV/SIJ83N3YIQiItLaKekXEREROYPKLFX8sCWLOWvSWbYrG8OwlXu5OjOqVwRjkyJJjAnQ8H0REWkSSvpFREREmplhGKzbn8ecNel8vSGDwvJK+7EBHYIYkxjJJT3D8HTVn2YiItK09JtFREREpJkcKihj3roDzE1N5/dDRfby9v4ejEmMZExiJFGBng6MUERE2jol/SIiIiJNqLyyigW/HWJOajqLdxymymobv+9uduKSHuGMTYykf4cgnJw0fF9ERJqfkv6zyK97cthTCNlF5YT5u2iuoIiISBPafCCfuanpfLH+ALklFnt5v2h/xiZFcWmvcHzdzQ6MUEREzkZK+s8iT3z5G7uzXXht82I8zM5EBXoQFeBJVGD1K8CD6CBPogI88XJT0xARETmZnOIKPl93gDmp6fyWWWAvD/V146p+tuH78e28HRihiIic7ZTZnUUiA9zJLSgi32Ki1FLFjoNF7DhYdNy6QV6uRAZ6El39MCDK/rUn4f7umJ2dznD0IiIiLUNllZXFOw4zZ006P287iKXKNnzf1dmJ4d1CGZMUyfkdg3HR70oREWkBlPSfRd69OZFvv/2WYReN4HBxJftzS9iXU8L+nFL255SwP7eE/Tkl5JZYOFJcwZHiCjbsz6tzHWcnE+F+7vaHANFBnkQe82AgyMtVUwdERKTN+f1QIXPWpDNv3QEOF5bby3u292NMYiSX944gwMvVgRGKiIjUpaT/LOTq4kRssBexwV7HPV5YZmF/Tin7ckpItz8YKKl+X0p5pZX03FLSc0uBI3XO93R1rp424FE9baB6lECgrUzbEYmISGuRX2rhqw0ZzElNr/UgPMjLldF92zMmMZKu4b6OC1BEROQklH1JHT7uZrpFmOkWUfePGKvV4HBRuX1kwL4jpfYRA+k5JWQWlFFSUcX2g4VsP1h43OsHe7sSaX8Q4GEfMRAV6Em4n7uGQ4qIiENVWQ2W78pmzpp0ftiSRXmlFbCNdEvpEsLYpEhSuoTg6qLfVyIi0vK1mqT/8ssvZ/369Rw6dIiAgACGDRvGCy+8QERERL3nGIbB1KlTefvtt8nNzeW8887jn//8J927d7fXKS8vZ8KECXz00UeUlpZy4YUX8q9//YvIyMgzcVutjpOTiVBfd0J93UmKDaxzvLyyioy8MvvogKPTBmwjB/JLLWQXVZBdVMH6eqYOtPf3qLPIYM3aAoGaOiAiIs1k75Fi5qam82lqOhn5ZfbyzqHejE2MYnTf9rTzcXNghCIiIo3XapL+lJQUHnnkEcLDwzlw4AATJkxgzJgxLF++vN5zpk2bxiuvvMLMmTPp3LkzTz/9NMOHD2f79u34+PgAcN999/HVV18xe/ZsgoKCeOCBBxg1ahSpqak4OzufqdtrM9xcnIkL9iKunqkD+aUW9teaNmB7GLA/t4T0nFIqqqzsq55KcLypA16uzsfsNuBJdM0Ugur3Hq76NxMRkYYrLq/km02ZzE1NZ9WeHHu5r7sLl/eJYGxiFL0i/fTAWUREWq1Wk/Tff//99q9jYmKYNGkSo0ePxmKxYDbX3fPWMAxee+01Hn30Ua666ioA3n//fUJDQ/nwww+56667yM/P59133+V///sfw4YNA+CDDz4gKiqKn376iYsvvvjM3NxZxM/DjF97P3q096tzzGo1OFRYXj1toOSYaQO2BwMHC8sorqhiW1Yh27LqmzrgZn8QUDNtILJ6CkG4nwfOTvqjTUTkbGcYBqv25DAnNZ1vN2VSUlEFgMkE53dqx9jESIZ3C8XdrAfJIiLS+rWapP9YOTk5zJo1i+Tk5OMm/AB79uwhKyuLiy66yF7m5ubGkCFDWL58OXfddRepqalYLJZadSIiIujRowfLly+vN+kvLy+nvPzoqr0FBbZ9eS0WCxaLpSlusVnUxNaSYwzydCbI04c+7X3qHCu3VHEgr4z0vJrdBkrZX72g4P7cUgrLKskuKie7qJy1+/LqnO/iZCLC392200BA9VaEAR7VOw944O9hVk+Og7WGNipnN7XR1i0zv4x56zKYt+4A+3JK7eUxgZ5c3S+C0X0iCPdzry61YrFYHRPoaVAbldZA7VRautbSRhsaX6tK+idOnMgbb7xBSUkJ/fv35+uvv663blZWFgChoaG1ykNDQ9m7d6+9jqurKwEBAXXq1Jx/PM899xxTp06tU/7jjz/i6enZ4PtxlPnz5zs6hNMWUP3q5Qf4AbFQUglHyuBIuanOf3PKodIK+3JKq//Qy6lzTTdngyA3CHIzCHKv/d9AN9DMgTOnLbRRadvURluPiirYlGvi10MmduSbMLA93HVzMugTZHBeiJUOPgWYigtYt2wb6xwcb1NRG5XWQO1UWrqW3kZLSkoaVM+hSf+UKVOOmzwfa/Xq1SQlJQHw4IMPcvvtt7N3716mTp3KzTffzNdff33C3tk/HjMM46S9uSer8/DDD/P3v//d/r6goICoqCguuugifH1b7rY9FouF+fPnM3z48HpHSLRVVcdMHUjPLWV/ztERAum5pRwsLKe8ykRGCWSUHP/fPsTHjcgADyKrFxqMrB4pEBXgQaivu6YONIGzuY1K66A22joYhsGG9Hw+XZfBN5uyKCyrtB87NzaAq/tFMKJ7aJvcQlZtVFoDtVNp6VpLG60ZcX4yDv1tN378eK699toT1omNjbV/HRwcTHBwMJ07d6Zr165ERUWxcuVKBgwYUOe8sLAwwNabHx4ebi8/dOiQvfc/LCyMiooKcnNza/X2Hzp0iOTk5HpjcnNzw82t7uq9ZrO5RTeKGq0lzqZkBqLdXIkOrjttAKDMUlX9MKCk1poC+3NsZYXllRwqLOdQ4fGnDpida3YdOHaRwaNbEvpp6kCjnI1tVFoXtdGW6VBhGZ+tPcDc1HR2Hiqyl7f39+DqxEjG9IskOqjlj8hrCmqj0hqonUpL19LbaENjc2jSX5PEnwrDMABqza0/VlxcHGFhYcyfP5++ffsCUFFRweLFi3nhhRcASExMxGw2M3/+fMaNGwdAZmYmmzdvZtq0aacUl7RO7mZnOoZ40zHEu84xwzDIL7XU2W2gZkvC9NxSLFUGaUdKSDty/CE2Pm4u1Q8EPKofBhx9OBAZ4KHFokRETlFFpZUF2w4yZ006i3Ycpspq+/vAzcWJS3qEMTYpigEdgnDSaCwRETlLtYpxbatWrWLVqlUMGjSIgIAAdu/ezRNPPEF8fHytXv6EhASee+45rrzySkwmE/fddx/PPvssnTp1olOnTjz77LN4enpy/fXXA+Dn58ftt9/OAw88QFBQEIGBgUyYMIGePXvaV/MXMZlM+Hu64u/pSq9I/zrHq6wGWQVl7M+p2W2gejvCXNsDgsOF5RSWV7I1s4CtmccfghPq62YfHRBp33nAg+ggT0J93PXHqojIH2zJyGduajpfrM8gp7jCXt432p+xiVGM6h2Or3vL7Z0RERE5U1pF0u/h4cG8efOYPHkyxcXFhIeHM2LECGbPnl1rmP327dvJz8+3v3/ooYcoLS3lnnvuITc3l/POO48ff/wRH5+jQ7xfffVVXFxcGDduHKWlpVx44YXMnDkTZ2f1vErDODvZhva39/egf4egOsdLK6pIzz122kD1aIHqV3FFFQcLyjlYUM6avbl1znd1dqJ9QPXUgYCjIwVqtiT089QftSJydsgtruDz9QeYsya91kPUEB83ruoXyZjE9nQMOf40LhERkbNVq0j6e/bsyYIFC05ar2bIfw2TycSUKVOYMmVKvee4u7szffp0pk+ffrphihyXh6sznUJ96BRa9w9RwzDILbHYRwkcnTZgezCQkVdKRZWVPdnF7MkuPu71fd1djj4EqH4wUDN9IDLAAzcXPcASkdarssrKkp2HmbMmnZ9+O4ilyva73uxsYni3UMYmRnF+p2BcnJ0cHKmIiEjL1CqSfpG2ymQyEejlSqCXK72j/Oscr6yykplfZtt14Jj1BGrWF8guKqegrJItGQVsyag7dcBkglAf9+ppAx720QE1DwlCfNw0dUBEWqTfDxUxJ3U/n609wKHCo+v3dI/wZWxiJFf0aU+Al6sDIxQREWkdlPSLtGAuzk72Xnvi6x4vqagkPbfUvttAzcOA9OqvSyqqyCooI6ugjFVpdc93dXGq3nqw9m4DkdUPBvw8NHVARM6cgjILX23IYG5qOuuO2Skl0MuVK/pEMDYxim4RLXdrXBERkZZISb9IK+bp6kLnUB861zN1IKe4wr6oYM0aAjWjBTLyyqiotLL7cDG7Dx9/6oCfh/nojgMBR3cdiA70pL2/B64uGk4rIqfHajVYvusIc1L38/3mLMorrYBtvZSULu0YkxjFBQkh+nkjIiJyipT0i7RRJpOJIG83grzd6BsdUOe4ferAMQ8C9uUcfThwpLiC/FIL+QcsbD5w/KkD4b7uRFY/EIj+w5aE7bw1dUBE6rfvSAlzU/fz6doDHMgrtZd3CvFmbFIko/u2J8TH3YERioiItA1K+kXOUsdOHUg+zvHi8srqhQVr7zZQU1ZqqSIjv4yM/DJW7cmpc75bzdSBY3YaiDrmwYCPttISOesUl1fy3eYs5qzZz6/H/NzwcXfh8t4RjE2KonekHyaTHhiKiIg0FSX9InJcXm4uJIT5khBWd/6sYRhkF1Ucs9vA0fUE9uWUkJlfSnmllV2Hi9lVz9QBf09znYcB4b6uZJfZhvuKSNtgGAar03KZs2Y/327KpLiiCrCNFhrUMZgxiZFc3D0Md7N2GhEREWkOSvpFpNFMJhPtfNxo5+NGv+NMHbBUWcnIK2V/TukxCwzWjBQoJae4grwSC3kl+WxMz//D2S68tPlnOoX60CXUhy5htjULuoT5EOLjph5AkVYiI6+UeWvTmZuaTtqREnt5bJAnYxIjuapfJBH+Hg6MUERE5OygpF9EmpzZ2YmYIC9igryOe7yovPKY0QFHHwbsO1JMWnYRpRYrG9PrPhDw9zTbHgCE+tA5rPqhQKgPfp6aKiDSEpRZqvhx60HmrNnPL79nY1QP2vF0debSnuGMTYrinNgAPbwTERE5gxqV9G/fvp2PPvqIpUuXkpaWRklJCe3ataNv375cfPHFXH311bi5uTVXrCLSRni7udA13Jeu4bWnDlgsFr765lu6nzuE3UdK2ZZVyI6DhWw/WEhadjF5JRZW7cmps4ZAmK979UMAb/uogE4hPni4ariwSHMzDIMN6fnMWbOfrzZkUFBWaT92blwgYxMjGdkzHC839TOIiIg4QoN+A69bt46HHnqIpUuXkpyczLnnnsvo0aPx8PAgJyeHzZs38+ijj/LXv/6Vhx56iPvuu0/Jv4icEmcTdGjnRZcIfy7pGW4vL7NUsetwEduzbA8BdmQVsuNgEQfySskqKCOroIwlOw7b65tMEBPoaX8I0DnUh4QwH2KDvTA7a+svkdN1qLCMz9cdYG5qOjsOFtnL2/t7cHW/9lydGFnvaB8RERE5cxqU9I8ePZoHH3yQjz/+mMDAwHrrrVixgldffZWXX36ZRx55pMmCFBFxNzvTPcKP7hF+tcoLyizsPFjI9qwi26iA6ocCOcUVpB0pIe1ICT9uPWivb3Y2Ed/u6IiAmnUD2vt7aItBkZOoqLSyYNsh5qbuZ+H2w1RVL7rp5uLEiB5hjE2MIjk+SP8viYiItCANSvp37tyJq6vrSesNGDCAAQMGUFFRcdqBiYg0hK+7mcSYQBJjaj+QPFxYbn8IUDNFYEdWIcUVVWzLKmRbViFsOFrf09W5evFAb7qE+VavG+BNO28tHijyW2YBc9ak8/n6A+QUH/0d3yfKn7FJkYzqFYGfh9bWEBERaYkalPQ3JOE/nfoiIk2tZneBgR2D7WVWq8GBvNJaDwG2ZRWy+3AxJRVVbNifx4b9ebWuE1C9eGBC2NHFAzuF+ijBkTYvt7iCL9YfYO7adDYfKLCXt/Nx46p+7RmbGEnHEB8HRigiIiIN0ahVdQoLC9mxYwddunTB29ubtWvX8tprr1FaWsro0aO54YYbmitOEZHT5uRkIirQk6hATy7sGmovt1RZ2XukmO1ZRWw/WMj2rAJ2HCwi7UgxuSUWft2Tw69/WDww3M/dPj2gZqpAxxBv7TUurVpllZWlO7OZk7qfn7YeoqLKCtimxQzrGsrYpEgGd2qHi9bFEBERaTUanPQvWbKEUaNGUVRUREBAAB999BFjxoyhffv2ODs7M2/ePEpKSrjjjjuaM14RkSZndnaiY4gPHUN8uJSjiweWVtRePLBmqkBmfpn9tWj70cUDnUwQG+RF52O3FAzzITbIU0mStGi7DhcxZ00689amc6iw3F7eLdyXsUmRXNGnPYFeGsUnIiLSGjU46X/ssccYO3YsU6dOZcaMGVxzzTWMHz+eZ599FoCnn36af/7zn0r6RaTN8HB1pkd7P3q0r714YH6pbfFA+5aC1Q8F8kos7M4uZnd2Md9vybLXd3V2Ij7E27alYFj1VIFQ2+KBWi9AHKWgzMI3GzOZs2Y/a/fl2csDPM1c0ac9Y5Mi6yycKSIiIq1Pg5P+jRs38vbbbxMZGcnEiROZMmUK11xzjf34tddeywsvvNAsQYqItCR+HmaSYgNJij26eKBhGBwuKrc9ALAvHljEzoOFlFRU8VtmAb9lFtS6jrebC51Cve0jArpUjxAI9taWp9I8rFaDFbuPMGfNfr7fkkWZxTZ839nJxNDO7RiTGMmFXUNxddHIFBERkbaiwUl/QUGBfbs+V1dXPD098fE5uoCPj48PJSUlTR+hiEgrYDKZCPFxJ8THnfM7tbOXW60G6bmltoUDj5kisOtwEUXllazbl8e6Y3pZAYK8XI9uKVg9KqBzqDc+7lo8UE7N/pwS5qSm82lqOgfySu3lHUO8GZsYyZV92xPi6+7ACEVERKS5NDjpN5lMtYah/vG9iIjU5eRkIjrIk+ggT4Z3O7p4YEWllbQjxUdHBVRPEdiXU8KR4gpW7D7Cit1Hal2rvb+H/SFAlzBvOof6EN9OiwfK8ZVUVPLtpizmpu5n5e6jC1H6uLtwWe8IxiZG0ifKX7/LRURE2rgGJ/2GYXDhhRfi4mI7paSkhMsuu8y+PV9lZWXzRCgi0ga5ujhV9+DX3vKspKKS3w8V2R8G1KwbcLCgnAN5pRzIK2XBtkP2+s5OJmKDPI8+DKieIhAb5IWzk5K5s41hGKzZm8ucNfv5ZmMmxRVVAJhMMDA+mLFJkVzcPUwPikRERM4iDU76J0+eXOv9FVdcUafO1VdfffoRiYicxTxdXegV6U+vSP9a5XklFew4eMyWgllFbMsqoKCskl2Hi9l1uJhvNx2zeKCLE51CvO0PAWrWDQj3c1fPbhuUmV/KvLUHmJuazp7sYnt5TJAnY/pFclViJO39PRwYoYiIiDjKKSf9IiJy5vh7unJuXCDnxtVePPBQ4dHFA2vWDdhxsJAyi5UtGQVsyai9eKCPmwudq0cFJNinCvhoO7ZWqMxSxfytB5mTms4vOw9jNWzlnq7OjOwZztjESM6NC9RDHhERkbNcg5N+ERFpWUwmE6G+7oT6ujO489HFA6usBum5JbapAcc8DNh9uJjC8kpS9+aSuje31rWCvd3s6wTUPAzoFOqDt5t+TbQkhmGw6UA+c9ak88X6AxSUHZ1ad25sIGOSIrm0Zzhe+ncTERGRag36q6Bv374N7ilYu3btaQUkIiKnx9nJREyQFzFBXlzcPcxeXlFpZXd20TGLBxaxo3rxwOyicrJ/L2fZ77UXD4wM8Di6pWD1w4AO7bxwc9Gc8DPpcGE5n6+zDd/ffrDQXh7h587ViZFc3S+S2GAvB0YoIiIiLVWDkv7Ro0fbvy4rK+Nf//oX3bp1Y8CAAQCsXLmSLVu2cM899zRLkCIicvpcXZxICPMlIcy3VnlxeSU7DxXVGhWwLauQw4XlpOeWkp5bys/HLB7o4mQiLtjLvlZAzRSB6EBPLR7YhCxVVhZsO8ScNeks2n6Iyurx+64uTozoHsbYpEiS44P1PRcREZETalDSf+x8/j//+c/ce++9PPXUU3Xq7N+/v2mjExGRZufl5kKfKH/6RPnXKs8prrCvEXDsugGFZbaHBDsPFfENmfb67mYnOoXU3lIwIcyXUF83zStvhN8yC5ibms7n6w5wpLjCXt47yp+xiZFc1jsCPw+zAyMUERGR1qTRk/7mzJnDmjVr6pTfeOONJCUl8d577zVJYCIi4liBXq707xBE/w5B9jLDMMgqKKuzpeDOg0WUWaxsOpDPpgP5ta7j6+5ydEvBY3YS8PfU4oE18koq+GJ9BnNS97P5wNHFF4O93biqX3vGJkbS6Q/bO4qIiIg0RKOTfg8PD3755Rc6depUq/yXX37B3d29yQITEZGWx2QyEe7nQbifB0O7hNjLq6wG+3JK7CMCdhy0jQrYk11MQVklq9NyWZ1We/HAEB+3Og8DOoV64+l6dixCV2U1WLLzMHPXpDN/60EqqqwAmJ1NXJgQytikSAZ3bofZ2cnBkYqIiEhr1ui/rO677z7uvvtuUlNT6d+/P2Cb0//ee+/xxBNPNHmAIiLS8jlXz/OPC/ZiRI+jiweWV1ax+3Dx0S0Fq/+bnlvKocJyDhWWs3Rntr2+yQRRAZ5HdxGofhgQF+yFq0vbSH53HS5ibmo689amc7Cg3F7eNdyXsYmRXNEngiBvNwdGKCIiIm1Jo5P+SZMm0aFDB15//XU+/PBDALp27crMmTMZN25ckwcoIiKtl5uLM13DfekaXnvxwKLyStt6AccsHrg9q4jsonL25ZSwL6eEn347aK/v4mSiQzsvuoT50iXU2z46ICrAE6dWsJBdYZmFrzdmMmfNftbuy7OX+3uaGd2nPWMSI+nR3s9xAYqIiEibdUpjKMeNG6cEX0RETpm3mwv9ogPoFx1Qq/xIUfkxIwKK7A8GCssr2XGwiB0Hi/jqmPoeZmc6H/MQoGaEQDsfxy8eaLUarNx9hDmp6Xy3OZMyi234vpMJhnRux9ikKC7sGqLtD0VERKRZNcvEScMwHP7HloiItD5B3m4ke7uRHB9sLzMMg4z8sqOjArJsCwj+friIUksVG9Lz2ZBee/FAf0+z7UFAqG2KQEKYD51DfPDzbP5V7/fnlDA3NZ1P16aTnltqL49v58XYpCiu6tueEF+tgSMiIiJnRoOS/q5du/L4448zZswYXF3rX215586dvPLKK8TExDBp0qQmC1JERM5eJpOJ9v4etPf3ICXh6OKBlVVW9uaU2B8G1KwbkJZdTF6JhVV7cli1J6fWtcJ83avXCTi6pWDHEG88XE+vt720oorvNmcyZ006K3YfsZf7uLkwqncEY5Mi6RvlrwfiIiIicsY1KOn/5z//ycSJE/nLX/7CRRddRFJSEhEREbi7u5Obm8vWrVv55Zdf2Lp1K+PHj+eee+5p7rhFROQs5+LsRHw7b+LbeXNJz3B7eZmlil2Hi45uKZhVyI6DRRzIKyWroIysgjKW7Dhsr28yQUyg59FdBKoXD4wN9jrhyvmGYZC6N5e5qel8vTGTovJK+/WS44MYmxjFxd3DTvuBgoiIiMjpaFDSf8EFF7B69WqWL1/Oxx9/zIcffkhaWhqlpaUEBwfTt29fbr75Zm688Ub8/f2bOWQREZH6uZud6R7hR/eI2gvjFZRZ2Hmw6OiWgtUjA3KKK0g7UkLakRJ+3Hp08UCzs4n4dt5HtxUM9aFDsDt55fDW4t18tj6T3dnF9vrRgZ6MSYzkqn7tiQzwPGP3KyIiInIijZrTn5ycTHJycnPFIiIi0mx83c0kxgSQGFN78cDsonLbA4CahwHV6wYUV1SxrXr9gNpcgN8B20KCI3uGMzYpknNjA1vFTgIiIiJydmmWhfxERERai2BvN4I7ujGw49HFA61WgwN5pbUeAmw/WMTvhwqxVBkkxfgzLimakb3C8XbTr1IRERFpufSXioiIyB84OZmICvQkKtCTC7uG2stLysr54pvvGXP5uZjNzb8TgIiIiMjpqn+FIhEREanF7OyEpx6Xi4iISCuipF9ERERERESkjVLSLyIiIiIiItJGNVnSv3btWkaNGtVUlxMRERERERGR09SopH/+/Pk8+OCDPPLII+zevRuAbdu2MXr0aM455xwqKyubJUgRERERERERabwGJ/3vv/8+F198MTNmzOD555+nf//+fPDBB5x77rkEBASwYcMGvv/+++aMVUREREREREQaocFJ/6uvvsqzzz5LdnY2s2fPJjs7m1dffZV169YxY8YMevTo0ZxxioiIiIiIiEgjNTjp37VrF9dccw0AY8aMwdnZmVdeeYX4+PhmC+5Yl19+OdHR0bi7uxMeHs5NN91ERkZGvfUtFgsTJ06kZ8+eeHl5ERERwc0331znnKFDh2IymWq9rr322ua+HREREREREZFm1+Ckv7i4GC8vL9tJTk64u7sTFRXVbIH9UUpKCp988gnbt2/n008/ZdeuXYwZM6be+iUlJaxdu5bHH3+ctWvXMm/ePHbs2MHll19ep+4dd9xBZmam/fXvf/+7OW9FRERERERE5IxwaUzlH374AT8/PwCsVis///wzmzdvrlXneEl1U7j//vvtX8fExDBp0iRGjx6NxWLBbDbXqe/n58f8+fNrlU2fPp1zzz2Xffv2ER0dbS/39PQkLCysWeIWERERERERcZRGJf1/+tOfar2/6667ar03mUxUVVWdflQnkZOTw6xZs0hOTj5uwl+f/Px8TCYT/v7+tcpnzZrFBx98QGhoKJdccgmTJ0/Gx8en3uuUl5dTXl5uf19QUADYphRYLJbG3cwZVBNbS45Rzm5qo9LSqY1KS6c2Kq2B2qm0dK2ljTY0PpNhGEYzx9JkJk6cyBtvvEFJSQn9+/fn66+/JigoqEHnlpWVMWjQIBISEvjggw/s5e+88w5xcXGEhYWxefNmHn74YTp27FhnlMCxpkyZwtSpU+uUf/jhh3h6ejb+xkREREREREQaoaSkhOuvv578/Hx8fX3rrefQpL++5PlYq1evJikpCYDs7GxycnLYu3cvU6dOxc/Pj6+//hqTyXTCa1gsFsaOHcu+fftYtGjRCb8hqampJCUlkZqaSr9+/Y5b53g9/VFRUWRnZ5/w2o5msViYP38+w4cPb9QICZEzRW1UWjq1UWnp1EalNVA7lZautbTRgoICgoODT5r0N3h4/5IlSxpUb/DgwQ29JOPHjz/pSvmxsbH2r4ODgwkODqZz58507dqVqKgoVq5cyYABA+o932KxMG7cOPbs2cOCBQtOmpT369cPs9nMzp0760363dzccHNzq1NuNptbdKOo0VrilLOX2qi0dGqj0tKpjUproHYqLV1Lb6MNja3BSf/QoUPrPVbT024ymaisrGzoJe1J/KmoGaBwbI/7H9Uk/Dt37mThwoUNmgqwZcsWLBYL4eHhpxSXiIiIiIiISEvR4C37cnNzj/s6cOAADz74IG5ubiQkJDRLkKtWreKNN95g/fr17N27l4ULF3L99dcTHx9fq5c/ISGBzz77DIDKykrGjBnDmjVrmDVrFlVVVWRlZZGVlUVFRQUAu3bt4sknn2TNmjWkpaXx7bffMnbsWPr27cvAgQOb5V5EREREREREzpQG9/TXbNVXw2q18t577zF16lScnJz45z//WWd1/6bi4eHBvHnzmDx5MsXFxYSHhzNixAhmz55da5j99u3byc/PByA9PZ0vv/wSgD59+tS63sKFCxk6dCiurq78/PPPvP766xQVFREVFcWll17K5MmTcXZ2bpZ7ERERERERETlTGrVlX4158+bxyCOPcPjwYR5++GH++te/HneOe1Pp2bMnCxYsOGm9Y9ckjI2N5WRrFEZFRbF48eLTjk9ERERERESkJWrw8H6AxYsX079/f2666Sauuuoqdu/ezYQJE5o14RcRERERERGRU9Pgnv6RI0fy888/c+utt/L5558TFhbWnHGJiIiIiIiIyGlqcNL//fff4+Liwscff8wnn3xSb72cnJwmCUxERERERERETk+Dk/4ZM2Y0ZxwiIiIiIiIi0sQanPQ318r8IiIiIiIiItI8Tmn1/hplZWV8/PHHFBcXM3z4cDp16tRUcYmIiIiIiIjIaWpw0v/ggw9SUVHB66+/DkBFRQUDBgxgy5YteHp68tBDDzF//nwGDBjQbMGKiIiIiIiISMM1eMu+7777jgsvvND+ftasWezdu5edO3eSm5vL2LFjefrpp5slSBERERERERFpvAYn/fv27aNbt2729z/++CNjxowhJiYGk8nE3/72N9atW9csQYqIiIiIiIhI4zU46XdycsIwDPv7lStX0r9/f/t7f39/cnNzmzY6ERERERERETllDU76ExIS+OqrrwDYsmUL+/btIyUlxX587969hIaGNn2EIiIiIiIiInJKGrWQ33XXXcc333zDli1bGDlyJHFxcfbj3377Leeee26zBCkiIiIiIiIijdfgnv6rr76ab7/9ll69enH//ffz8ccf1zru6enJPffc0+QBioiIiIiIiMipaXBPP8CwYcMYNmzYcY9Nnjy5SQISERERERERkabR4J5+EREREREREWldlPSLiIiIiIiItFFK+kVERERERETaKCX9IiIiIiIiIm3UKSX9lZWV/PTTT/z73/+msLAQgIyMDIqKipo0OBERERERERE5dY1avR9g7969jBgxgn379lFeXs7w4cPx8fFh2rRplJWV8dZbbzVHnCIiIiIiIiLSSI3u6f/b3/5GUlISubm5eHh42MuvvPJKfv755yYNTkREREREREROXaN7+n/55ReWLVuGq6trrfKYmBgOHDjQZIGJiIiIiIiIyOlpdE+/1WqlqqqqTnl6ejo+Pj5NEpSIiIiIiIiInL5GJ/3Dhw/ntddes783mUwUFRUxefJkRo4c2ZSxiYiIiIiIiMhpaPTw/ldffZWUlBS6detGWVkZ119/PTt37iQ4OJiPPvqoOWIUERERERERkVPQ6KQ/IiKC9evX89FHH7F27VqsViu33347N9xwQ62F/URERERERETEsRqd9AN4eHhw2223cdtttzV1PCIiIiIiIiLSRBqd9H/55ZfHLTeZTLi7u9OxY0fi4uJOOzAREREREREROT2NTvpHjx6NyWTCMIxa5TVlJpOJQYMG8fnnnxMQENBkgYqIiIiIiIhI4zR69f758+dzzjnnMH/+fPLz88nPz2f+/Pmce+65fP311yxZsoQjR44wYcKE5ohXRERERERERBqo0T39f/vb33j77bdJTk62l1144YW4u7tz5513smXLFl577TXN9xcRERERERFxsEb39O/atQtfX9865b6+vuzevRuATp06kZ2dffrRiYiIiIiIiMgpa3TSn5iYyIMPPsjhw4ftZYcPH+ahhx7inHPOAWDnzp1ERkY2XZQiIiIiIiIi0miNHt7/7rvvcsUVVxAZGUlUVBQmk4l9+/bRoUMHvvjiCwCKiop4/PHHmzxYEREREREREWm4Rif9Xbp04bfffuOHH35gx44dGIZBQkICw4cPx8nJNnBg9OjRTR2niIiIiIiIiDRSo5N+sG3PN2LECEaMGNHU8YiIiIiIiIhIEzmlpL+4uJjFixezb98+Kioqah279957myQwERERERERETk9jU76161bx8iRIykpKaG4uJjAwECys7Px9PQkJCRESb+IiIiIiIhIC9Ho1fvvv/9+LrvsMnJycvDw8GDlypXs3buXxMREXnrppeaIUUREREREREROQaOT/vXr1/PAAw/g7OyMs7Mz5eXlREVFMW3aNB555JHmiFFERERERERETkGjk36z2YzJZAIgNDSUffv2AeDn52f/WkREREREREQcr9Fz+vv27cuaNWvo3LkzKSkpPPHEE2RnZ/O///2Pnj17NkeMIiIiIiIiInIKGt3T/+yzzxIeHg7AU089RVBQEHfffTeHDh3i7bffbvIARUREREREROTUNKqn3zAM2rVrR/fu3QFo164d3377bbMEJiIiIiIiIiKnp1E9/YZh0KlTJ9LT05srHhERERERERFpIo1K+p2cnOjUqRNHjhxprnjqdfnllxMdHY27uzvh4eHcdNNNZGRknPCcW265BZPJVOvVv3//WnXKy8v561//SnBwMF5eXlx++eV6qCEiIiIiIiJtQqPn9E+bNo0HH3yQzZs3N0c89UpJSeGTTz5h+/btfPrpp+zatYsxY8ac9LwRI0aQmZlpf/1xOsJ9993HZ599xuzZs/nll18oKipi1KhRVFVVNdetiIiIiIiIiJwRjV69/8Ybb6SkpITevXvj6uqKh4dHreM5OTlNFtyx7r//fvvXMTExTJo0idGjR2OxWDCbzfWe5+bmRlhY2HGP5efn8+677/K///2PYcOGAfDBBx8QFRXFTz/9xMUXX9y0NyEiIiIiIiJyBjU66X/ttdeaIYzGycnJYdasWSQnJ58w4QdYtGgRISEh+Pv7M2TIEJ555hlCQkIASE1NxWKxcNFFF9nrR0RE0KNHD5YvX15v0l9eXk55ebn9fUFBAQAWiwWLxXK6t9dsamJryTHK2U1tVFo6tVFp6dRGpTVQO5WWrrW00YbGZzIMw2jmWJrMxIkTeeONNygpKaF///58/fXXBAUF1Vv/448/xtvbm5iYGPbs2cPjjz9OZWUlqampuLm58eGHH3LrrbfWSuABLrroIuLi4vj3v/993OtOmTKFqVOn1in/8MMP8fT0PL2bFBERERERETmJkpISrr/+evLz8/H19a233ikl/bt27WLGjBns2rWL119/nZCQEL7//nuioqLs2/k1RH3J87FWr15NUlISANnZ2eTk5LB3716mTp2Kn58fX3/9NSaTqUGfl5mZSUxMDLNnz+aqq66qN+kfPnw48fHxvPXWW8e9zvF6+qOiosjOzj7hN9vRLBYL8+fPZ/jw4ScdISHiCGqj0tKpjUpLpzYqrYHaqbR0raWNFhQUEBwcfNKkv9HD+xcvXswll1zCwIEDWbJkiX24/MaNG/nPf/7D3LlzG3yt8ePHc+21156wTmxsrP3r4OBggoOD6dy5M127diUqKoqVK1cyYMCABn1eeHg4MTEx7Ny5E4CwsDAqKirIzc0lICDAXu/QoUMkJyfXex03Nzfc3NzqlJvN5hbdKGq0ljjl7KU2Ki2d2qi0dGqj0hqonUpL19LbaENja3TSP2nSJJ5++mn+/ve/4+PjYy9PSUnh9ddfb9S1apL4U1EzQOGPvfQncuTIEfbv3094eDgAiYmJmM1m5s+fz7hx4wDbaIDNmzczbdq0U4pLREREREREpKVo9JZ9mzZt4sorr6xT3q5dO44cOdIkQf3RqlWreOONN1i/fj179+5l4cKFXH/99cTHx9fq5U9ISOCzzz4DoKioiAkTJrBixQrS0tJYtGgRl112GcHBwfb4/fz8uP3223nggQf4+eefWbduHTfeeCM9e/a0r+YvIiIiIiIi0lo1uqff39+fzMxM4uLiapWvW7eO9u3bN1lgx/Lw8GDevHlMnjyZ4uJiwsPDGTFiBLNnz641zH779u3k5+cD4OzszKZNm/jvf/9LXl4e4eHhpKSk8PHHH9caofDqq6/i4uLCuHHjKC0t5cILL2TmzJk4Ozs3y72IiIiIiIiInCmNTvqvv/56Jk6cyJw5czCZTFitVpYtW8aECRO4+eabmyNGevbsyYIFC05a79g1CT08PPjhhx9Oeo67uzvTp09n+vTppxWjiIiIiIiISEvT6OH9zzzzDNHR0bRv356ioiK6devG4MGDSU5O5rHHHmuOGEVERERERETkFDS6p99sNjNr1iyefPJJ1q1bh9VqpW/fvnTq1Kk54hMRERERERGRU3RKW/YNGTKE+Ph44uPjmyMmEREREREREWkCjR7eP3z4cKKjo5k0aRKbN29ujphEREREREREpAk0OunPyMjgoYceYunSpfTq1YtevXoxbdo00tPTmyM+ERERERERETlFjU76g4ODGT9+PMuWLWPXrl1cc801/Pe//yU2NpYLLrigOWIUERFpGQwDDKujoxARERFpsEbP6T9WXFwckyZNonfv3jz++OMsXry4qeISERFpGXL3QtpS2LMUlz1LGFV0CEw3wAWPgE+Yo6MTEREROaFTTvqXLVvGrFmzmDt3LmVlZVx++eU8++yzTRmbiIjImZefDmm/wJ6lkLYE8vbZD5kAZ4B178PmOTDgL5B8L7j7OipaERERkRNqdNL/yCOP8NFHH5GRkcGwYcN47bXXGD16NJ6ens0Rn4iISPMqzDqa4O9ZCrl7ah93coGIfhA7iMqoZH5dvYYBpT/hdGANLHkR1rwHgx+CpNvAxdUx9yAiIiJSj0Yn/YsWLWLChAlcc801BAcH1zq2fv16+vTp01SxiYiINL2iw7bh+tVD9jmys/ZxkxOE94G48yF2MET3BzdvAAyLhextJVSNewCn37+Hn6fCkd/h+4mw8l9w4RPQ/SpwavSSOSIiIiLNotFJ//Lly2u9z8/PZ9asWfznP/9hw4YNVFVVNVlwIiIip60kxzZcvybJP/zbHyqYIKwnxA2G2PMhZgC4+534miYTdLsculwC6/4Hi56HvL3w6e2w/B8wbCrEpzTbLYmIiIg01CnP6V+wYAHvvfce8+bNIyYmhquvvpp33323KWMTERFpvNI82Lusesj+Uji4uW6dkO7VPfnnQ0wyeAae2mc5m23D+ntdAyv+Bcteh8wN8L/REH8BDJsC4b1P42ZERERETk+jkv709HRmzpzJe++9R3FxMePGjcNisfDpp5/SrVu35opRRESkfmUFsG8F7FliS/IzNwJG7TrtEmwJftz5EDMIvIKaNgZXLxjyICTdapvnv/pd2LXA9uo5Di54FAJim/YzRURERBqgwUn/yJEj+eWXXxg1ahTTp09nxIgRODs789ZbbzVnfCIiIrWVF8H+lUd78jPWg/GHqWVBHY8m+bHng3fImYnNKxgueQHO+z9Y+AxsmgObPoEtn8E5f4bBDzb9AwcRERGRE2hw0v/jjz9y7733cvfdd9OpU6fmjElEROQoSyns//Vokn8gFayVtesExEHsoOp5+YPAN8IxsdYIjIOr/wMDxsNPk2H3Ivj1TVg/CwbeC/3vsY0OEBEREWlmDU76ly5dynvvvUdSUhIJCQncdNNNXHPNNc0Zm4iInI0sZZC++ujCewfWQFVF7Tp+0Ud78WMHgX+UY2I9mYg+cPMXtmH+8ydD1kZY8DSs+g8MnQR9bwLnU15eR0REROSkGvyXxoABAxgwYACvv/46s2fP5r333uPvf/87VquV+fPnExUVhY+PT3PGKiIibVFlha33Pm2pbV5++mqoLKtdxyfiaJIfd37rmx8ffwHEDYXNn8KCJyFvH3x9H6z4JwybDAmjbDsCiIiIiDSxRncveHp6ctttt3Hbbbexfft23n33XZ5//nkmTZrE8OHD+fLLL5sjThERaSuqLLZ5+GlLbD35+38FS0ntOl4hxyT5gyGwQ+tPip2coNdY21Z/a96DxdPgyE74+EaIPBeGP2nbLlBERESkCZ3WmMIuXbowbdo0nnvuOb766ivee++9popLRETaCmuVbRu7muH6+1ZARVHtOp7BtmH6NfPygzu3/iS/Pi5u0P9u6HM9LPuHrbc/fRXMGAFdRsKFkyEkwdFRioiISBvRJBMJnZ2dGT16NKNHj26Ky4mISGtmtcLBTUcX3tu7HMoLatfxCICYgdUL751v21LPyckx8TqKux9c+LhtVf/Fz8Pa/8H2b2HH99DnBhj6MPi1d3SUIiIi0spp9SARETk9Visc/u1okp/2C5Tl1a7j5gcxyUeH7If2OPuS/Pr4hsNlr0P/v8DPU2Hb17Duf7bt/s77Pxh0P3j4OzpKERERaaWU9IuISOMYBmTvsC26V5PklxypXcfVG6IHHE3yw3uDk7Nj4m0t2nWGa2fB/lUw/wnbNIhlr8Ha9+H8CbYRAWZ3R0cpIiIirYySfhEROTHDgCO7bAvvpf1iexUdrF3H7AnR/Y8uvBfeG5zNjom3tYs6F279zjbM/6cpcHgb/Pgo/PoWpDwKvcbpAYqIiIg0mJJ+ERGpzTAgN+3owntpv0BhRu06Lu625DR2sK03P6IfuLg6JNw2yWSCLpdAx+Gw4SNY+Czk74fP/w9WvAHDpkDHYW13sUMRERFpMkr6RUQE8vYfk+QvtSWYx3J2hchzqnvyz4f2SRpqfiY4u0C/m6DnGFtP/9JX4eBmmDXG9m8xfCq0T3R0lCIiItKCKekXETkbFWTYevBr5uXnptU+7uRiS+xr5uRHnQtmD4eEKti+94Puh35/gqUvw6q3bf9u71wA3a+ECx6HoHhHRykiIiItkJJ+EZGzQdGhown+nqWQs6v2cZMzRPQ9muRH9wdXL8fEKvXzDISLn4Hz7rIN+d8wG7Z8Br99BYm3wpCHwDvE0VGKiIhIC6KkX0SkLSo+Ur2yfnWSn7299nGTE4T1qk7yB9uSfHdfx8QqjecfDVe+BQPG2xb7+30+rH7HNv8/+a8w4C/g5uPoKEVERKQFUNIvItIWlOZC2rKjSf6hLXXrhPY82pMfk6y939uCsB5w41zbKI75kyFjLSx6Dlb/B4ZMhMRbtIuCiIjIWU5Jv4hIa1SWD3uXH114L2sTYNSuE9Lt6MJ7MQNtQ8OlbYobDHcsgK2fw89PQs5u+HYCrPwXXPgEdButlf5FRETOUkr6RURag/JC2Lfy6Lz8zA1gWGvXCe58TJI/CLzbOSZWcQyTybaoX8IoSJ0Ji1+wJf9zbrFtqTh8qu3hgIiIiJxVlPSLiLREFSWwf+XRnvwDa8Goql0nMB5iB9kSudhB4BPmmFilZXE2w7l3QO/rYMUbsOwftmH/718GHYfDsCm2aQEiIiJyVlDSLyLSEljKIH3V0SQ/fQ1YLbXr+MccXXgvdhD4tXdMrNI6uHnD0EmQdBssngapM2wL/v3+E/S+FlIeBf8oR0cpIiIizUxJv4iII1SW2xL7moX30ldDVXntOr6RRxfeizvftmK7SGN5h8ClL0H/u2HBU7Yt/jZ8BJvn2UYEnP+A1nsQERFpw5T0i4icCVUW2xD9tCW2JH//KqgsrV3HO6x2kh8Qp8XXpOkExcPYmbYt/eZPtj1wWvEGrP0fnH8/nPd/YPZwdJQiIiLSxJT0i4g0h6pK22J7NUn+vpVgKa5dx6vd0QQ/9nwI6qgkX5pf+0T401fw+8/w02Q4uBl+mgK/vg0pj0Cf68HJ2dFRioiISBNR0i8i0hSsVbZt82qG6+9dDhWFtet4BB6z8N750K6LknxxDJMJOg2D+BTYNAcWPA35++HL8bbe/2FToPMItU8REZE2QEm/iMipsFrh0JajC+/tXQZl+bXruPvZts6r6ckP6QZOTo6JV+R4nJxti/p1Gw2r/wNLX4LD2+CjayF6AAx/EqLOdXSUIiIichqU9IuINIRh2JKhPUttQ/bTlkFpTu06rj4Qk3w0yQ/rqWHS0jqY3SF5PPS9EZa9BivfhH0r4N3hkDDK1vMf3MnRUYqIiMgpUNIvInI8hgFHfoc9S2w9+Wm/QPHh2nXMXhAz4Oi8/LDe4Kwfq9KKefjbEvxz7oBFz8H6WbDta9j+HfS7CYY+DD5hjo5SREREGkF/nYqIgC3Jz9l9NMHfsxSKsmrXcfGA6POqk/zBENEXnM2OiVekOfm1hyvegAF/gZ+fhO3fQupM2PgJ9L8HBt5rm74iIiIiLZ6SfhE5e+XuPbrwXtpSKDhQ+7izm20+c01PfvtEcHFzTKwijhDSFa77CPaugPlPQPoq27z/Ne/BkIcg6Tb9PyEiItLCKekXkbNH/oFjkvwlkLev9nEnM0Sec3ROfuQ5trnOIme7mAFw+4+w7Rvb9n5HdsL3k2xz/y94HHpcrUUqRUREWigl/SLSdhVmVQ/Vr56Xn7O79nEnF4jodzTJjzoPXD0dE6tIS2cyQddRtq381n8AC5+DvL0w78+w/B8wfCrEX+DoKEVEROQPlPSLSNtRdLh6Tn51b/6RnbWPm5wgvE91kj8YovuDm7dDQhVptZxdIPEW6DnW1tO/7HXI2gj/uxI6pNgWAozo4+AgRUREpIaSfhFpvUpybD35NUn+4d/+UMEE4b1svfix59uGKGvxMZGm4eoFgydA4q22ef6r3oHdC+HthdBjDFzwGATGOTpKERGRs16rmYB3+eWXEx0djbu7O+Hh4dx0001kZGSc8ByTyXTc14svvmivM3To0DrHr7322ua+HRE5FaV5sO1b+P5heHMQTOsAn9wEq94+mvCH9oDz7oZrP4SJe+CuJXDxM9BlhBJ+kebgFQQjnoO/roGe42xlm+fCG+fAdxOhONux8YmIiJzlWk1Pf0pKCo888gjh4eEcOHCACRMmMGbMGJYvX17vOZmZmbXef/fdd9x+++1cffXVtcrvuOMOnnzySft7Dw+Ppg1eRE5NWQHsW1E9J/8X2xBiw1q7TruEo6vrxwyyJSAicuYFxMLV70DyeNtif7sWwK9vwbpZMPBvMOAe2+gAEREROaNaTdJ///3327+OiYlh0qRJjB49GovFgtl8/H2yw8LCar3/4osvSElJoUOHDrXKPT0969Q9kfLycsrLy+3vCwoKALBYLFgslgZf50yria0lxyhnN0tpIe0KNsJPq7DuX44pcwMmo6pWHSOoI9bogRixgzCiB4J3yB8uovYtzUc/RxsguBtc+wmmPYtxXjAVU9ZGWPg0xqq3sQ5+CGvvG8D5+L+35fSpjUproHYqLV1raaMNjc9kGIbRzLE0uZycHO6++24OHDjAL7/80qBzDh48SGRkJO+//z7XX3+9vXzo0KFs2bIFwzAIDQ3lkksuYfLkyfj4+NR7rSlTpjB16tQ65R9++CGenlr5W6RRDIPA4p1E5fxC+7xVmKtKah0ucg0h26cr2d5dOeLTlTJzgIMCFZFGM6y0z/2Vrplz8ao4DECRWxhbI8aS6Zdk2xFARERETklJSQnXX389+fn5+Pr61luvVSX9EydO5I033qCkpIT+/fvz9ddfExTUsKG806ZN4/nnnycjIwN396P7br/zzjvExcURFhbG5s2befjhh+nYsSPz58+v91rH6+mPiooiOzv7hN9sR7NYLMyfP5/hw4fXOzpC5IzJ24fTpk9w2vQxptw99uJScwDmLhdB3GCM2EHg296BQYrUpp+jp6iqAqe17+P0y0uYSo4AYG2fhPWCyRjRAxwcXNuiNiqtgdqptHStpY0WFBQQHBx80qTfocP76+sxP9bq1atJSkoC4MEHH+T2229n7969TJ06lZtvvpmvv/4aUwN6Ct577z1uuOGGWgk/2Obz1+jRowedOnUiKSmJtWvX0q9fv+Ney83NDTc3tzrlZrO5RTeKGq0lTmmDygth6xew/iPYe8woHbMXdLuCyh5j+XFLPiMvHaU2Ki2afo42ktkMyfdAvxth+XRY8QZOB9bg9L/LoPMlMGwyhHR1dJRtitqotAZqp9LStfQ22tDYHJr0jx8//qQr5cfGxtq/Dg4OJjg4mM6dO9O1a1eioqJYuXIlAwacuJdg6dKlbN++nY8//vikMfXr1w+z2czOnTvrTfpFpBGsVbBnsS3R/+0rqCytPmCCuMHQ53roehm4emFYLLD1W4eGKyLNyN0XLngUzrkdFr8Aqe/Dju9g5w/Q+3pIeQT8NLpHRESkKTk06a9J4k9FzayEY4fZ1+fdd98lMTGR3r17n7Tuli1bsFgshIeHn1JcIlLt8A7Y8CFs/AQKDhwtD+oIva+DXteAf5Tj4hMRx/EJg1GvQv974Ocn4bcvYf0Htq3+zrsLBt0PHlq/Q0REpCm0itX7V61axapVqxg0aBABAQHs3r2bJ554gvj4+Fq9/AkJCTz33HNceeWV9rKCggLmzJnDyy+/XOe6u3btYtasWYwcOZLg4GC2bt3KAw88QN++fRk4cOAZuTeRNqUkBzZ/Chs+ggOpR8vd/aHH1bZe/faJWrxLRGyCO8E1/4P9q+GnybB3GSx73TYC4PwH4Nw7wex+8uuIiIhIvVpF0u/h4cG8efOYPHkyxcXFhIeHM2LECGbPnl1rbv327dvJz8+vde7s2bMxDIPrrruuznVdXV35+eefef311ykqKiIqKopLL72UyZMn4+zs3Oz3JdImVFlg53xbr/7278FavXWIyRk6XQS9r4Uul4BL3XUwREQAiDoHbvkGdvwAP02Bw7/B/Mfh13/bpgP0ugac9HtZRETkVLSKpL9nz54sWLDgpPWOtxHBnXfeyZ133nnc+lFRUSxevPi04xM56xgGZG6w9ehvmgPVq3EDENbTNje351jwbue4GEWkdTGZoMsI6DQcNsyGhc9AQTp8fjcsfwOGTbEd00ghERGRRmkVSb+ItBCFWbY5+hs+gkNbj5Z7hUCvcba5+mE9HBefiLR+Ts7Q9wbocRWsehuWvgyHtsCHYyH2fBg2FSITHR2liIhIq6GkX0ROzFIK276xJfq7FoBhtZU7u0HCSFuvfvwF4KwfJyLShMweMPBv0Pcm+OVV21D/tKXwnwug22i48P/bu/PwLKs78f/vJzskECBBICZhX2TfNIJWUQRHrVtrLeLXamupTrVTL3TsaKuigzJ1fjPWpdix06lUBWlrpdZKKy7gAihb2ERABAIN+xaWEAJ5fn8cyCIgqMCTJ3m/rutc4Tn3ks/NdQj53Pe5P+d+yGof6yglSar1/C1d0uGiUVjzARSOh8WToKxarYy8gvCefrerra4t6eRr2AyG/nso6jd1TPi59NEk+PhV6HsjDPo3yDgt1lFKklRrmfRLqrJtdXiXdv4E2Layqj8zLyT6va7zyZqk2GiSB1eNhQG3wRsPwvK/w+zfhJ9ZA2+HgT+C1EaxjlKSpFrHpF+q78p2hqf581+E1e9V9SenQ7erQrLf+lxISIhVhJJUpUU3uP73sOo9mHJ/WB502s9h1m/g/J9Av5sgKSXWUUqSVGuY9Ev1UcUBWDkNCifAkr/A/tKDGyLQ9jzoPRzOuBxS0mMapiQdVZtz4ftvwkd/hjcfgq0rYPK/wsyxMPg+6Hq1NyslScKkX6pfNi0N78Mu+D3sLK7qz+oIva8La2Fn5sYuPkn6IiKRMCOpy2Uw93cw9T/Cq0l//B7kPBkq/bc7P9ZRSpIUUyb9Ul23Zysseikk+8Vzq/rTmkD3b4an+qf3c+1rSfErMRnOvDncuJw5Ft5/HIrnwe+ugA4XwUWjoGWPWEcpSVJMmPRLddGBclj+ekj0l/0dKspDfyQROg4NT/U7/RMkpcY2Tkk6kVIz4Py7od934Z3/DIX+PnkDPnkz3BC44F5o2jrWUUqSdEqZ9Et1RTQK6+aHyvsL/wB7tlRta9kDeg2HHt+CjOaxi1GSToWM5nDpo3D2rfDW6DDbacGLsPhPYem/r90ZlgKUJKkeMOmX4t3O9bBgYijKt2lJVX/6adDz2rDMXsvusYtPkmKlWTu45v9gwO3wxgOw8h2Y8RTMfQ7OvQMKboWUhrGOUpKkk8qkX4pH5aXw8V/DU/0Vb0G0IvQnpoaCVr2ug/YXQqL/xCWJ0/vCd16BFW/ClFGwYSG8+SB8+Gu44J4wE8qfl5KkOsr/4aR4EY1C0UyYPx4WT4KykqpteQUh0e92NTRoEqsIJan2ikRCUb92F4ZXoN4aDTuK4JUfwfSn4KIHoPOlFjWVJNU5Jv1SbbdtFcx/MTzV37aqqj8zD3oNC8l+VvtYRSdJ8SUhAXp9Oyz1N+t/Q8G/zUvhxeGQdzYMeQjyC2IdpSRJJ4xJv1Qb7S2Bj/4cEv3V71f1p2RA1ytDot/6nPDLqyTpi0tKhQG3QZ//F5b4mzEW1syE/xsKXb4Ogx+A5p1iHaUkSV+ZSb9UW1QcgE+nhqf6S/4C+0sPbohAu/NDon/G5ZCSHssoJaluScuEwffDmd+HqWNg3vPw8auw9DXocwMMugcat4p1lJIkfWkm/VKsbVoKheNhwe9hZ3FVf1ZH6H1dWFs6Mzd28UlSfdA4B654MlT6f/OhkPjPHRd+Ng/4IZzz43CDQJKkOGPSL8XCnq2w8I9h+n7x3Kr+tCbQ45rwVP/0fhaUkqRTrXlnGPZCKJw65X5Y8wG8+18w+7dw3r/CmTeHVwMkSYoTJv3SqbJ/H3wyJTzVX/Z3qCgP/QlJ0GFIeKrf6Z/8ZVKSaoP8s+F7fw/T/N8YBZuXwd/vgQ+ehgvvg+7XWFdFkhQXTPqlkykahXWFUDgBFv0R9myp2tayJ/QeHn5xzGgesxAlSUcRiUCXy6DjxVD4Qnjnf3sR/GkEvP8EDBkF7Qc7K0uSVKuZ9EsnQ8k6WPj7kOxvWlLVn9ECenwrJPstusUuPknS8UtMgn43hp/fH/wK3nsMNiyE578Jbc+HIQ9CTp9YRylJ0hGZ9EsnSnkpfPzXMH3/07chWhH6E1PDk6Lew6HdBeGXR0lS/ElpCF8bCf1ugnf+P5j1a1g5DZ4ZBN2/Gab9N2sb6yglSarB7EP6KqJRKJoRCvItngRlJVXb8gpCQb5uV0ODJrGKUJJ0ojVsBv/0CBTcAm8/HCr8L3oJPnoF+n8vFPzztS1JUi1h0i99GdtWwfwXQ7K/bVVVf2Y+9BoWWlb7WEUnSToVmraGbzxzcJm/B+GTN+DD/wnv/5/zYzj7h5CaEesoJUn1nEm/dLz2lsBHk0Kyv/r9qv6UDOh6ZXiq3/ocqzlLUn3Tqif8v5fg02lhmb91hWEGwIe/hkH/Bn2/A4nJsY5SklRPmfRLn6fiAHw6NTzRX/Iq7C89uCEC7c6HXsPhjK9DSnoso5Qk1QbtzocRb8NHL8ObD4WZYH8dCTPHwuD74YwrrPQvSTrlTPqlI9n4McwfH97T3Lmuqj+rI/S+Dnp+GzJzYxefJKl2SkgIRf26XA5znoVpP4ctn8DvvwOn94chD0Gbc2IdpSSpHjHplw7ZsxUW/jEk+8XzqvrTmkCPa8JT/dP7+pRGknRsSSlQ8INwo3j6kzD9KfjHbHj2Uuh4MVw0Clp0jXWUkqR6wKRf9dv+fbD89TB9f9nfoaI89CckQcehoSBfp3+CpNTYxilJik+pjeCCe6H/zeGp/5xnYfnfw/89vYeHbc4ckySdRCb9qn+i0VBkqXACLPoj7NlSta1lz/BLWPdrXG5JknTiNGoBX//vUNH/rX8PhWELXwgzzApuga+NhAZNYx2lJKkOMulX/VGyDhZMDNX3Ny2p6s9oAT2vDdX3W3SLXXySpLovuwNcOw7WzgmV/le/B9OfgLnj4Gt3wlk/gOQGsY5SklSHmPSrbtu3B5a+BoXj4dO3IVoR+hNToctl4al+uwsg0X8KkqRTKLcf3PQqLJ8CbzwAGz8KNwE+eCZM+e81DBISYx2lJKkOMNNR3RONQtGMkOh/9GcoK6nalnd2KKrU9Spo0CRWEUqSFArDdhoKHQaHmWhvPQwla+HPP4QZT4Vifx2HWkBWkvSVmPSr7ti68uD0/QlhbeRDMvPDE5NewyCrfczCkyTpiBISw8yzbt+AD5+Bd/8rPPkffy20PheGPAi5/WMdpSQpTpn0K77tLTlYDGkCFE2v6k/JCE/ze18H+QPDusmSJNVmyWlwzr9A3xvgvcdg5q/CO///OxjOuAIGPxBqAkiS9AWY9Cv+VBwI7+fPfxGWvAr7Sw9uiEC786HXcDjj65CSHtMwJUn6Uho0hSEPhaJ+b4+B+eNhySvw8V+h341w/r+F1QAkSToOJv2KHxs/Dr/4LPg97FxX1Z/dKVTe7/ltyDw9dvFJknQiZebCVb+EAbfBmw/Bsskw+//CTe8Bt8PAH0Fa41hHKUmq5Uz6Vbvt3gKL/hiK8q0rrOpPawI9rglP9U/va5EjSVLd1aIrDH8RVr0fKv2vnQXvPBpuAJx/N/T7LiSlxDpKSVItZdKv2mf/Plj+eijIt+zvUFEe+hOSQhXjXtdBp4shKTW2cUqSdCq1OQdungJL/gJvPghbPoHJd8PMsXDhfaEQoCRJn2HSr9ohGoXieSHRX/hHKN1ata1lz1DVuPs1kNE8djFKkhRrkQh0vQI6XwLznoOp/xFWrHnpZpj+JJEL7o91hJKkWsakX7FVUhze0Z8/ATZ9XNWf0QJ6Xhue6rfoFrv4JEmqjRKTof/3Qj2bGWPh/cdhXSFJ47/BgEbdSJj5aXgtILsTNGntKjaSVI+Z9OvU27cnVCCePx4+nQrRitCflAZdLguJfrsLINHhKUnS50pJh/P/Ffp/F975T6KzfsNpOxfDm4ur9klKg6yO0LwTZHeu+prV3lflJKkeMKvSqRGNwurp4Yn+4kmwb2fVtryzofd10PUqaNAkRgFKkhTH0rPhkp+zv9/3+eRPj9C56QEStnwS3vvfvxc2LAytukgiNG0DzTuHGQHNO4ebAdkdXRVAkuoQk36dXFtXhqWF5k+A7aur+jPzodew0LLaxy4+SZLqkqZtWNbqKjpceikJyclQcSC88795GWxaWvNrWQlsXRHa0tdqnqdRzuEzA5p3hvTmrpgjSXHGpF8n3t4d8NGfoXACFE2v6k/JCE/ze18H+QN9v1CSpJMtITHcXM9qH4r/HRKNws71sHkpbFp28OvBmwG7NsDO4tA+nVrzfGlNDp8Z0LxTuJnv/+uSVCvFXdJfVlZGQUEB8+fPZ968efTu3fuo+0ajUR588EGeeeYZtm3bRkFBAb/85S/p1q1bjfPdddddTJgwgdLSUgYPHszYsWPJzc09BVdTh1QcgE/fDon+x6+GqYQARKDdoFB9v8tl4d1DSZIUW5EING4VWrtBNbeVbq82I6DaTYFtq2HvdljzQWjVJTWA7A5VMwIO3RRo1h6SUk7RRUmSjiTukv67776bnJwc5s+ff8x9H330Uf77v/+bZ599lk6dOjF69GiGDBnC0qVLadSoEQB33HEHf/nLX3jxxRfJysrizjvv5Otf/zpz5swhMTHxZF9O/Nu4BArHhwr8u9ZX9Wd3CgX5en4bMk+PXXySJOmLadAE8s4Krbry0lAj4LOvCWz5BPaXwvqFoVUXSYRmbWu+JpDdKfw5tdEpuyRJqs/iKumfPHkyr7/+Oi+99BKTJ0/+3H2j0Si/+MUv+OlPf8o3vvENAMaNG0eLFi0YP348t9xyCzt27OA3v/kNzz33HBdddBEAzz//PHl5ebzxxhtcfPHFJ/2a4tLuLbDojyHZX1dY1d+gKXS/Jkzfz+nrO3+SJNUlyQ2gZY/QqjuwP9TtOVrdgEMFBZf+teZx1g2QpFMibpL+DRs2MGLECCZNmkTDhg2Puf/KlStZv349Q4cOrexLTU3l/PPPZ/r06dxyyy3MmTOH8vLyGvvk5OTQvXt3pk+fftSkv6ysjLKyssrPJSUlAJSXl1NeXv5lL/GkOxTbl4rxwD4iy6eQsHAikU+mEKkI54gmJBFtfxEVPYcR7TCkaumf/ftPVNiqR77SGJVOAceoaruYjdHG+aG1u6iqLxqFXeuJbF5OZPMy2LKMyOaDbffGo9YNiKY1IZrdCbI6Es3uVNnIzIOIdQPqAn+WqraLlzF6vPHFRdIfjUa56aabuPXWW+nfvz+rVq065jHr14ep5i1atKjR36JFC1avXl25T0pKCk2bNj1sn0PHH8mYMWN48MEHD+t//fXXj+uGRKxNmTLl+HaMRmlSupK8Le9x+raZpB7YVblpe4M2rGl2Lmubns2+5MbwKfDpmycnYNU7xz1GpRhxjKq2q31jNCe0ZoOgGSTv301GWTGN9haTsTd8bbR3HQ33bSKydzuRtR/C2g9rnGF/JIVdaS3ZlZbDzrQcdqbmsCsth12pLYkmxMWvtPqM2jdOpZpq+xjds2fPce0X05+Qo0aNOmLyXN2sWbOYPn06JSUl3HPPPV/4e0Q+Mz0sGo0e1vdZx9rnnnvuYeTIkZWfS0pKyMvLY+jQoTRuXHvXtS0vL2fKlCkMGTKE5OTko+9Yso6ERX8IT/U3L63sjqafRkWPb1HRYxjpp51BF6DLyQ9b9chxj1EpRhyjqu3ifYzuLy+FrSuqZgRsOThLYOsKkg7so0lpEU1Ki2ocE40kQtM2VbMCsjpBdkeiWR2tG1BLxfs4Vd0XL2P00IzzY4lp0n/77bczbNiwz92nTZs2jB49mpkzZ5KamlpjW//+/bn++usZN27cYce1bNkSCE/zW7VqVdm/cePGyqf/LVu2ZN++fWzbtq3G0/6NGzcycODAo8aUmpp6WCwAycnJtXpQHHLEOPftgY//CvPHh2l20YrQn5QWqu73Gk6k3SASE5OwvKFOtnj5t6T6yzGq2i5ux2hyMjTsA7l9avYfqhvw2RUFNi0jsm9nuFGwdQUs+0zNp8anV1tesNoyg+nZ1g2oBeJ2nKreqO1j9Hhji2nSn52dTXZ29jH3e+KJJxg9enTl5+LiYi6++GImTpxIQUHBEY9p27YtLVu2ZMqUKfTpE/7j2LdvH9OmTePnP/85AP369SM5OZkpU6Zw7bXXArBu3ToWLVrEo48++lUvr/arqICiGSHRX/xn2Lezalve2aEgX7erIS0zdjFKkiQlJkFW+9C4tKo/GoWd6w4vILhpKezeCCX/CO3Tt2uer0HTwwsIHqobkGDdAEl1S1y8AJWfn1/jc0ZGBgDt27cnNze3sr9Lly6MGTOGq6++mkgkwh133MEjjzxCx44d6dixI4888ggNGzZk+PDhAGRmZnLzzTdz5513kpWVRbNmzbjrrrvo0aNHZTX/OmnbSlj8EsyfEO6aH9IkPyyz12sYNGsXu/gkSZKORyQCjXNCa39BzW2l26rNCKh2M2B7Udi2ZmZo1SU3hKwOVTMCDt0UaNYOklJO3XVJ0gkUF0n/8Vq6dCk7duyo/Hz33XdTWlrKD3/4Q7Zt20ZBQQGvv/46jRpVvd/12GOPkZSUxLXXXktpaSmDBw/m2WefJTGxjk1i319GZN4LnLvsaZLnLavqT2kE3a4MyX7+QO9uS5KkuqFBU8gvCK26fXvCEoKVMwMOvi6w5RMo3wPrF4RWXSQxJP41XhPoFFpqxqm7Jkn6EuIy6W/Tpg3RaPSw/s/2RSIRRo0axahRo456rrS0NJ588kmefPLJEx1m7RJJIHHqw2Tt2UyUCJF2g6D3cOjydUip/SsOSJIknRApDaFVz9CqO7Aftq06fGbA5mWwbxdsWR7aZzXOrfaaQLXXBdKP/QqrJJ0KcZn060tITKZiwI9Y+tEiOl5zH8lZrWMdkSRJUu2RmATZHULrcllVfzQKJcWHFRBk81LYvQlK1oa24q2a52vQ7OCsAOsGSIotk/56pOLs21i+9TU6Ns6JdSiSJEnxIRKBzNNDa39hzW17th5eQHDzUti+Bkq3WjdAUq1g0i9JkiR9GQ2bQf7ZoVW3b094FeCzhQS3rDh63YCEJGja1roBkk44k35JkiTpREppCK16hVbdgf1hFaXqBQQ3L4XNy60bIOmkMemXJEmSToXEJMjuGBpfr+r/KnUDaswMOHhToHGudQMkVTLplyRJkmLpS9UNKAp1A4pmhFZdcsODNxc+MzOgWTtITD511yWpVjDplyRJkmqrL1s3YN380KpLSAqJ/2dnBmR3gpT0U3dNkk4pk35JkiQp3hy1bkA5bFt1eN2ATcugfHe4MbB5GXz8as3jMvNqFhA8dFMgPeuUXZKkk8OkX5IkSaorEpM/p27APz7zmsDBr3s2w441oa14s+b5GmbVfE0gu5N1A6Q4Y9IvSZIk1XWRCGTmhtZhcM1te7YeeWbAjiLYswWKpodWXXI6ZHewboAUB0z6JUmSpPqsYTNoPSC06vbtDssJVi8guGkZbF0RXhWwboAUF0z6JUmSJB0uJR1yeodW3YFy2LqyZgHBTUvDDYLjqBuQkNWRnG0JsLMPNMs/VVcj1Vsm/ZIkSZKOX2JyeHrfvBOccXlVf0VFqBvw2dcENi8NrwkcrBuQuOJNzgR4Yiw0bQP5A8Msg/yBkNU+vIog6YQx6ZckSZL01SUkQJO80DpcVHPb7i2VMwMOrF/EzsWvk1m6hsi2VWG1gfnjw37pzSF/QGitB0CLHpBoyiJ9Ff4LkiRJknRypWdB+kBoPZCK8nKmHTiPSy88l+T1c2H1dCiaCf+YA7s3wZJXQgNIaQR5Z1bNBji9HyQ3iO21SHHGpF+SJEnSqZfWGDoOCQ2gfC8UzwsrBayeAWs+gLISWPFWaAAJyXB6X8g/O9wIyC+ABk1jdw1SHDDplyRJkhR7yWlVqwh8Dag4ABsWQ9GMg7MBZsCuDeFmwJoP4P3HgQic1vVgTYAB0HogNM6J9ZVItYpJvyRJkqTaJyERWvUMreAWiEZh28owC+DQbICtK2Dj4tBm/W84rknrkPwfmg2Q3dHigKrXTPolSZIk1X6RCDRrF1qf60Pfzg1hBsCh2QAbFsH21aHNnxD2aZgdbgC0HhhmA7TsaXFA1SuOdkmSJEnxqVEL6HZVaAB7S2DthwdnA8yAtbNhz2b4+NXQAFIyIPfMqtkAp/eHlIaxugLppDPplyRJklQ3pDUOywUeWjJwf1koDnioJkDRB1C2Az59OzQIxQFzelfVBMgrgIbNYnYJ0olm0i9JkiSpbkpKPfhu/9nhc0UFbPyoZnHAnetg7azQpj8R9juta9VNgPyzITM3dtcgfUUm/ZIkSZLqh4QEaNk9tLNGHCwOuKraTYCZsGV5uDGw8SOY/ZtwXGZ+zRUCsjtZHFBxw6RfkiRJUv0UiUCztqH1Hh76dm2qWRxw/QLYUQQLimDBxLBPw6xwA+BQa9UTEpNjdx3S5zDplyRJkqRDMppD1ytCAyjbCWs+PHgTYAb8Yzbs2VKzOGByOuT2r1ohIPdMiwOq1jDplyRJkqSjSW0EHQaHBrB/H6wrrFYccAbs3QErp4UGkJAErXpXvRKQP8DigIoZk35JkiRJOl5JKZB3VmjcEYoDblpSdRNg9QzYWRxmBPxjNkx/MhzXvEu14oADoEleLK9C9YhJvyRJkiR9WQkJ0KJbaIeKA24vqrlCwOZlsOnj0Ob8NhyXmXfwJsDBmQDZncO5pBPMpF+SJEmSTpRIBJq2Dq3XsNC3e3PVLICiGbBuPuxYAwvXwMLfh30aNDu4vODB2QCtelkcUCeESb8kSZIknUzp2XDG5aEBlO2CtbOqZgOsnQ2lW2Hpa6EBJDcMxQHzB4bZALlnQkp67K5BccukX5IkSZJOpdQMaH9BaHCwOOB8KJoORTPDzYDSbbDyndAAIonh6f+hmgD5AyA9K3bXoLhh0i9JkiRJsZSUAnlnhnbOj0NxwM1LaxYHLFkLxXNDm/FUOC6788GaAAdnAzTJj+11qFYy6ZckSZKk2iQhAU47I7Qzbw5924sO1gSYHr5uXlrV5jwb9mmcG+oCHLoR0LyLxQFl0i9JkiRJtV6T/NB6fTt83r0F1sysmg2wbn6YDbDoj6EBNGgKedVuArTqFWYVqF4x6ZckSZKkeJOeBV0uCw1g3+5QHPDQbIC1s0NdgGWTQwNIanCwOODBpQJzzwr1BVSnmfRLkiRJUrxLSYd2g0IDOFAO6xZUvQ5QNCOsELDq3dDgYHHAnlU1AfIHhJUGVKeY9EuSJElSXZOYDLn9Qhv4o4PFAZfVvAmwYw0Uzwtt5i/DcVkdP1McsDVEIrG9Fn0lJv2SJEmSVNclJMBpXULr/73Qt33NwSUCD94I2LQEtiwPbe7vwj6NcqpmAbQeCM3PsDhgnDHplyRJkqT6qEleaD2/FT7v2VrzJsC6QthZDIteCg0gLbNmccCcPhYHrOVM+iVJkiRJ0LAZdLk0NIB9e+Afs6uKA66ZBXt3wPK/hwaQlAan96+aDZB3FqQ2it016DAm/ZIkSZKkw6U0hLbnhQahOOD6BVU1AYpmwJ4tsPq90AAiCdCyZ9UKAfkDIaN57K5BJv2SJEmSpOOQmAyn9wtt4O0QjcLm5dWKA06H7UXhtYB1hfDB0+G4rA5VNQHyB0DTNhYHPIVM+iVJkiRJX1wkAs07hdbvptC34x9hBsDq6eHrxo9gyyehzXsu7NOoFeSfXbVCwGldISExZpdR15n0S5IkSZJOjMzTocc1oQGUboOiD6pmAxTPg53rYPHLoQGkZkJ+QdVsgJw+kJQau2uoY0z6JUmSJEknR4Om0PmfQoODxQHnVM0GWDsLynbA8tdDA0hMhdz+VbMB8s6CtMaxu4Y4F3cLLJaVldG7d28ikQiFhYVH3a+8vJyf/OQn9OjRg/T0dHJycvjOd75DcXFxjf0GDRpEJBKp0YYNG3aSr0KSJEmS6qGUhtD2a3D+3fCdSfCT1fCDqXDxGDjjcmiYDQfKYPX78O5/wQvfhJ+3hl99DSb/BBZPgl0bY3wR8SXunvTffffd5OTkMH/+/M/db8+ePcydO5f77ruPXr16sW3bNu644w6uuOIKZs+eXWPfESNG8NBDD1V+btCgwUmJXZIkSZJUTWJSmM6f0wcG/DAUB9zySVVNgKIZsG1VWDVg/QL44FfhuGbtq60QMACatbM44FHEVdI/efJkXn/9dV566SUmT578uftmZmYyZcqUGn1PPvkkZ511FkVFReTn51f2N2zYkJYtW56UmCVJkiRJxykSgeyOofW7MfSVFB98HeDgTYANi2HritAKnw/7ZLQMrwMcWiGgRTeLAx4UN0n/hg0bGDFiBJMmTaJhw4Zf6hw7duwgEonQpEmTGv0vvPACzz//PC1atOCSSy7hgQceoFGjRkc9T1lZGWVlZZWfS0pKgPBKQXl5+ZeK7VQ4FFttjlH1m2NUtZ1jVLWdY1TxwHGqL6xBc+h8RWgApduJrP2QyJqZoRXPI7JrPXw0KTQgmtqIaG4B0bwConlnE83pA0lpx/Xt4mWMHm98kWg0Gj3JsXxl0WiUSy+9lHPOOYef/exnrFq1irZt2zJv3jx69+59XOfYu3cv5557Ll26dOH555+v7P/1r39N27ZtadmyJYsWLeKee+6hQ4cOh80SqG7UqFE8+OCDh/WPHz/+S9+QkCRJkiR9cQkV+2i651Oydi2j2a6lNNu9nOSKvTX2ORBJZnvDtmzJ6MyW9E5szejI/sT4zt327NnD8OHD2bFjB40bH73QYUyT/qMlz9XNmjWL6dOnM3HiRN555x0SExO/cNJfXl7Ot771LYqKipg6dern/oXMmTOH/v37M2fOHPr27XvEfY70pD8vL4/Nmzd/7rljrby8nClTpjBkyBCSk5NjHY50GMeoajvHqGo7x6jigeNUJ13FftiwmIRDMwHWzCSye1ONXaKRBDitGxV5Z1fOBqBReOU7XsZoSUkJ2dnZx0z6Yzq9//bbbz9mpfw2bdowevRoZs6cSWpqzbUa+/fvz/XXX8+4ceOOenx5eTnXXnstK1eu5K233jpmUt63b1+Sk5NZvnz5UZP+1NTUw2IBSE5OrtWD4pB4iVP1l2NUtZ1jVLWdY1TxwHGqkycZ8vuHxu2hOODWT6uKA66eTmTbStiwkMQNC2H2r8NhTdtC64FETj+L9LJ9tX6MHm9sMU36s7Ozyc7OPuZ+TzzxBKNHj678XFxczMUXX8zEiRMpKCg46nGHEv7ly5fz9ttvk5WVdczvtXjxYsrLy2nVqtXxXYQkSZIkqfaKRCCrfWh9bwh9JeuqVgdYPQM2LIJtK2HbSpIKX6B3RhfguzEN+0SJi0J+1SvtA2RkZADQvn17cnNzK/u7dOnCmDFjuPrqq9m/fz/XXHMNc+fO5dVXX+XAgQOsX78egGbNmpGSksKKFSt44YUXuPTSS8nOzuajjz7izjvvpE+fPpxzzjmn7gIlSZIkSadO41bQ/RuhAZRuh7WzYPV0KlZPZ9P+HDJjGuCJExdJ//FaunQpO3bsAGDt2rW88sorAIe99//2228zaNAgUlJSePPNN3n88cfZtWsXeXl5XHbZZTzwwAMkJrq8gyRJkiTVCw2aQMch0HEIB8rLWfbaa3SIdUwnSFwm/W3atOFI9Qer9x1tn+ry8vKYNm3aCY9PkiRJkqTaICHWAUiSJEmSpJPDpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDoqKdYB1AXRaBSAkpKSGEfy+crLy9mzZw8lJSUkJyfHOhzpMI5R1XaOUdV2jlHFA8epart4GaOH8s9D+ejRmPSfADt37gQgLy8vxpFIkiRJkuqTnTt3kpmZedTtkeixbgvomCoqKiguLqZRo0ZEIpFYh3NUJSUl5OXlsWbNGho3bhzrcKTDOEZV2zlGVds5RhUPHKeq7eJljEajUXbu3ElOTg4JCUd/c98n/SdAQkICubm5sQ7juDVu3LhWD17JMarazjGq2s4xqnjgOFVtFw9j9POe8B9iIT9JkiRJkuook35JkiRJkuook/56JDU1lQceeIDU1NRYhyIdkWNUtZ1jVLWdY1TxwHGq2q6ujVEL+UmSJEmSVEf5pF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpF+SJEmSpDrKpL8eGTt2LG3btiUtLY1+/frx7rvvxjokCYB33nmHyy+/nJycHCKRCJMmTYp1SFINY8aM4cwzz6RRo0acdtppXHXVVSxdujTWYUmVnn76aXr27Enjxo1p3LgxAwYMYPLkybEOSzqqMWPGEIlEuOOOO2IdigTAqFGjiEQiNVrLli1jHdYJYdJfT0ycOJE77riDn/70p8ybN4+vfe1rXHLJJRQVFcU6NIndu3fTq1cvnnrqqViHIh3RtGnTuO2225g5cyZTpkxh//79DB06lN27d8c6NAmA3Nxc/uM//oPZs2cze/ZsLrzwQq688koWL14c69Ckw8yaNYtnnnmGnj17xjoUqYZu3bqxbt26yrZw4cJYh3RCuGRfPVFQUEDfvn15+umnK/vOOOMMrrrqKsaMGRPDyKSaIpEIL7/8MldddVWsQ5GOatOmTZx22mlMmzaN8847L9bhSEfUrFkz/vM//5Obb7451qFIlXbt2kXfvn0ZO3Yso0ePpnfv3vziF7+IdVgSo0aNYtKkSRQWFsY6lBPOJ/31wL59+5gzZw5Dhw6t0T906FCmT58eo6gkKX7t2LEDCEmVVNscOHCAF198kd27dzNgwIBYhyPVcNttt3HZZZdx0UUXxToU6TDLly8nJyeHtm3bMmzYMD799NNYh3RCJMU6AJ18mzdv5sCBA7Ro0aJGf4sWLVi/fn2MopKk+BSNRhk5ciTnnnsu3bt3j3U4UqWFCxcyYMAA9u7dS0ZGBi+//DJdu3aNdVhSpRdffJG5c+cya9asWIciHaagoIDf/e53dOrUiQ0bNjB69GgGDhzI4sWLycrKinV4X4lJfz0SiURqfI5Go4f1SZI+3+23386CBQt47733Yh2KVEPnzp0pLCxk+/btvPTSS9x4441MmzbNxF+1wpo1a/jxj3/M66+/TlpaWqzDkQ5zySWXVP65R48eDBgwgPbt2zNu3DhGjhwZw8i+OpP+eiA7O5vExMTDnupv3LjxsKf/kqSj+9GPfsQrr7zCO++8Q25ubqzDkWpISUmhQ4cOAPTv359Zs2bx+OOP8z//8z8xjkyCOXPmsHHjRvr161fZd+DAAd555x2eeuopysrKSExMjGGEUk3p6en06NGD5cuXxzqUr8x3+uuBlJQU+vXrx5QpU2r0T5kyhYEDB8YoKkmKH9FolNtvv50//elPvPXWW7Rt2zbWIUnHFI1GKSsri3UYEgCDBw9m4cKFFBYWVrb+/ftz/fXXU1hYaMKvWqesrIwlS5bQqlWrWIfylfmkv54YOXIkN9xwA/3792fAgAE888wzFBUVceutt8Y6NIldu3bxySefVH5euXIlhYWFNGvWjPz8/BhGJgW33XYb48eP589//jONGjWqnDmVmZlJgwYNYhydBPfeey+XXHIJeXl57Ny5kxdffJGpU6fyt7/9LdahSQA0atTosDoo6enpZGVlWR9FtcJdd93F5ZdfTn5+Phs3bmT06NGUlJRw4403xjq0r8ykv5749re/zZYtW3jooYdYt24d3bt357XXXqN169axDk1i9uzZXHDBBZWfD703deONN/Lss8/GKCqpyqHlTgcNGlSj/7e//S033XTTqQ9I+owNGzZwww03sG7dOjIzM+nZsyd/+9vfGDJkSKxDk6S4sHbtWq677jo2b95M8+bNOfvss5k5c2adyJci0Wg0GusgJEmSJEnSiec7/ZIkSZIk1VEm/ZIkSZIk1VEm/ZIkSZIk1VEm/ZIkSZIk1VEm/ZIkSZIk1VEm/ZIkSZIk1VEm/ZIkSZIk1VEm/ZIkSZIk1VEm/ZIkqdY577zzGD9+/OfuE4lEmDRp0hc671NPPcUVV1zxFSKTJCm+mPRLkiQANm7cyC233EJ+fj6pqam0bNmSiy++mBkzZlTu06ZNGyKRCDNnzqxx7B133MGgQYMqP48aNYpIJEIkEiEhIYGcnByuv/561qxZc8w4Xn31VdavX8+wYcO+UPyHvl8kEiEpKYn8/HxGjhxJWVlZ5T4jRoxg1qxZvPfee1/o3JIkxSuTfkmSBMA3v/lN5s+fz7hx41i2bBmvvPIKgwYNYuvWrTX2S0tL4yc/+ckxz9etWzfWrVvH2rVrmThxIgsXLuTaa6895nFPPPEE3/3ud0lI+OK/pvz2t79l3bp1rFy5krFjx/Lcc88xevToyu2pqakMHz6cJ5988gufW5KkeJQU6wAkSVLsbd++nffee4+pU6dy/vnnA9C6dWvOOuusw/a95ZZbePrpp3nttde49NJLj3rOpKQkWrZsCUBOTg4jRozgX/7lXygpKaFx48ZHPGbz5s288cYbPPbYYzX6ly9fzs0338yHH35Iu3btePzxx494fJMmTSq/Z15eHldccQVz586tsc8VV1zB0KFDKS0tpUGDBkeNX5KkusAn/ZIkiYyMDDIyMpg0aVKN6fBH0qZNG2699VbuueceKioqjuv869ev509/+hOJiYkkJiYedb/33nuPhg0bcsYZZ1T2VVRU8I1vfIPExERmzpzJr371q+OaabBs2TLefvttCgoKavT379+f8vJyPvzww+OKXZKkeGbSL0mSSEpK4tlnn2XcuHE0adKEc845h3vvvZcFCxYccf+f/exnrFy5khdeeOGo51y4cCEZGRk0bNiQVq1aMXXqVG677TbS09OPesyqVato0aJFjan9b7zxBkuWLOG5556jd+/enHfeeTzyyCNHPP66664jIyODtLQ0OnfuTLdu3bjnnntq7JOenk6TJk1YtWrV5/yNSJJUN5j0S5IkILzTX1xczCuvvMLFF1/M1KlT6du3L88+++xh+zZv3py77rqL+++/n3379h3xfJ07d6awsJBZs2bx8MMP07t3bx5++OHPjaG0tJS0tLQafUuWLCE/P5/c3NzKvgEDBhzx+Mcee4zCwkLmz5/Pq6++yrJly7jhhhsO269Bgwbs2bPnc2ORJKkuMOmXJEmV0tLSGDJkCPfffz/Tp0/npptu4oEHHjjiviNHjqS0tJSxY8cecXtKSgodOnSgW7du3HvvvfTu3Zt//ud//tzvn52dzbZt22r0RaPRw/aLRCJHPL5ly5Z06NCBzp07c9lll/Hggw8yceJEPvnkkxr7bd26lebNm39uLJIk1QUm/ZIk6ai6du3K7t27j7gtIyOD++67j4cffpiSkpJjnuu+++5jwoQJhxXWq65Pnz6sX7++RuLftWtXioqKKC4uruyrvozg5zlUP6C0tLSyb8WKFezdu5c+ffoc1zkkSYpnJv2SJIktW7Zw4YUX8vzzz7NgwQJWrlzJH/7wBx599FGuvPLKox73gx/8gMzMTCZMmHDM79GuXTuuvPJK7r///qPu06dPH5o3b877779f2XfRRRfRuXNnvvOd7zB//nzeffddfvrTnx7x+O3bt7N+/XqKi4uZNm0aDz30EJ06dapRGPDdd9+lXbt2tG/f/pgxS5IU70z6JUkSGRkZFBQU8Nhjj3HeeefRvXt37rvvPkaMGMFTTz111OOSk5P593//d/bu3Xtc3+fOO+/kr3/9Kx988MERtycmJvK9732vRoHAhIQEXn75ZcrKyjjrrLP4/ve/f9TaAN/97ndp1aoVubm5XHfddXTr1o3JkyeTlFS1SvGECRMYMWLEccUrSVK8i0SP9KKcJElSjGzYsIFu3boxZ84cWrdufULPvWjRIgYPHsyyZcvIzMw8oeeWJKk28km/JEmqVVq0aMFvfvMbioqKTvi5i4uL+d3vfmfCL0mqN3zSL0mSJElSHeWTfkmSJEmS6iiTfkmSJEmS6iiTfkmSJEmS6iiTfkmSJEmS6iiTfkmSJEmS6iiTfkmSJEmS6iiTfkmSJEmS6iiTfkmSJEmS6iiTfkmSJEmS6qj/H2WFLiDkbTLDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Read the data from the text file\n",
    "data = []\n",
    "with open('C:\\Users\\\\malik\\\\Desktop\\\\Disertation\\\\data.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        if \"With z\" in line or \"Without z\" in line:\n",
    "            model_type = \"With z\" if \"With z\" in line else \"Without z\"\n",
    "            noise_type = re.search(r'\\[(.*?)\\]', line).group(1)\n",
    "            snr_level = int(re.search(r'SNR (\\d)', line).group(1))\n",
    "            snr_value = float(re.search(r'SNR: ([\\d.-]+)', line).group(1))\n",
    "            rmse_value = float(re.search(r'RMSE: ([\\d.-]+)', line).group(1))\n",
    "            data.append({\"Model_Type\": model_type, \"Noise_Type\": noise_type, \"SNR_Level\": snr_level, \"SNR\": snr_value, \"RMSE\": rmse_value})\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separate the data for the two models\n",
    "df_with_z = df[df[\"Model_Type\"] == \"With z\"]\n",
    "df_without_z = df[df[\"Model_Type\"] == \"Without z\"]\n",
    "\n",
    "# Calculate average SNR and RMSE for each SNR level\n",
    "avg_snr_with_z = df_with_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_with_z = df_with_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "avg_snr_without_z = df_without_z.groupby('SNR_Level')['SNR'].mean()\n",
    "avg_rmse_without_z = df_without_z.groupby('SNR_Level')['RMSE'].mean()\n",
    "\n",
    "# Plot SNR vs Average SNR\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_snr_with_z.index, avg_snr_with_z.values, label='With z')\n",
    "plt.plot(avg_snr_without_z.index, avg_snr_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Average SNR (dB)')\n",
    "plt.title('SNR vs Average SNR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('snr_vs_avg_snr.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot SNR vs RMSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(avg_rmse_with_z.index, avg_rmse_with_z.values, label='With z')\n",
    "plt.plot(avg_rmse_without_z.index, avg_rmse_without_z.values, label='Without z')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('SNR vs RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# plt.savefig('snr_vs_rmse.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5823d5-c4f8-40ea-a901-892e88df8277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
