{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdfcd0-6177-4cbb-a654-b7cdb21d303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import wfdb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ECGDataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, raw_signals, noisy_signals):\n",
    "        self.raw_signals = raw_signals\n",
    "        self.noisy_signals = noisy_signals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_signal = self.raw_signals[idx]\n",
    "        noisy_signal = self.noisy_signals[idx]\n",
    "        return torch.tensor(raw_signal, dtype=torch.float32), torch.tensor(noisy_signal, dtype=torch.float32)\n",
    "\n",
    "# Define the Improved DAE model\n",
    "class ImprovedDAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedDAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Define the function to add noise to the signal\n",
    "def add_noise(signal, noise, snr):\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    factor = (signal_power / noise_power) / (10 ** (snr / 10))\n",
    "    noisy_signal = signal + noise * np.sqrt(factor)\n",
    "    return noisy_signal\n",
    "\n",
    "# Define the function to load MIT-BIH data\n",
    "def load_mit_bih_data(records, noise_type, snr_levels, target_length=650000):\n",
    "    raw_signals = []\n",
    "    noisy_signals_dict = {snr: [] for snr in snr_levels}\n",
    "    \n",
    "    for record in records:\n",
    "        raw_record = wfdb.rdrecord(f'mit-bih-arrhythmia-database-1.0.0/{record}')\n",
    "        raw_signal = raw_record.p_signal[:, 0]  # Use the first channel for simplicity\n",
    "        \n",
    "        # Load noise and add it to the raw signal\n",
    "        noise_record = wfdb.rdrecord(f'mit-bih-noise-stress-test-database-1.0.0/{noise_type}')\n",
    "        noise_signal = noise_record.p_signal[:, 0]\n",
    "        \n",
    "        # Ensure the signals are of the same length\n",
    "        min_length = min(len(raw_signal), len(noise_signal), target_length)\n",
    "        raw_signal = raw_signal[:min_length]\n",
    "        noise_signal = noise_signal[:min_length]\n",
    "        \n",
    "        # Pad signals to target length\n",
    "        if min_length < target_length:\n",
    "            raw_signal = np.pad(raw_signal, (0, target_length - min_length), 'constant')\n",
    "            noise_signal = np.pad(noise_signal, (0, target_length - min_length), 'constant')\n",
    "        \n",
    "        raw_signals.append(raw_signal)\n",
    "        \n",
    "        for snr in snr_levels:\n",
    "            noisy_signal = add_noise(raw_signal, noise_signal, snr)\n",
    "            noisy_signals_dict[snr].append(noisy_signal)\n",
    "    \n",
    "    return np.array(raw_signals), {snr: np.array(noisy_signals_dict[snr]) for snr in snr_levels}\n",
    "\n",
    "# Load the data\n",
    "records = ['103', '105', '111', '116', '122', '205', '213', '219', '223', '230']\n",
    "noise_types = ['bw', 'em', 'ma']\n",
    "snr_levels = [0, 1, 2, 3, 4, 5]\n",
    "target_length = 649984\n",
    "\n",
    "raw_signals, noisy_signals_dict = {}, {}\n",
    "for noise_type in noise_types:\n",
    "    raw_signals[noise_type], noisy_signals_dict[noise_type] = load_mit_bih_data(records, noise_type, snr_levels, target_length)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "datasets = {}\n",
    "for noise_type in noise_types:\n",
    "    for snr in snr_levels:\n",
    "        datasets[(noise_type, snr)] = ECGDataset(raw_signals[noise_type], noisy_signals_dict[noise_type][snr])\n",
    "\n",
    "dataloaders = {key: DataLoader(dataset, batch_size=16, shuffle=True) for key, dataset in datasets.items()}\n",
    "\n",
    "# Define the training function\n",
    "def train_dae(model, dataloaders, num_epochs=10, lr=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for (noise_type, snr), dataloader in dataloaders.items():\n",
    "        for epoch in range(num_epochs):\n",
    "            for raw_signals, noisy_signals in dataloader:\n",
    "                raw_signals = raw_signals.unsqueeze(1)  # Add channel dimension\n",
    "                noisy_signals = noisy_signals.unsqueeze(1)\n",
    "                \n",
    "                outputs = model(noisy_signals)\n",
    "                loss = criterion(outputs, raw_signals)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            print(f'[{noise_type} SNR {snr}] Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize and train the model\n",
    "dae_model = ImprovedDAE()\n",
    "trained_model = train_dae(dae_model, dataloaders, num_epochs=10)\n",
    "\n",
    "# Test the trained model on a sample\n",
    "sample_noisy_signal = noisy_signals_dict['bw'][3][0]  # Example with 'bw' noise and SNR 3\n",
    "sample_noisy_signal = torch.tensor(sample_noisy_signal, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "denoised_signal = trained_model(sample_noisy_signal).detach().numpy().squeeze()\n",
    "\n",
    "# Plot the original, noisy, and denoised signals\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(raw_signals['bw'][0], label='Original Signal')\n",
    "plt.plot(sample_noisy_signal.squeeze(), label='Noisy Signal')\n",
    "plt.plot(denoised_signal, label='Denoised Signal')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e262548-ca95-4005-bab1-6d959f3b2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import wfdb\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ECGDataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, raw_signals, noisy_signals):\n",
    "        self.raw_signals = raw_signals\n",
    "        self.noisy_signals = noisy_signals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_signal = self.raw_signals[idx]\n",
    "        noisy_signal = self.noisy_signals[idx]\n",
    "        return torch.tensor(raw_signal, dtype=torch.float32), torch.tensor(noisy_signal, dtype=torch.float32)\n",
    "\n",
    "# Define the Improved DAE model\n",
    "class ImprovedDAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedDAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Define the function to add noise to the signal\n",
    "def add_noise(signal, noise, snr):\n",
    "    signal_power = np.mean(signal ** 2)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "    factor = (signal_power / noise_power) / (10 ** (snr / 10))\n",
    "    noisy_signal = signal + noise * np.sqrt(factor)\n",
    "    return noisy_signal\n",
    "\n",
    "# Define the function to load MIT-BIH data\n",
    "def load_mit_bih_data(records, noise_type, snr_levels, sample_length=101):\n",
    "    raw_signals = []\n",
    "    noisy_signals_dict = {snr: [] for snr in snr_levels}\n",
    "    \n",
    "    for record in records:\n",
    "        raw_record = wfdb.rdrecord(os.path.join('mit-bih-arrhythmia-database-1.0.0', record))\n",
    "        raw_signal = raw_record.p_signal[:, 0]  # Use the first channel for simplicity\n",
    "        \n",
    "        # Load noise and add it to the raw signal\n",
    "        noise_record = wfdb.rdrecord(os.path.join('mit-bih-noise-stress-test-database-1.0.0', noise_type))\n",
    "        noise_signal = noise_record.p_signal[:, 0]\n",
    "        \n",
    "        # Ensure the signals are of the same length\n",
    "        min_length = min(len(raw_signal), len(noise_signal))\n",
    "        raw_signal = raw_signal[:min_length]\n",
    "        noise_signal = noise_signal[:min_length]\n",
    "        \n",
    "        for start_idx in range(0, min_length - sample_length + 1, sample_length):\n",
    "            raw_sample = raw_signal[start_idx:start_idx + sample_length]\n",
    "            noise_sample = noise_signal[start_idx:start_idx + sample_length]\n",
    "            raw_signals.append(raw_sample)\n",
    "            \n",
    "            for snr in snr_levels:\n",
    "                noisy_sample = add_noise(raw_sample, noise_sample, snr)\n",
    "                noisy_signals_dict[snr].append(noisy_sample)\n",
    "    \n",
    "    return np.array(raw_signals), {snr: np.array(noisy_signals_dict[snr]) for snr in snr_levels}\n",
    "\n",
    "# Load the data\n",
    "records = ['103', '105', '111', '116', '122', '205', '213', '219', '223', '230']\n",
    "noise_types = ['bw', 'em', 'ma']\n",
    "snr_levels = [0, 1, 2, 3, 4, 5]\n",
    "sample_length = 101\n",
    "\n",
    "raw_signals, noisy_signals_dict = {}, {}\n",
    "for noise_type in noise_types:\n",
    "    raw_signals[noise_type], noisy_signals_dict[noise_type] = load_mit_bih_data(records, noise_type, snr_levels, sample_length)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "datasets = {}\n",
    "for noise_type in noise_types:\n",
    "    for snr in snr_levels:\n",
    "        dataset = ECGDataset(raw_signals[noise_type], noisy_signals_dict[noise_type][snr])\n",
    "        train_size = 30000\n",
    "        test_size = 2000\n",
    "        train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "        datasets[(noise_type, snr, 'train')] = train_dataset\n",
    "        datasets[(noise_type, snr, 'test')] = test_dataset\n",
    "\n",
    "dataloaders = {key: DataLoader(dataset, batch_size=64, shuffle=True) for key, dataset in datasets.items()}\n",
    "\n",
    "# Define the training function\n",
    "def train_dae(model, train_loaders, test_loaders, num_epochs=10, lr=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for (noise_type, snr, phase), dataloader in dataloaders.items():\n",
    "        if phase == 'train':\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                for raw_signals, noisy_signals in dataloader:\n",
    "                    raw_signals = raw_signals.unsqueeze(1)  # Add channel dimension\n",
    "                    noisy_signals = noisy_signals.unsqueeze(1)\n",
    "\n",
    "                    outputs = model(noisy_signals)\n",
    "                    loss = criterion(outputs, raw_signals)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                print(f'[{noise_type} SNR {snr}] Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize and train the model\n",
    "dae_model = ImprovedDAE()\n",
    "train_loaders = {key: loader for key, loader in dataloaders.items() if key[2] == 'train'}\n",
    "test_loaders = {key: loader for key, loader in dataloaders.items() if key[2] == 'test'}\n",
    "trained_model = train_dae(dae_model, train_loaders, test_loaders, num_epochs=10)\n",
    "\n",
    "# Test the trained model on a sample\n",
    "def test_dae(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for raw_signals, noisy_signals in test_loader:\n",
    "            raw_signals = raw_signals.unsqueeze(1)\n",
    "            noisy_signals = noisy_signals.unsqueeze(1)\n",
    "            outputs = model(noisy_signals)\n",
    "            raw_signals = raw_signals.squeeze().numpy()\n",
    "            noisy_signals = noisy_signals.squeeze().numpy()\n",
    "            outputs = outputs.squeeze().numpy()\n",
    "            return raw_signals[0], noisy_signals[0], outputs[0]\n",
    "\n",
    "# Test the model on a specific noise type and SNR level\n",
    "raw_sample, noisy_sample, denoised_sample = test_dae(trained_model, test_loaders[('bw', 3, 'test')])\n",
    "\n",
    "# Plot the original, noisy, and denoised signals\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(raw_sample, label='Original Signal')\n",
    "plt.plot(noisy_sample, label='Noisy Signal')\n",
    "plt.plot(denoised_sample, label='Denoised Signal')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
