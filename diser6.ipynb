{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ma23193/Dissertation/blob/main/diser6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vzwj_SSePgJ",
        "outputId": "1bce2bee-04f0-4174-b367-42478ee5ba63"
      },
      "id": "-vzwj_SSePgJ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cf92d797-3ab8-450d-87f7-2370f980f445",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf92d797-3ab8-450d-87f7-2370f980f445",
        "outputId": "12e2ad8c-af65-4ce7-9f80-240f93ecd702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available arrhythmia records: ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '111', '112', '113', '114', '115', '116', '117', '118', '119', '121', '122', '123', '124', '200', '201', '202', '203', '205', '207', '208', '209', '210', '212', '213', '214', '215', '217', '219', '220', '221', '222', '223', '228', '230', '231', '232', '233', '234']\n",
            "Available noise records: ['118e00', '118e06', '118e12', '118e18', '118e24', '118e_6', '119e00', '119e06', '119e12', '119e18', '119e24', '119e_6', 'bw', 'em', 'ma']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Function to list available records in a directory\n",
        "def list_records(directory):\n",
        "    records = [f.split('.')[0] for f in os.listdir(directory) if f.endswith('.dat')]\n",
        "    return sorted(set(records))\n",
        "\n",
        "# Paths to the folders containing the extracted datasets\n",
        "arrhythmia_folder_path = '/content/drive/MyDrive/Dissertation/mit-bih-arrhythmia-database-1.0.0'\n",
        "noise_folder_path = '/content/drive/MyDrive/Dissertation/mit-bih-noise-stress-test-database-1.0.0'\n",
        "\n",
        "arrhythmia_records = list_records(arrhythmia_folder_path)\n",
        "noise_records = list_records(noise_folder_path)\n",
        "\n",
        "print(f\"Available arrhythmia records: {arrhythmia_records}\")\n",
        "print(f\"Available noise records: {noise_records}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "10b0c0c7-9ff7-4c2f-a73e-98f08556231e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10b0c0c7-9ff7-4c2f-a73e-98f08556231e",
        "outputId": "e6c3fd20-a7e3-4b1e-9747-f612dfcf9201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean data shape: (9750000,)\n",
            "Noisy data shape: (9750000,)\n",
            "Train loader created with 3046 samples.\n",
            "Test loader created with 761 samples.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import wfdb\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load ECG data\n",
        "def load_ecg_data(record_path):\n",
        "    record = wfdb.rdrecord(record_path)\n",
        "    signal = record.p_signal[:, 0]  # Use only the first channel\n",
        "    return signal\n",
        "\n",
        "# Preprocess data\n",
        "def preprocess_data(arrhythmia_folder, noise_folder, train_records, test_records):\n",
        "    clean_signals = []\n",
        "    noise_signals = []\n",
        "\n",
        "    # Load arrhythmia records\n",
        "    for record in train_records + test_records:\n",
        "        record_path = os.path.join(arrhythmia_folder, record)\n",
        "        if os.path.exists(record_path + '.dat'):\n",
        "            signal = load_ecg_data(record_path)\n",
        "            clean_signals.append(signal)\n",
        "\n",
        "    # Load noise records\n",
        "    for record in noise_records:\n",
        "        record_path = os.path.join(noise_folder, record)\n",
        "        if os.path.exists(record_path + '.dat'):\n",
        "            signal = load_ecg_data(record_path)\n",
        "            noise_signals.append(signal)\n",
        "\n",
        "    if clean_signals:\n",
        "        clean_signals = np.concatenate(clean_signals, axis=0)\n",
        "    else:\n",
        "        clean_signals = np.empty((0,))\n",
        "\n",
        "    if noise_signals:\n",
        "        noise_signals = np.concatenate(noise_signals, axis=0)\n",
        "    else:\n",
        "        noise_signals = np.empty((0,))\n",
        "\n",
        "    min_length = min(len(clean_signals), len(noise_signals))\n",
        "    clean_signals = clean_signals[:min_length]\n",
        "    noise_signals = noise_signals[:min_length]\n",
        "\n",
        "    if clean_signals.size > 0 and noise_signals.size > 0:\n",
        "        # Create noisy signals by adding noise to clean signals\n",
        "        noisy_signals = clean_signals + noise_signals\n",
        "        # Normalize signals\n",
        "        scaler = MinMaxScaler()\n",
        "        clean_signals = scaler.fit_transform(clean_signals.reshape(-1, 1)).flatten()\n",
        "        noisy_signals = scaler.transform(noisy_signals.reshape(-1, 1)).flatten()\n",
        "    else:\n",
        "        noisy_signals = np.empty((0,))\n",
        "\n",
        "    return clean_signals, noisy_signals\n",
        "\n",
        "# Define the records to use for training and testing\n",
        "train_records = ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109']\n",
        "test_records = ['111', '112', '113', '114', '115', '116', '117', '118', '119', '121']\n",
        "\n",
        "# Filter out unavailable records\n",
        "train_records = [rec for rec in train_records if rec in arrhythmia_records]\n",
        "test_records = [rec for rec in test_records if rec in arrhythmia_records]\n",
        "\n",
        "# Paths to the folders containing the extracted datasets\n",
        "arrhythmia_folder_path = '/content/drive/MyDrive/Dissertation/mit-bih-arrhythmia-database-1.0.0'\n",
        "noise_folder_path = '/content/drive/MyDrive/Dissertation/mit-bih-noise-stress-test-database-1.0.0'\n",
        "\n",
        "clean_data, noisy_data = preprocess_data(arrhythmia_folder_path, noise_folder_path, train_records, test_records)\n",
        "\n",
        "print(f\"Clean data shape: {clean_data.shape}\")\n",
        "print(f\"Noisy data shape: {noisy_data.shape}\")\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, clean_data, noisy_data, segment_length=2560):\n",
        "        self.clean_data = clean_data\n",
        "        self.noisy_data = noisy_data\n",
        "        self.segment_length = segment_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clean_data) // self.segment_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = idx * self.segment_length\n",
        "        end_idx = start_idx + self.segment_length\n",
        "        clean_sample = self.clean_data[start_idx:end_idx]\n",
        "        noisy_sample = self.noisy_data[start_idx:end_idx]\n",
        "        return torch.Tensor(noisy_sample).unsqueeze(0), torch.Tensor(clean_sample).unsqueeze(0)\n",
        "\n",
        "segment_length = 2560  # As specified in the paper\n",
        "train_size = int(0.8 * len(clean_data))\n",
        "test_size = len(clean_data) - train_size\n",
        "\n",
        "train_clean = clean_data[:train_size]\n",
        "test_clean = clean_data[train_size:]\n",
        "train_noisy = noisy_data[:train_size]\n",
        "test_noisy = noisy_data[train_size:]\n",
        "\n",
        "train_dataset = ECGDataset(train_clean, train_noisy, segment_length=segment_length)\n",
        "test_dataset = ECGDataset(test_clean, test_noisy, segment_length=segment_length)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Train loader created with {len(train_loader.dataset)} samples.\")\n",
        "print(f\"Test loader created with {len(test_loader.dataset)} samples.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "083dbc98-1a2c-4ea8-9bfd-9fb19a0c3cbb",
      "metadata": {
        "id": "083dbc98-1a2c-4ea8-9bfd-9fb19a0c3cbb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(1, 512, kernel_size=4, stride=2, padding=1),  # (N, 512, 1280)\n",
        "            nn.PReLU(),\n",
        "            nn.Conv1d(512, 512, kernel_size=4, stride=2, padding=1),  # (N, 512, 640)\n",
        "            nn.PReLU(),\n",
        "            nn.Conv1d(512, 512, kernel_size=4, stride=2, padding=1),  # (N, 512, 320)\n",
        "            nn.PReLU(),\n",
        "            nn.Conv1d(512, 512, kernel_size=4, stride=2, padding=1),  # (N, 512, 160)\n",
        "            nn.PReLU(),\n",
        "            nn.Conv1d(512, 256, kernel_size=4, stride=2, padding=1),  # (N, 256, 80)\n",
        "            nn.PReLU(),\n",
        "            nn.Conv1d(256, 128, kernel_size=4, stride=2, padding=1),  # (N, 128, 40)\n",
        "            nn.PReLU(),\n",
        "            nn.Conv1d(128, 64, kernel_size=4, stride=2, padding=1),  # (N, 64, 20)\n",
        "            nn.PReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose1d(64, 128, kernel_size=4, stride=2, padding=1),  # (N, 128, 40)\n",
        "            nn.PReLU(),\n",
        "            nn.ConvTranspose1d(128, 256, kernel_size=4, stride=2, padding=1),  # (N, 256, 80)\n",
        "            nn.PReLU(),\n",
        "            nn.ConvTranspose1d(256, 512, kernel_size=4, stride=2, padding=1),  # (N, 512, 160)\n",
        "            nn.PReLU(),\n",
        "            nn.ConvTranspose1d(512, 512, kernel_size=4, stride=2, padding=1),  # (N, 512, 320)\n",
        "            nn.PReLU(),\n",
        "            nn.ConvTranspose1d(512, 512, kernel_size=4, stride=2, padding=1),  # (N, 512, 640)\n",
        "            nn.PReLU(),\n",
        "            nn.ConvTranspose1d(512, 512, kernel_size=4, stride=2, padding=1),  # (N, 512, 1280)\n",
        "            nn.PReLU(),\n",
        "            nn.ConvTranspose1d(512, 1, kernel_size=4, stride=2, padding=1)  # (N, 1, 2560)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = []\n",
        "        for layer in self.encoder:\n",
        "            x = layer(x)\n",
        "            encoded.append(x.clone())  # Save the output for skip connections\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        for i, layer in enumerate(self.decoder):\n",
        "            if isinstance(layer, nn.ConvTranspose1d):\n",
        "                x = layer(x)\n",
        "                if i < len(self.decoder) - 1:\n",
        "                    x = nn.functional.prelu(x)\n",
        "                    x += encoded[-(i + 1)]  # Skip connection\n",
        "\n",
        "        print(f\"Generator output shape: {x.shape}\")\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b8c67e16-0f83-41ae-b089-633bdbdb7289",
      "metadata": {
        "id": "b8c67e16-0f83-41ae-b089-633bdbdb7289"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv1d(2, 64, kernel_size=4, stride=2, padding=1),  # (N, 64, 1280)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1),  # (N, 128, 640)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Conv1d(128, 256, kernel_size=4, stride=2, padding=1),  # (N, 256, 320)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Conv1d(256, 512, kernel_size=4, stride=2, padding=1),  # (N, 512, 160)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),  # (N, 1024, 80)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1024 * 80, 1),  # Ensure this matches the expected input size\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        print(f\"Shape after conv layers: {x.shape}\")\n",
        "        x = self.fc(x)\n",
        "        print(f\"Shape after linear layer: {x.shape}\")\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "173cebe1-6905-45c4-a6ac-4bd6e9d2ae9f",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "173cebe1-6905-45c4-a6ac-4bd6e9d2ae9f",
        "outputId": "485178ab-dbd6-4b9d-983e-a1a4b49a289c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [64, 2, 4], expected input[32, 1, 2560] to have 2 channels, but got 1 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6ef94ab1c7eb>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-6200b47cbb20>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape after conv layers: {x.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 306\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    307\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 2, 4], expected input[32, 1, 2560] to have 2 channels, but got 1 channels instead"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.RMSprop(generator.parameters(), lr=0.0005)\n",
        "optimizer_D = optim.RMSprop(discriminator.parameters(), lr=0.0005)\n",
        "\n",
        "num_epochs = 10  # Adjust the number of epochs as needed\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (noisy, clean) in enumerate(train_loader):\n",
        "        noisy, clean = noisy.to(device), clean.to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        real_labels = torch.ones(noisy.size(0), 1).to(device)\n",
        "        fake_labels = torch.zeros(noisy.size(0), 1).to(device)\n",
        "\n",
        "        outputs = discriminator(clean)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "\n",
        "        fake_clean = generator(noisy)\n",
        "        outputs = discriminator(fake_clean.detach())\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        outputs = discriminator(fake_clean)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], '\n",
        "                  f'D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4aefda1-896d-4643-8788-d52b9a3196ab",
      "metadata": {
        "id": "e4aefda1-896d-4643-8788-d52b9a3196ab"
      },
      "outputs": [],
      "source": [
        "def add_noise(signal, noise_type, snr_db):\n",
        "    \"\"\"\n",
        "    Add noise of a specific type to the signal at a given SNR level.\n",
        "\n",
        "    Args:\n",
        "        signal (numpy array): Clean ECG signal.\n",
        "        noise_type (str): Type of noise ('BW', 'EM', 'MA', 'EM+BW', 'MA+BW', 'MA+EM', 'MA+EM+BW').\n",
        "        snr_db (float): Desired signal-to-noise ratio in dB.\n",
        "\n",
        "    Returns:\n",
        "        noisy_signal (numpy array): Noisy ECG signal.\n",
        "    \"\"\"\n",
        "    noise = np.zeros_like(signal)\n",
        "    if 'BW' in noise_type:\n",
        "        noise += np.random.normal(0, 1, signal.shape)\n",
        "    if 'EM' in noise_type:\n",
        "        noise += np.random.normal(0, 1, signal.shape) * np.random.exponential(1, signal.shape)\n",
        "    if 'MA' in noise_type:\n",
        "        noise += np.convolve(np.random.normal(0, 1, signal.size), np.ones(10)/10, mode='same')\n",
        "\n",
        "    signal_power = np.mean(signal**2)\n",
        "    noise_power = np.mean(noise**2)\n",
        "    noise_variance = signal_power / (10**(snr_db / 10))\n",
        "    noise = noise * np.sqrt(noise_variance / noise_power)\n",
        "\n",
        "    noisy_signal = signal + noise\n",
        "    return noisy_signal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d6dec1ee-80be-4adf-801b-d3aea9e19706",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "d6dec1ee-80be-4adf-801b-d3aea9e19706",
        "outputId": "11a6afc6-9bfc-4c73-8271-6698c4c8ae5b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "prelu() missing 1 required positional arguments: \"weight\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-23e8226726fe>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Evaluate the model and get the results in table form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mavg_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-23e8226726fe>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(generator, test_loader, noise_types, snr_levels)\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mclean_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     \u001b[0mdenoised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0msnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_snr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenoised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-fdf4f5938b5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Skip connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: prelu() missing 1 required positional arguments: \"weight\""
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "def add_noise(signal, noise_type, snr_db):\n",
        "    noise = np.zeros_like(signal)\n",
        "    if 'BW' in noise_type:\n",
        "        noise += np.random.normal(0, 1, signal.shape)\n",
        "    if 'EM' in noise_type:\n",
        "        noise += np.random.normal(0, 1, signal.shape) * np.random.exponential(1, signal.shape)\n",
        "    if 'MA' in noise_type:\n",
        "        noise += np.convolve(np.random.normal(0, 1, signal.size), np.ones(10)/10, mode='same')\n",
        "\n",
        "    signal_power = np.mean(signal**2)\n",
        "    noise_power = np.mean(noise**2)\n",
        "    noise_variance = signal_power / (10**(snr_db / 10))\n",
        "    noise = noise * np.sqrt(noise_variance / noise_power)\n",
        "\n",
        "    noisy_signal = signal + noise\n",
        "    return noisy_signal\n",
        "\n",
        "def calculate_snr(clean, denoised):\n",
        "    noise = clean - denoised\n",
        "    signal_power = np.mean(clean**2)\n",
        "    noise_power = np.mean(noise**2)\n",
        "    snr = 10 * np.log10(signal_power / noise_power)\n",
        "    return snr\n",
        "\n",
        "def evaluate_model(generator, test_loader, noise_types, snr_levels):\n",
        "    generator.eval()\n",
        "    results = {noise_type: {snr: {\"snr\": [], \"rmse\": []} for snr in snr_levels} for noise_type in noise_types}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for noisy, clean in test_loader:\n",
        "            clean = clean.numpy()\n",
        "            for noise_type in noise_types:\n",
        "                for snr_db in snr_levels:\n",
        "                    noisy_signals = np.array([add_noise(c.flatten(), noise_type, snr_db) for c in clean])\n",
        "                    noisy_tensor = torch.Tensor(noisy_signals).unsqueeze(1).to(device)\n",
        "                    clean_tensor = torch.Tensor(clean).to(device)\n",
        "\n",
        "                    denoised = generator(noisy_tensor).cpu().numpy().squeeze()\n",
        "\n",
        "                    snr = calculate_snr(clean, denoised)\n",
        "                    rmse = np.sqrt(np.mean((clean - denoised) ** 2))\n",
        "\n",
        "                    results[noise_type][snr_db][\"snr\"].append(snr)\n",
        "                    results[noise_type][snr_db][\"rmse\"].append(rmse)\n",
        "\n",
        "    avg_results = {noise_type: {snr: {\"snr\": np.mean(results[noise_type][snr][\"snr\"]),\n",
        "                                      \"rmse\": np.mean(results[noise_type][snr][\"rmse\"])}\n",
        "                                for snr in snr_levels}\n",
        "                   for noise_type in noise_types}\n",
        "\n",
        "    table_data = []\n",
        "    for snr_db in snr_levels:\n",
        "        row = []\n",
        "        for noise_type in noise_types:\n",
        "            row.append(avg_results[noise_type][snr_db]['snr'])\n",
        "            row.append(avg_results[noise_type][snr_db]['rmse'])\n",
        "        table_data.append(row)\n",
        "\n",
        "    columns = []\n",
        "    for noise_type in noise_types:\n",
        "        columns.append(f\"{noise_type}_SNR\")\n",
        "        columns.append(f\"{noise_type}_RMSE\")\n",
        "\n",
        "    df = pd.DataFrame(table_data, columns=columns, index=[f\"{snr}dB\" for snr in snr_levels])\n",
        "\n",
        "    print(df)\n",
        "    return df\n",
        "\n",
        "# Define the noise types and SNR levels to evaluate\n",
        "noise_types = ['BW', 'EM', 'MA', 'EM+BW', 'MA+BW', 'MA+EM', 'MA+EM+BW']\n",
        "snr_levels = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "# Evaluate the model and get the results in table form\n",
        "avg_results_df = evaluate_model(generator, test_loader, noise_types, snr_levels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "51feac54-3c53-4ea7-af6a-a2fc3b70ec19",
      "metadata": {
        "id": "51feac54-3c53-4ea7-af6a-a2fc3b70ec19"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}